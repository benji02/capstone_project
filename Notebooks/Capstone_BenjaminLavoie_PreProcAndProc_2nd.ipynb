{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b019fa",
   "metadata": {},
   "source": [
    "# Benjamin Lavoie (benjaminlavoie02@gmail.com)\n",
    "\n",
    "# CapStone project: Gaming Score Forecasting Model\n",
    "\n",
    "# Last update: March 15th, 2024 (version 2.1)\n",
    "\n",
    "# Notebook 2: Pre-processing and Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233239f0",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "**[3. Part 3 - Introduction (2nd Notebook)](#heading--3)**\n",
    "\n",
    "  * [3.1 - Data Dictionary](#heading--3-1)\n",
    "\n",
    "  * [3.2 - Separating the dataframe](#heading--3-2)\n",
    "\n",
    "  * [3.3 - One hot encoding (dummy variables)](#heading--3-3)\n",
    "  \n",
    "  * [3.4 - Columns to vectorize with TFDIF](#heading--3-4)\n",
    "    \n",
    "  * [3.5 - Variance Threshold](#heading--3-5)\n",
    "  \n",
    "\n",
    "**[4. Part 4 - Modeling](#heading--4)**\n",
    "  \n",
    "  * [4.1 - First Scores, some optimization](#heading--4-1)\n",
    "  \n",
    "  * [4.2 - Confusion Matrix](#heading--4-2)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "29fb31ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Necessary libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import nltk\n",
    "import statsmodels.api as sm\n",
    "import glob\n",
    "import os\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# To plot\n",
    "from scipy import stats\n",
    "from scipy.stats import norm \n",
    "\n",
    "# To split the data as necessary for modelling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# To process text data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# To get rid of logistic regression default solver warnings that appear if sklearn hasn't been updated\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# To \"pickle\" things, like accuracies or even an entire fitted model\n",
    "import joblib\n",
    "\n",
    "# To cross-validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# To set up a temporary directory for caching pipeline results\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "# To build a pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# To do dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# To do a cross-validated grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "\n",
    "#imporint different models\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# To see more columns at once, I'll change the display.max_columns number\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9868f4",
   "metadata": {},
   "source": [
    "<div id=\"heading--3\"/>\n",
    "\n",
    "## 3. Part 3 - Introduction (2nd Notebook)\n",
    "\n",
    "The cleaning and the EDA has all been done in the 1st Notebook.\n",
    "\n",
    "In this 2nd Notebook, I will be doing the pre-processing as well as the processing/modeling.\n",
    "\n",
    "I will start importing the data set, and then by separating the dataset. Since I have 14k+ rows and not 100k+ rows, I'll keep only 20% for the testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace31412",
   "metadata": {},
   "source": [
    "<div id=\"heading--3-1\"/>\n",
    "\n",
    "## 3.1 - Data Dictionary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5d4889",
   "metadata": {},
   "source": [
    "| Feature/Column | Definition | Data type |\n",
    "|----------|----------|----------|\n",
    "| Platform | Platform the game was released on | String |\n",
    "| Developer | Developer of the game | String |\n",
    "| Publisher | Publisher of the game | String |\n",
    "| Genre | Genre of the game | String |\n",
    "| Platform_Brand | Brand of the platform (Nintendo, Sony, Microsoft, PC | String |\n",
    "| Platform_Type | Type of the platform (HomeConsole, Handheld, PC) | String |\n",
    "| Release Date | Release date | DateTime |\n",
    "| Metascore_Range | Classification: Weak, Okay or Strong | String |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "08cf386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_data_2.0.csv', index_col='Unnamed: 0', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "982c658e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Handheld', 'HomeConsole', 'PC']"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df['Platform_Type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc465383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "40466190",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Platform_Brand</th>\n",
       "      <th>Platform_Type</th>\n",
       "      <th>Release_Date</th>\n",
       "      <th>Release_Day</th>\n",
       "      <th>Release_Month</th>\n",
       "      <th>Release_Year</th>\n",
       "      <th>Metascore_Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>Nintendo EAD</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>HomeConsole</td>\n",
       "      <td>2006-11-19</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>Okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mario Kart 8 Deluxe</td>\n",
       "      <td>NS</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>Nintendo EPD</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>HomeConsole</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>Strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Team Fortress 2</td>\n",
       "      <td>PC</td>\n",
       "      <td>Valve</td>\n",
       "      <td>Valve Corporation</td>\n",
       "      <td>Shooter</td>\n",
       "      <td>PC</td>\n",
       "      <td>PC</td>\n",
       "      <td>2007-10-10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2007</td>\n",
       "      <td>Strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "      <td>PC</td>\n",
       "      <td>Valve</td>\n",
       "      <td>Valve Corporation</td>\n",
       "      <td>Shooter</td>\n",
       "      <td>PC</td>\n",
       "      <td>PC</td>\n",
       "      <td>2012-08-21</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "      <td>Strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "      <td>PC</td>\n",
       "      <td>Valve</td>\n",
       "      <td>Valve Corporation</td>\n",
       "      <td>Shooter</td>\n",
       "      <td>PC</td>\n",
       "      <td>PC</td>\n",
       "      <td>2015-10-23</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>Strong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Name Platform   Publisher            Developer  \\\n",
       "0                        Wii Sports      Wii  Nintendo         Nintendo EAD     \n",
       "1               Mario Kart 8 Deluxe       NS  Nintendo         Nintendo EPD     \n",
       "2                   Team Fortress 2       PC     Valve    Valve Corporation     \n",
       "3  Counter-Strike: Global Offensive       PC     Valve    Valve Corporation     \n",
       "4  Counter-Strike: Global Offensive       PC     Valve    Valve Corporation     \n",
       "\n",
       "     Genre Platform_Brand Platform_Type Release_Date  Release_Day  \\\n",
       "0   Sports       Nintendo   HomeConsole   2006-11-19           19   \n",
       "1   Racing       Nintendo   HomeConsole   2017-04-28           28   \n",
       "2  Shooter             PC            PC   2007-10-10           10   \n",
       "3  Shooter             PC            PC   2012-08-21           21   \n",
       "4  Shooter             PC            PC   2015-10-23           23   \n",
       "\n",
       "   Release_Month  Release_Year Metascore_Range  \n",
       "0             11          2006            Okay  \n",
       "1              4          2017          Strong  \n",
       "2             10          2007          Strong  \n",
       "3              8          2012          Strong  \n",
       "4             10          2015          Strong  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323cc8a2",
   "metadata": {},
   "source": [
    "<div id=\"heading--3-2\"/>\n",
    "\n",
    "## 3.2 - Separating the dataframe\n",
    "\n",
    "Let's separate the data in train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "72254416",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Platform', 'Release_Date', 'Release_Day','Release_Month', 'Release_Year'], axis = 1, inplace=True)\n",
    "# df.drop(['Release_Date', 'Release_Day','Release_Month', 'Release_Year'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "7babd11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy variables before separating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2f5e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f673a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbb322e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d221d4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TRAIN set has 10783 data points.\n",
      "The TEST set has 3595 data points.\n"
     ]
    }
   ],
   "source": [
    "# separating into X and y\n",
    "\n",
    "X = df.drop(columns=\"Metascore_Range\")\n",
    "y = df[\"Metascore_Range\"]\n",
    "\n",
    "\n",
    "# Separating into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)\n",
    "\n",
    "# resetting the indexes to be able to separate the review columns and concatenate them easily later\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# Print info on how the data has been split\n",
    "print(f'The TRAIN set has {len(X_train)} data points.')\n",
    "print(f'The TEST set has {len(X_test)} data points.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "bb65ddc3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# might use later\n",
    "\n",
    "# for col1 in X_train.columns:\n",
    "#     for col2 in X_train.columns:\n",
    "#         if col1 != col2:\n",
    "#             contingency_table = pd.crosstab(X_train[col1], X_train[col2])\n",
    "#             chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "#             if (p > 1e-10):\n",
    "#                 print(f'Chi-square test between {col1} and {col2}: Chi2={chi2}, p-value={p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235c0e04",
   "metadata": {},
   "source": [
    "<div id=\"heading--3-3\"/>\n",
    "\n",
    "## 3.3 - One hot encoding (dummy variables)\n",
    "\n",
    "<br>\n",
    "\n",
    "I will transform some of the columns into dummy variables\n",
    "- Platform (testing with and without)\n",
    "- Genre\n",
    "- Platform_Brand\n",
    "- Platform_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "da795594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when trying without platform\n",
    "\n",
    "# X_train_numerical = X_train[['Platform', 'Genre', 'Platform_Brand', 'Platform_Type']].copy()\n",
    "# X_train_dummy = pd.get_dummies(X_train_numerical, dtype=np.int32)\n",
    "\n",
    "# X_test_numerical = X_test[['Platform', 'Genre', 'Platform_Brand', 'Platform_Type']].copy()\n",
    "# X_test_dummy = pd.get_dummies(X_test_numerical, dtype=np.int32)\n",
    "\n",
    "# X_train = pd.concat([X_train, X_train_dummy], axis=\"columns\")\n",
    "# X_test = pd.concat([X_test, X_test_dummy], axis=\"columns\")\n",
    "\n",
    "# X_train.drop(['Platform', 'Genre', 'Platform_Brand', 'Platform_Type'], axis = 1, inplace=True)\n",
    "# X_test.drop(['Platform', 'Genre', 'Platform_Brand', 'Platform_Type'], axis = 1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_numerical = X_train[['Genre', 'Platform_Brand', 'Platform_Type']].copy()\n",
    "X_train_dummy = pd.get_dummies(X_train_numerical, dtype=np.int32)\n",
    "\n",
    "X_test_numerical = X_test[['Genre', 'Platform_Brand', 'Platform_Type']].copy()\n",
    "X_test_dummy = pd.get_dummies(X_test_numerical, dtype=np.int32)\n",
    "\n",
    "X_train = pd.concat([X_train, X_train_dummy], axis=\"columns\")\n",
    "X_test = pd.concat([X_test, X_test_dummy], axis=\"columns\")\n",
    "\n",
    "\n",
    "X_train.drop(['Genre', 'Platform_Brand', 'Platform_Type'], axis = 1, inplace=True)\n",
    "X_test.drop(['Genre', 'Platform_Brand', 'Platform_Type'], axis = 1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "3b82d454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check collinearity after encoding!!\n",
    "# Drop at least one column from one hot encoding!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bceecfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d02932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2813dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "79181f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10783, 3)\n",
      "(10783, 26)\n",
      "(3595, 3)\n",
      "(3595, 26)\n",
      "(10783, 29)\n",
      "(3595, 29)\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# sanity check with all the dfs\n",
    "\n",
    "print(X_train_numerical.shape)\n",
    "print(X_train_dummy.shape)\n",
    "print(X_test_numerical.shape)\n",
    "print(X_test_dummy.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train.isna().sum().sum())\n",
    "print(X_test.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "1981a11d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Publisher', 'Developer', 'Genre_Action',\n",
       "       'Genre_Action-Adventure', 'Genre_Adventure', 'Genre_Board Game',\n",
       "       'Genre_Fighting', 'Genre_MMO', 'Genre_Misc', 'Genre_Music',\n",
       "       'Genre_Party', 'Genre_Platform', 'Genre_Puzzle', 'Genre_Racing',\n",
       "       'Genre_Role-Playing', 'Genre_Sandbox', 'Genre_Shooter',\n",
       "       'Genre_Simulation', 'Genre_Sports', 'Genre_Strategy',\n",
       "       'Genre_Visual Novel', 'Platform_Brand_Microsoft',\n",
       "       'Platform_Brand_Nintendo', 'Platform_Brand_PC', 'Platform_Brand_Sony',\n",
       "       'Platform_Type_Handheld', 'Platform_Type_HomeConsole',\n",
       "       'Platform_Type_PC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the columns\n",
    "\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbb09f8",
   "metadata": {},
   "source": [
    "I think that using a NLP is a good idea, so I will use TF IDF to create more features. Then, I will be able to continue the processing.\n",
    "\n",
    "<div id=\"heading--3-4\"/>\n",
    "\n",
    "## 3.4 - Columns to vectorize with TFDIF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c4560b",
   "metadata": {},
   "source": [
    "Before vectorizing, I will create a my_tokenizer function to tokenize properly some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "40c3ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "ENGLISH_STOP_WORDS = stopwords.words('english')\n",
    "\n",
    "# Custom stopwords to be added\n",
    "\n",
    "custom_stopwords = []\n",
    "custom_stopwords = ['game', 'games', 'unknown', 'studio', 'inc', 'ltd', 'studios']\n",
    "\n",
    "# Extend stopwords with custom stopwords\n",
    "ENGLISH_STOP_WORDS.extend(custom_stopwords)\n",
    "\n",
    "# my_tokenizer function, to be used when vectorizing\n",
    "def my_tokenizer(sentence):\n",
    "    # remove punctuation and set to lower case\n",
    "    for punctuation_mark in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation_mark,'').lower()\n",
    "\n",
    "    # split sentence into words\n",
    "    listofwords = sentence.split(' ')\n",
    "    listofstemmed_words = []\n",
    "    \n",
    "    # remove stopwords and any tokens that are just empty strings\n",
    "    for word in listofwords:\n",
    "        if (not word in ENGLISH_STOP_WORDS) and (word!=''):\n",
    "            # Stem words\n",
    "            stemmed_word = stemmer.stem(word)\n",
    "            listofstemmed_words.append(stemmed_word)\n",
    "\n",
    "    return listofstemmed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca88def",
   "metadata": {},
   "source": [
    "Now, I will vectorize 3 columns: Name, Publisher and Developer.\n",
    "\n",
    "Under the code, I will also create histograms to show the 20 most weighted words in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "8b6317b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Name_007  Name_06  Name_07  Name_08  Name_09  Name_1  Name_10  Name_11  \\\n",
      "0           0.0  0.58202      0.0      0.0      0.0     0.0      0.0      0.0   \n",
      "1           0.0  0.00000      0.0      0.0      0.0     0.0      0.0      0.0   \n",
      "2           0.0  0.00000      0.0      0.0      0.0     0.0      0.0      0.0   \n",
      "3           0.0  0.00000      0.0      0.0      0.0     0.0      0.0      0.0   \n",
      "4           0.0  0.00000      0.0      0.0      0.0     0.0      0.0      0.0   \n",
      "...         ...      ...      ...      ...      ...     ...      ...      ...   \n",
      "10778       0.0  0.00000      0.0      0.0      0.0     0.0      0.0      0.0   \n",
      "10779       0.0  0.00000      0.0      0.0      0.0     0.0      0.0      0.0   \n",
      "10780       0.0  0.00000      0.0      0.0      0.0     0.0      0.0      0.0   \n",
      "10781       0.0  0.00000      0.0      0.0      0.0     0.0      0.0      0.0   \n",
      "10782       0.0  0.00000      0.0      0.0      0.0     0.0      0.0      0.0   \n",
      "\n",
      "       Name_12  Name_13  Name_14  Name_15  Name_18  Name_19  Name_2  Name_20  \\\n",
      "0          0.0      0.0      0.0      0.0      0.0      0.0     0.0      0.0   \n",
      "1          0.0      0.0      0.0      0.0      0.0      0.0     0.0      0.0   \n",
      "2          0.0      0.0      0.0      0.0      0.0      0.0     0.0      0.0   \n",
      "3          0.0      0.0      0.0      0.0      0.0      0.0     0.0      0.0   \n",
      "4          0.0      0.0      0.0      0.0      0.0      0.0     0.0      0.0   \n",
      "...        ...      ...      ...      ...      ...      ...     ...      ...   \n",
      "10778      0.0      0.0      0.0      0.0      0.0      0.0     0.0      0.0   \n",
      "10779      0.0      0.0      0.0      0.0      0.0      0.0     0.0      0.0   \n",
      "10780      0.0      0.0      0.0      0.0      0.0      0.0     0.0      0.0   \n",
      "10781      0.0      0.0      0.0      0.0      0.0      0.0     0.0      0.0   \n",
      "10782      0.0      0.0      0.0      0.0      0.0      0.0     0.0      0.0   \n",
      "\n",
      "       Name_2001  Name_2002  Name_2003  Name_2004  Name_2005  Name_2008  \\\n",
      "0            0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "1            0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "2            0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "3            0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "4            0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "...          ...        ...        ...        ...        ...        ...   \n",
      "10778        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "10779        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "10780        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "10781        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "10782        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "\n",
      "       Name_2009  Name_2010  Name_2011  ...  Name_wolfenstein  Name_wonder  \\\n",
      "0            0.0        0.0        0.0  ...               0.0          0.0   \n",
      "1            0.0        0.0        0.0  ...               0.0          0.0   \n",
      "2            0.0        0.0        0.0  ...               0.0          0.0   \n",
      "3            0.0        0.0        0.0  ...               0.0          0.0   \n",
      "4            0.0        0.0        0.0  ...               0.0          0.0   \n",
      "...          ...        ...        ...  ...               ...          ...   \n",
      "10778        0.0        0.0        0.0  ...               0.0          0.0   \n",
      "10779        0.0        0.0        0.0  ...               0.0          0.0   \n",
      "10780        0.0        0.0        0.0  ...               0.0          0.0   \n",
      "10781        0.0        0.0        0.0  ...               0.0          0.0   \n",
      "10782        0.0        0.0        0.0  ...               0.0          0.0   \n",
      "\n",
      "       Name_wood  Name_world  Name_worm  Name_wrath  Name_wrestl  Name_wwe  \\\n",
      "0            0.0    0.407746        0.0         0.0          0.0       0.0   \n",
      "1            0.0    0.000000        0.0         0.0          0.0       0.0   \n",
      "2            0.0    0.000000        0.0         0.0          0.0       0.0   \n",
      "3            0.0    0.000000        0.0         0.0          0.0       0.0   \n",
      "4            0.0    0.000000        0.0         0.0          0.0       0.0   \n",
      "...          ...         ...        ...         ...          ...       ...   \n",
      "10778        0.0    0.000000        0.0         0.0          0.0       0.0   \n",
      "10779        0.0    0.000000        0.0         0.0          0.0       0.0   \n",
      "10780        0.0    0.000000        0.0         0.0          0.0       0.0   \n",
      "10781        0.0    0.000000        0.0         0.0          0.0       0.0   \n",
      "10782        0.0    0.000000        0.0         0.0          0.0       0.0   \n",
      "\n",
      "       Name_wwii  Name_x  Name_x2  Name_xcom  Name_xiii  Name_xmen  \\\n",
      "0            0.0     0.0      0.0        0.0        0.0        0.0   \n",
      "1            0.0     0.0      0.0        0.0        0.0        0.0   \n",
      "2            0.0     0.0      0.0        0.0        0.0        0.0   \n",
      "3            0.0     0.0      0.0        0.0        0.0        0.0   \n",
      "4            0.0     0.0      0.0        0.0        0.0        0.0   \n",
      "...          ...     ...      ...        ...        ...        ...   \n",
      "10778        0.0     0.0      0.0        0.0        0.0        0.0   \n",
      "10779        0.0     0.0      0.0        0.0        0.0        0.0   \n",
      "10780        0.0     0.0      0.0        0.0        0.0        0.0   \n",
      "10781        0.0     0.0      0.0        0.0        0.0        0.0   \n",
      "10782        0.0     0.0      0.0        0.0        0.0        0.0   \n",
      "\n",
      "       Name_xtreme  Name_yakuza  Name_year  Name_ys  Name_yugioh  Name_z  \\\n",
      "0              0.0          0.0        0.0      0.0          0.0     0.0   \n",
      "1              0.0          0.0        0.0      0.0          0.0     0.0   \n",
      "2              0.0          0.0        0.0      0.0          0.0     0.0   \n",
      "3              0.0          0.0        0.0      0.0          0.0     0.0   \n",
      "4              0.0          0.0        0.0      0.0          0.0     0.0   \n",
      "...            ...          ...        ...      ...          ...     ...   \n",
      "10778          0.0          0.0        0.0      0.0          0.0     0.0   \n",
      "10779          0.0          0.0        0.0      0.0          0.0     0.0   \n",
      "10780          0.0          0.0        0.0      0.0          0.0     0.0   \n",
      "10781          0.0          0.0        0.0      0.0          0.0     0.0   \n",
      "10782          0.0          0.0        0.0      0.0          0.0     0.0   \n",
      "\n",
      "       Name_zelda  Name_zero  Name_zombi  Name_zone  Name_zoo  \n",
      "0             0.0        0.0         0.0        0.0       0.0  \n",
      "1             0.0        0.0         0.0        0.0       0.0  \n",
      "2             0.0        0.0         0.0        0.0       0.0  \n",
      "3             0.0        0.0         0.0        0.0       0.0  \n",
      "4             0.0        0.0         0.0        0.0       0.0  \n",
      "...           ...        ...         ...        ...       ...  \n",
      "10778         0.0        0.0         0.0        0.0       0.0  \n",
      "10779         0.0        0.0         0.0        0.0       0.0  \n",
      "10780         0.0        0.0         0.0        0.0       0.0  \n",
      "10781         0.0        0.0         0.0        0.0       0.0  \n",
      "10782         0.0        0.0         0.0        0.0       0.0  \n",
      "\n",
      "[10783 rows x 697 columns]\n",
      "      Name_007  Name_06  Name_07   Name_08  Name_09  Name_1  Name_10  Name_11  \\\n",
      "0          0.0      0.0      0.0  0.624997      0.0     0.0      0.0      0.0   \n",
      "1          0.0      0.0      0.0  0.000000      0.0     0.0      0.0      0.0   \n",
      "2          0.0      0.0      0.0  0.000000      0.0     0.0      0.0      0.0   \n",
      "3          0.0      0.0      0.0  0.000000      0.0     0.0      0.0      0.0   \n",
      "4          0.0      0.0      0.0  0.000000      0.0     0.0      0.0      0.0   \n",
      "...        ...      ...      ...       ...      ...     ...      ...      ...   \n",
      "3590       0.0      0.0      0.0  0.000000      0.0     0.0      0.0      0.0   \n",
      "3591       0.0      0.0      0.0  0.000000      0.0     0.0      0.0      0.0   \n",
      "3592       0.0      0.0      0.0  0.000000      0.0     0.0      0.0      0.0   \n",
      "3593       0.0      0.0      0.0  0.000000      0.0     0.0      0.0      0.0   \n",
      "3594       0.0      0.0      0.0  0.000000      0.0     0.0      0.0      0.0   \n",
      "\n",
      "      Name_12  Name_13  Name_14  Name_15  Name_18  Name_19    Name_2  Name_20  \\\n",
      "0         0.0      0.0      0.0      0.0      0.0      0.0  0.000000      0.0   \n",
      "1         0.0      0.0      0.0      0.0      0.0      0.0  0.000000      0.0   \n",
      "2         0.0      0.0      0.0      0.0      0.0      0.0  0.000000      0.0   \n",
      "3         0.0      0.0      0.0      0.0      0.0      0.0  0.000000      0.0   \n",
      "4         0.0      0.0      0.0      0.0      0.0      0.0  0.000000      0.0   \n",
      "...       ...      ...      ...      ...      ...      ...       ...      ...   \n",
      "3590      0.0      0.0      0.0      0.0      0.0      0.0  0.000000      0.0   \n",
      "3591      0.0      0.0      0.0      0.0      0.0      0.0  0.447687      0.0   \n",
      "3592      0.0      0.0      0.0      0.0      0.0      0.0  0.000000      0.0   \n",
      "3593      0.0      0.0      0.0      0.0      0.0      0.0  0.000000      0.0   \n",
      "3594      0.0      0.0      0.0      0.0      0.0      0.0  1.000000      0.0   \n",
      "\n",
      "      Name_2001  Name_2002  Name_2003  Name_2004  Name_2005  Name_2008  \\\n",
      "0           0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "1           0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "2           0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "3           0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "4           0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "3590        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "3591        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "3592        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "3593        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "3594        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "\n",
      "      Name_2009  Name_2010  Name_2011  ...  Name_wolfenstein  Name_wonder  \\\n",
      "0           0.0        0.0        0.0  ...               0.0          0.0   \n",
      "1           0.0        0.0        0.0  ...               0.0          0.0   \n",
      "2           0.0        0.0        0.0  ...               0.0          0.0   \n",
      "3           0.0        0.0        0.0  ...               0.0          0.0   \n",
      "4           0.0        0.0        0.0  ...               0.0          0.0   \n",
      "...         ...        ...        ...  ...               ...          ...   \n",
      "3590        0.0        0.0        0.0  ...               0.0          0.0   \n",
      "3591        0.0        0.0        0.0  ...               0.0          0.0   \n",
      "3592        0.0        0.0        0.0  ...               0.0          0.0   \n",
      "3593        0.0        0.0        0.0  ...               0.0          0.0   \n",
      "3594        0.0        0.0        0.0  ...               0.0          0.0   \n",
      "\n",
      "      Name_wood  Name_world  Name_worm  Name_wrath  Name_wrestl  Name_wwe  \\\n",
      "0           0.0         0.0        0.0         0.0          0.0       0.0   \n",
      "1           0.0         0.0        0.0         0.0          0.0       0.0   \n",
      "2           0.0         0.0        0.0         0.0          0.0       0.0   \n",
      "3           0.0         0.0        0.0         0.0          0.0       0.0   \n",
      "4           0.0         0.0        0.0         0.0          0.0       0.0   \n",
      "...         ...         ...        ...         ...          ...       ...   \n",
      "3590        0.0         0.0        0.0         0.0          0.0       0.0   \n",
      "3591        0.0         0.0        0.0         0.0          0.0       0.0   \n",
      "3592        0.0         0.0        0.0         0.0          0.0       0.0   \n",
      "3593        0.0         0.0        0.0         0.0          0.0       0.0   \n",
      "3594        0.0         0.0        0.0         0.0          0.0       0.0   \n",
      "\n",
      "      Name_wwii  Name_x  Name_x2  Name_xcom  Name_xiii  Name_xmen  \\\n",
      "0           0.0     0.0      0.0        0.0        0.0        0.0   \n",
      "1           0.0     0.0      0.0        0.0        0.0        0.0   \n",
      "2           0.0     0.0      0.0        0.0        0.0        0.0   \n",
      "3           0.0     0.0      0.0        0.0        0.0        0.0   \n",
      "4           0.0     0.0      0.0        0.0        0.0        0.0   \n",
      "...         ...     ...      ...        ...        ...        ...   \n",
      "3590        0.0     0.0      0.0        0.0        0.0        0.0   \n",
      "3591        0.0     0.0      0.0        0.0        0.0        0.0   \n",
      "3592        0.0     0.0      0.0        0.0        0.0        0.0   \n",
      "3593        0.0     0.0      0.0        0.0        0.0        0.0   \n",
      "3594        0.0     0.0      0.0        0.0        0.0        0.0   \n",
      "\n",
      "      Name_xtreme  Name_yakuza  Name_year  Name_ys  Name_yugioh  Name_z  \\\n",
      "0             0.0          0.0        0.0      0.0          0.0     0.0   \n",
      "1             0.0          0.0        0.0      0.0          0.0     0.0   \n",
      "2             0.0          0.0        0.0      0.0          0.0     0.0   \n",
      "3             0.0          0.0        0.0      0.0          0.0     0.0   \n",
      "4             0.0          0.0        0.0      0.0          0.0     0.0   \n",
      "...           ...          ...        ...      ...          ...     ...   \n",
      "3590          0.0          0.0        0.0      0.0          0.0     0.0   \n",
      "3591          0.0          0.0        0.0      0.0          0.0     0.0   \n",
      "3592          0.0          0.0        0.0      0.0          0.0     0.0   \n",
      "3593          0.0          0.0        0.0      0.0          0.0     0.0   \n",
      "3594          0.0          0.0        0.0      0.0          0.0     0.0   \n",
      "\n",
      "      Name_zelda  Name_zero  Name_zombi  Name_zone  Name_zoo  \n",
      "0            0.0        0.0         0.0        0.0       0.0  \n",
      "1            0.0        0.0         0.0        0.0       0.0  \n",
      "2            0.0        0.0         0.0        0.0       0.0  \n",
      "3            0.0        0.0         0.0        0.0       0.0  \n",
      "4            0.0        0.0         0.0        0.0       0.0  \n",
      "...          ...        ...         ...        ...       ...  \n",
      "3590         0.0        0.0         0.0        0.0       0.0  \n",
      "3591         0.0        0.0         0.0        0.0       0.0  \n",
      "3592         0.0        0.0         0.0        0.0       0.0  \n",
      "3593         0.0        0.0         0.0        0.0       0.0  \n",
      "3594         0.0        0.0         0.0        0.0       0.0  \n",
      "\n",
      "[3595 rows x 697 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABNYAAAHqCAYAAADI9cPOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACjKklEQVR4nOzdd3iN9//H8fexskhEQiJGEpskSO29EqNWqV1qVbW0iqhde9UerVJVs0ZtbVGzdlsUtUftWkUkZpC8f3/4nfubI0ZyiHMSz8d1nevKuc+dc973Gfe5z+v+DJOqqgAAAAAAAABIkBS2LgAAAAAAAABIigjWAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKBGsAAAAAAACAFQjWAAB2yWQyxevy22+/JWodly5dkr59+0qpUqXE09NTXF1dpUiRIvLtt99KdHR0nPVv374tnTt3Fh8fH3F0dJTChQvLggUL4vVYrVq1krRp08ZrXZPJJAMGDEjIphj8/PykVq1aVv2vtQ4fPiwDBgyQM2fOvNbHfZYBAwaIyWSy6n9nzpwpJpNJdu/e/cJ1J0+eLDNnzrTqcV7kZd4DtuTn5yetWrV66ftJyOtgjTNnzsR7P3TmzBn57bffnnl7gwYNXvh4T/v8V6xY0biPFClSSLp06SRXrlzSsGFDWbx4scTExMS5Hz8/v2fWcfv27Rdu76t8v7Zq1cri8R0cHCRv3rzSv39/uX//foLvLyGveatWrcTPz89imTXvPfO+4tq1awn6PwDAmyOVrQsAAOBpdu7caXF98ODBsmnTJtm4caPF8gIFCiRqHXv27JHZs2fL+++/L1988YWkTp1aVq9eLR9//LH8/vvv8v3331usX79+fdm1a5eMGDFC8uTJI/PmzZOmTZtKTEyMNGvW7JXVtXPnTsmaNesru7/EdvjwYRk4cKBUrFgxzo9dW/jggw+kevXqif44kydPFk9Pz1cSJOH1ypw5c5z9UIcOHSQiIkJ++OGHOOuaQ+Nhw4ZJpUqVLG738PCwuo4cOXIYj3fnzh05ffq0LF++XBo2bCjlypWTn376Sdzc3Cz+p0yZMjJ69Og49+Xs7PzMxzFvb86cOa2u9WmcnJyM/XZ4eLjMnz9fBg0aJEePHpWFCxe+0sd6kWXLlomrq+trfUwAQPJHsAYAsEslS5a0uJ4xY0ZJkSJFnOWJrUyZMvLPP/9I6tSpjWWhoaHy4MED+frrr2XgwIGSLVs2ERFZtWqVrFu3zgjTREQqVaokZ8+elc8//1waN24sKVOmfCV1ve7nIbnJmjVrkgomk5K7d+8+N8BJKhwcHOJ8zlxdXeXBgwfP/fzlzp37lX4+nZyc4tzfBx98IDNmzJA2bdrIhx9+GCegSp8+fYJreNr2vgpP7rdr1KghZ86ckR9//FHGjh0rWbJkeeWP+SzBwcGv7bESKrl8bgDgTURXUABAknXjxg3p0KGDZMmSRdKkSSM5cuSQPn36SFRUlMV6JpNJPvnkE5k6darkyZNHHBwcpECBAvHqounu7m4RqpkVL15cREQuXLhgLFu2bJmkTZtWGjZsaLFu69at5eLFi/LHH3/Ea7tOnjwpb7/9tqRNm1ayZcsmYWFhT92mJ7sBbtu2TUqVKiWOjo6SJUsW+eKLL+S7774zuqo9ac2aNfLWW2+Jk5OT5MuXL07rOxGRy5cvS/v27SVr1qySJk0a8ff3l4EDB8qjR48s1vvmm2+kUKFCkjZtWkmXLp3ky5dPevfuLSKPu2+Zn5NKlSoZ3cKe1eXs0KFDYjKZZNGiRcayPXv2iMlkkoCAAIt169SpI0WKFLFYtnDhQilVqpS4uLhI2rRppVq1arJ3716LdZ7WFTQqKkrCwsLE29tbnJ2dpXz58rJnz55ndh+7deuWfPzxx+Lp6SkeHh5Sv359uXjxonG7n5+fHDp0SDZv3mxsc+zWepGRkdKtWzfx9/eXNGnSSJYsWaRz585y584di8eJjIyUdu3aiYeHh6RNm1aqV68ux48ff+pzF5uqipeXl3Ts2NFYFh0dLe7u7pIiRQq5cuWKsXzs2LGSKlUquXnzprFs5cqVUqpUKXF2dpZ06dJJaGhonBZc5ufxr7/+kgYNGoi7u7vR4unhw4fSvXt34/ksW7as/Pnnn3HqvHv3rvE8ODo6SoYMGaRo0aIyf/78F26jyONWUK1bt5YMGTKIi4uL1K5dW06dOmXcPnjwYEmVKpWcP38+zv+2adNGPDw8rOqWaGutW7eWt99+WxYtWiRnz5596ft7WldQ8+t76NAhadq0qbi5uYmXl5e0adNGIiIirH4sc9BmrvtZ3Zqf9dl70Wv+LE/eX0xMjAwZMkTy5s0rTk5Okj59eilYsKBMmDAhzv9euXLlhc+BqsrkyZOlcOHC4uTkJO7u7tKgQYM4tVWsWFECAwNly5YtUrp0aXF2dpY2bdq8sH4AgH0iWAMAJEn379+XSpUqyezZs6Vr167yyy+/SPPmzWXkyJFSv379OOuvXLlSJk6cKIMGDZLFixeLr6+vNG3aVBYvXmzV42/cuFFSpUolefLkMZYdPHhQ8ufPL6lSWTYIL1iwoHH7izx8+FDq1KkjVapUkRUrVkibNm1k3Lhx8uWXXz73//7++28JDQ2Vu3fvyqxZs2TKlCny119/ydChQ5+6/v79+yUsLEy6dOkiK1askIIFC0rbtm1ly5YtxjqXL1+W4sWLy6+//ir9+vWT1atXS9u2bWX48OHSrl07Y70FCxZIhw4dpEKFCrJs2TJZvny5dOnSxQiIatasKcOGDRMRka+//lp27twpO3fulJo1az61toCAAMmcObOsX7/eWLZ+/XpxcnKSw4cPG+HVo0ePZPPmzRISEmKsN2zYMGnatKkUKFBAfvzxR5kzZ47cunVLypUrJ4cPH37uc9i6dWsZP368tG7dWlasWCHvvvuu1KtXzyJsiu2DDz6Q1KlTy7x582TkyJHy22+/SfPmzY3bly1bJjly5JDg4GBjm5ctWyYij8OkChUqyKxZs6RTp06yevVq6dGjh8ycOVPq1Kkjqioij3+ov/POOzJnzhwJCwuTZcuWScmSJaVGjRrP3RaRx2FF5cqVLZ7H3bt3y82bN8XR0VE2bNhg8fwWKVJE0qdPLyIi8+bNk7p164qrq6vMnz9fpk+fLuHh4VKxYkXZtm1bnMeqX7++5MqVSxYtWiRTpkwREZF27drJ6NGj5f333zeez/r160t4eLjF/3bt2lW++eYb6dSpk6xZs0bmzJkjDRs2lOvXr79wG0VE2rZtKylSpJB58+bJ+PHj5c8//5SKFSsar1v79u0lVapUMnXqVIv/u3HjhixYsEDatm0rjo6O8Xqs+IiJiZFHjx5ZXBKL+b2ydetWi+WqGqeGp43HFl/vvvuu5MmTR5YsWSI9e/aUefPmSZcuXay+v5MnT4rI45bI1njRax5fI0eOlAEDBkjTpk3ll19+kYULF0rbtm2fej/xeQ7at28vnTt3lpCQEFm+fLlMnjxZDh06JKVLl7YIskUej9/ZvHlzadasmaxatUo6dOiQ0KcBAGAvFACAJKBly5bq4uJiXJ8yZYqKiP74448W63355ZcqIrp27VpjmYiok5OTXr582Vj26NEjzZcvn+bKlSvBtfz666+aIkUK7dKli8Xy3Llza7Vq1eKsf/HiRRURHTZs2HPvt2XLlk/dprffflvz5s1rsUxEtH///sb1hg0bqouLi/7333/GsujoaC1QoICKiJ4+fdpY7uvrq46Ojnr27Flj2b179zRDhgzavn17Y1n79u01bdq0Fuupqo4ePVpFRA8dOqSqqp988ommT5/+udu2aNEiFRHdtGnTc9cza968uebIkcO4HhISou3atVN3d3edNWuWqqpu377d4rU+d+6cpkqVSj/99FOL+7p165Z6e3tro0aNjGX9+/fX2IdBhw4dUhHRHj16WPzv/PnzVUS0ZcuWxrIZM2aoiGiHDh0s1h05cqSKiF66dMlYFhAQoBUqVIizfcOHD9cUKVLorl27LJYvXrxYRURXrVqlqqqrV69WEdEJEyZYrDd06NA474Gn+e6771RE9Ny5c6qqOmTIEM2XL5/WqVNHW7duraqqDx48UBcXF+3du7eqPn7f+Pj4aFBQkEZHRxv3devWLc2UKZOWLl3aWGZ+Hvv162fxuEeOHFERifMZ+eGHH+I8n4GBgfrOO+88dzuexvw61KtXz2K5+X0xZMgQY1nLli01U6ZMGhUVZSz78ssvNUWKFBafjRepUKGCBgQEPPW2TZs2qYg89XLixIkX3veT+7gXPZ7q/94fX375pbHM19f3qTX06dPnuY9/+vRpFRGdMWOGscz8+o4cOdJi3Q4dOqijo6PGxMTEa5sePnyoDx8+1P/++08nTJigJpNJixUrZqz3rPeyr6/vUz978X3NfX19n3t/tWrV0sKFCz93G+L7HOzcuVNFRMeMGWOx3vnz59XJyUm7d+9uLKtQoYKKiG7YsOG5jw0ASBposQYASJI2btwoLi4ucWbbM3fzid0aR0SkSpUq4uXlZVxPmTKlNG7cWE6ePGnRnfNF/vrrL2nUqJGULFlShg8fHuf25800GZ9ZKE0mk9SuXdtiWcGCBV/Y1Wvz5s1SuXJl8fT0NJalSJFCGjVq9NT1CxcuLNmzZzeuOzo6Sp48eSwe5+eff5ZKlSqJj4+PRcsXc2upzZs3i8jjbrE3b96Upk2byooVK17J7HlVqlSRU6dOyenTp+X+/fuybds2qV69ulSqVEnWrVsnIo9bWTk4OEjZsmVFROTXX3+VR48eyfvvv29Rr6Ojo1SoUOG5M8iat+XJ56tBgwZxWiCa1alTx+K6uWVifLrl/fzzzxIYGCiFCxe2qLVatWoWs91u2rRJRETee+89i/+P70QY5tZ85lZr69atk9DQUAkJCTGex507d8qdO3eMdY8dOyYXL16UFi1aSIoU/ztUTJs2rbz77rvy+++/y927dy0e591337W4/qy6GzVqFOf5LF68uKxevVp69uwpv/32m9y7dy9e22b25GOULl1afH19jRpERD777DO5evWq0b04JiZGvvnmG6lZs+Yrn0zjyy+/lF27dllczOMwPtma7WkzCyeE/n/LxieVLVs2Tg0v0yLqae/1+/fvy9WrV1/4v3fu3JHUqVNL6tSpJWPGjNK5c2epUaOG0XrTGvF5zeOjePHisn//funQoYP8+uuvEhkZ+cx1X/Qc/Pzzz2IymaR58+YWr7G3t7cUKlQozv7H3d1dKleunKB6AQD2ickLAABJ0vXr18Xb2ztOWJUpUyZJlSpVnG5k3t7ece7DvOz69evxGsh+7969EhoaKrlz55ZVq1aJg4ODxe0eHh5P7b5248YNERHJkCHDCx/D2dk5Trc0BweHF44Bdf36dYvg0Oxpy8y1PsnBwcEi1Lhy5Yr89NNPTx1jTkSMAK1Fixby6NEjmTZtmrz77rsSExMjxYoVkyFDhkhoaOhz636W2IGQv7+/PHz4UCpXrixXrlyRwYMHG7eVKVNGnJycjHpFRIoVK/bU+4wdEj3J/Lo9+XylSpXqmTM6Prnc/H6ITzB05coVOXny5Auf2+vXrz+1hqe9n5/G19dXcubMKevXr5fGjRvLzp07JSwsTHLlyiWdOnWSY8eOGd1sS5cubTymyONZIp/k4+MjMTExEh4ebjHQ+pPrmu/jyTqfti0TJ06UrFmzysKFC+XLL78UR0dHqVatmowaNUpy5879wm181mc79mcxODhYypUrJ19//bW899578vPPP8uZM2fidA99FXLkyCFFixZ96m2DBg2SgQMHGtd9fX2fOv5hfJlDXB8fH4vlbm5uz6zBGi/zXndycjK6mDs4OIivr+9Lz8wZn9c8Pnr16iUuLi4yd+5cmTJliqRMmVLKly8vX375ZZzn70XPwZUrV4xxDZ8mR44cFtef9vkCACRNBGsAgCTJw8ND/vjjD1FVi3Dt6tWr8ujRI4uWWyKPxwt7knnZs4KT2Pbu3SshISHi6+sra9euFTc3tzjrBAUFyfz58+XRo0cWrXIOHDggIiKBgYHx2zgreHh4xBnDR+Tp2x1fnp6eUrBgwWeO0xb7x3zr1q2ldevWcufOHdmyZYv0799fatWqJcePHxdfX98EP3bWrFklT548sn79evHz85OiRYtK+vTppUqVKtKhQwf5448/5Pfff7cIKcyvuXkMvYQwvweuXLliMUvho0ePEvxjPT48PT3FycnpqRNGmG8312WuIfb7NCGvq3m8vs2bN0tMTIxUrFhR0qVLJz4+PrJu3TpZv369lCtXzggKzI9z6dKlOPd18eJFSZEihbi7u1ssfzLgNt/H5cuXX/h8uri4yMCBA2XgwIFy5coVo/Va7dq15ejRoy/cvmd9tnPlymWxrFOnTtKwYUP566+/5KuvvpI8efJYHfxa68MPP5RatWoZ158M5xNq5cqVYjKZpHz58i9bWqJJkSLFC0M+BweHOBO0iMgzP3vxfc1fJFWqVNK1a1fp2rWr3Lx5U9avXy+9e/eWatWqyfnz5xM0S6enp6eYTCbZunXrU1/XJ5fFpwUzACBpoCsoACBJqlKlity+fVuWL19usXz27NnG7bFt2LDBIniKjo6WhQsXSs6cOV/YWm3fvn0SEhIiWbNmlXXr1sUJFczq1asnt2/fliVLllgsnzVrlvj4+EiJEiXiu3kJVqFCBdm4caNFN8yYmBiLmTUTqlatWnLw4EHJmTOnFC1aNM7lyVYyIo9Dkho1akifPn3kwYMHcujQIRFJWAsXs5CQENm4caPRfVFEJE+ePJI9e3bp16+fPHz40GLigmrVqkmqVKnkn3/+eWq9z/txbw4mFi5caLF88eLFLzX4/JOtAM1q1aol//zzj3h4eDy1TnP3xEqVKomIyA8//GDx//PmzYt3DSEhIXLlyhUZP368lCxZUtKlSycijz8jy5Ytk127dlk8j3nz5pUsWbLIvHnzLLoa3rlzR5YsWWLMFPo8FStWfGrdP/7443OfTy8vL2nVqpU0bdpUjh07FqfL6dM8+Rg7duyQs2fPGjWY1atXT7Jnzy5hYWGyfv166dChw2sPN3x8fCxe56CgIKvva8aMGbJ69Wpp2rSpRbfupMjPz0/+/vtvi2UbN26U27dvP3X9+L7mCZE+fXpp0KCBdOzYUW7cuJHgloS1atUSVZV///33qZ/pl3mtAQD2jRZrAIAk6f3335evv/5aWrZsKWfOnJGgoCDZtm2bDBs2TN5++22LoEDkcWuCypUryxdffCEuLi4yefJkOXr0qCxYsOC5j3Ps2DHjvoYOHSonTpyQEydOGLfnzJnTmNmuRo0aEhoaKh9//LFERkZKrly5ZP78+bJmzRqZO3eupEyZ8hU/C//Tp08f+emnn6RKlSrSp08fcXJykilTphgzcz6vG+SzDBo0SNatWyelS5eWTp06Sd68eeX+/fty5swZWbVqlUyZMkWyZs0q7dq1EycnJylTpoxkzpxZLl++LMOHDxc3NzejW6a5td63334r6dKlE0dHR/H3939ua8EqVarI5MmT5dq1azJ+/HiL5TNmzBB3d3cpUqSIsdzPz08GDRokffr0kVOnTkn16tXF3d1drly5In/++afRMuppAgICpGnTpjJmzBhJmTKlVK5cWQ4dOiRjxowRNzc3q54/kcetGBcsWCALFy6UHDlyiKOjowQFBUnnzp1lyZIlUr58eenSpYsULFhQYmJi5Ny5c7J27VoJCwuTEiVKSNWqVaV8+fLSvXt3uXPnjhQtWlS2b98uc+bMiXcNlStXFpPJJGvXrrXY/pCQEGnZsqXxt1mKFClk5MiR8t5770mtWrWkffv2EhUVJaNGjZKbN2/KiBEjXviY+fPnl+bNm8v48eMlderUEhISIgcPHpTRo0fH6QZYokQJqVWrlhQsWFDc3d3lyJEjMmfOnHgFeCKPZzr94IMPpGHDhnL+/Hnp06ePZMmSJc6YYilTppSOHTtKjx49xMXFxRiP0d7du3dPfv/9d+PvU6dOyfLly+Xnn3+WChUqGLOwJmUtWrSQL774Qvr16ycVKlSQw4cPy1dfffXUlsEi8X/NX6R27doSGBgoRYsWlYwZM8rZs2dl/Pjx4uvrG69uyLGVKVNGPvzwQ2ndurXs3r1bypcvLy4uLnLp0iXZtm2bBAUFyccff5yg+wQAJA0EawCAJMnR0VE2bdokffr0kVGjRsl///0nWbJkkW7dukn//v3jrF+nTh0JCAiQvn37yrlz5yRnzpzyww8/SOPGjZ/7ODt37jS6Iz05qYDI41YjsX+gL126VPr06SP9+vWTGzduSL58+WT+/PnSpEmTl9vgFyhUqJCsW7dOunXrJu+//764u7tLixYtpEKFCtKjR49n/kB9nsyZM8vu3btl8ODBMmrUKLlw4YKkS5dO/P39jdBKRKRcuXIyc+ZM+fHHHyU8PFw8PT2lbNmyMnv2bCN09Pf3l/Hjx8uECROkYsWKEh0dHee5e1LlypUlRYoU4uTkJKVKlTKWh4SEyIwZM6RSpUpxAq9evXpJgQIFZMKECTJ//nyJiooSb29vKVasmHz00UfP3d4ZM2ZI5syZZfr06TJu3DgpXLiw/Pjjj1K9enVJnz59gp8/EZGBAwfKpUuXpF27dnLr1i1jTC0XFxfZunWrjBgxQr799ls5ffq0ODk5Sfbs2SUkJMRosZYiRQpZuXKldO3aVUaOHCkPHjyQMmXKyKpVqyRfvnzxqsHDw0MKFy5sdGc2M/9tvj22Zs2aiYuLiwwfPlwaN24sKVOmlJIlS8qmTZuMsdheZPr06eLl5SUzZ86UiRMnSuHChWXJkiVxPguVK1eWlStXyrhx4+Tu3buSJUsWef/996VPnz7xfpw5c+ZIkyZNJCoqSipVqiQTJkx46piGjRs3lh49ekiLFi2s+kzYwqlTp4z3v4uLi3h5eclbb70lixYtkvr161sd+tqTzz//XCIjI2XmzJkyevRoKV68uPz4449St27dp66fkNf8eSpVqiRLliyR7777TiIjI8Xb21tCQ0Pliy++eOb4h88zdepUKVmypEydOlUmT54sMTEx4uPjI2XKlJHixYsn+P4AAEmDSZ81nRAAAMmEyWSSjh07yldffWXrUl67qlWrypkzZ+T48eO2LiVJ2rFjh5QpU0Z++OGHeM/ECfs1adIk6dSpkxw8eFACAgJsXQ4AAEgGaLEGAEAy0bVrVwkODpZs2bLJjRs35IcffpB169bJ9OnTbV1akrBu3TrZuXOnFClSRJycnGT//v0yYsQIyZ07t9SvX9/W5eEl7N27V06fPi2DBg2SunXrEqoBAIBXhmANAIBkIjo6Wvr16yeXL18Wk8kkBQoUkDlz5kjz5s1tXVqS4OrqKmvXrpXx48fLrVu3xNPTU2rUqCHDhw8XR0dHW5eHl1CvXj25fPmylCtXLlmMSQYAAOwHXUEBAAAAAAAAKyT90U4BAAAAAAAAGyBYAwAAAAAAAKxAsAYAAAAAAABYgckLRCQmJkYuXrwo6dKlE5PJZOtyAAAAAAAAYCOqKrdu3RIfHx9JkeIFbdLUhvr3768iYnHx8vIybo+JidH+/ftr5syZ1dHRUStUqKAHDx60uI/79+/rJ598oh4eHurs7Ky1a9fW8+fPJ6iO8+fPx6mDCxcuXLhw4cKFCxcuXLhw4cKFy5t7iU++ZPMWawEBAbJ+/XrjesqUKY2/R44cKWPHjpWZM2dKnjx5ZMiQIRIaGirHjh2TdOnSiYhI586d5aeffpIFCxaIh4eHhIWFSa1atWTPnj0W9/U85vs6f/68uLq6vsKtAwAAAAAAQFISGRkp2bJlM/Ki57F5sJYqVSrx9vaOs1xVZfz48dKnTx+pX7++iIjMmjVLvLy8ZN68edK+fXuJiIiQ6dOny5w5cyQkJERERObOnSvZsmWT9evXS7Vq1eJVg7n7p6urK8EaAAAAAAAA4jVcmM0nLzhx4oT4+PiIv7+/NGnSRE6dOiUiIqdPn5bLly9L1apVjXUdHBykQoUKsmPHDhER2bNnjzx8+NBiHR8fHwkMDDTWeZqoqCiJjIy0uAAAAAAAAAAJYdNgrUSJEjJ79mz59ddfZdq0aXL58mUpXbq0XL9+XS5fviwiIl5eXhb/4+XlZdx2+fJlSZMmjbi7uz9znacZPny4uLm5GZds2bK94i0DAAAAAABAcmfTYK1GjRry7rvvSlBQkISEhMgvv/wiIo+7fJo92exOVV/YFO9F6/Tq1UsiIiKMy/nz519iKwAAAAAAAPAmsnlX0NhcXFwkKChITpw4YYy79mTLs6tXrxqt2Ly9veXBgwcSHh7+zHWexsHBwRhPjXHVAAAAAAAAYA27CtaioqLkyJEjkjlzZvH39xdvb29Zt26dcfuDBw9k8+bNUrp0aRERKVKkiKROndpinUuXLsnBgweNdQAAAAAAAIDEYNNZQbt16ya1a9eW7Nmzy9WrV2XIkCESGRkpLVu2FJPJJJ07d5Zhw4ZJ7ty5JXfu3DJs2DBxdnaWZs2aiYiIm5ubtG3bVsLCwsTDw0MyZMgg3bp1M7qWAgAAAAAAAInFpsHahQsXpGnTpnLt2jXJmDGjlCxZUn7//Xfx9fUVEZHu3bvLvXv3pEOHDhIeHi4lSpSQtWvXSrp06Yz7GDdunKRKlUoaNWok9+7dkypVqsjMmTMlZcqUttosAAAAAAAAvAFMqqq2LsLWIiMjxc3NTSIiIhhvDQAAAAAA4A2WkJzIrsZYAwAAAAAAAJIKgjUAAAAAAADACgRrAAAAAAAAgBUI1gAAAAAAAAArEKwBAAAAAAAAViBYAwAAAAAAAKxAsAYAAAAAAABYIZWtC0jq/Hr+8tof88yImq/9MQEAAAAAAGCJFmsAAAAAAACAFQjWAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKBGsAAAAAAACAFQjWAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFghla0LQNLh1/OX1/6YZ0bUfO2PCQAAAAAAEB+0WAMAAAAAAACsQLAGAAAAAAAAWIFgDQAAAAAAALACwRoAAAAAAABgBYI1AAAAAAAAwAoEawAAAAAAAIAVCNYAAAAAAAAAKxCsAQAAAAAAAFZIZesCAHvj1/OX1/6YZ0bUfO2PCQAAAAAAXg4t1gAAAAAAAAArEKwBAAAAAAAAViBYAwAAAAAAAKxAsAYAAAAAAABYgWANAAAAAAAAsALBGgAAAAAAAGAFgjUAAAAAAADACgRrAAAAAAAAgBUI1gAAAAAAAAArEKwBAAAAAAAAViBYAwAAAAAAAKxAsAYAAAAAAABYgWANAAAAAAAAsALBGgAAAAAAAGAFgjUAAAAAAADACgRrAAAAAAAAgBUI1gAAAAAAAAArEKwBAAAAAAAAViBYAwAAAAAAAKxAsAYAAAAAAABYgWANAAAAAAAAsALBGgAAAAAAAGAFgjUAAAAAAADACgRrAAAAAAAAgBUI1gAAAAAAAAArEKwBAAAAAAAAViBYAwAAAAAAAKxAsAYAAAAAAABYgWANAAAAAAAAsALBGgAAAAAAAGAFgjUAAAAAAADACgRrAAAAAAAAgBVS2boAALbh1/OX1/6YZ0bUfO2PCQAAAABAYqHFGgAAAAAAAGAFuwnWhg8fLiaTSTp37mwsU1UZMGCA+Pj4iJOTk1SsWFEOHTpk8X9RUVHy6aefiqenp7i4uEidOnXkwoULr7l6AAAAAAAAvGnsIljbtWuXfPvtt1KwYEGL5SNHjpSxY8fKV199Jbt27RJvb28JDQ2VW7duGet07txZli1bJgsWLJBt27bJ7du3pVatWhIdHf26NwMAAAAAAABvEJsHa7dv35b33ntPpk2bJu7u7sZyVZXx48dLnz59pH79+hIYGCizZs2Su3fvyrx580REJCIiQqZPny5jxoyRkJAQCQ4Olrlz58qBAwdk/fr1ttokAAAAAAAAvAFsHqx17NhRatasKSEhIRbLT58+LZcvX5aqVasayxwcHKRChQqyY8cOERHZs2ePPHz40GIdHx8fCQwMNNZ5mqioKImMjLS4AAAAAAAAAAlh01lBFyxYIH/99Zfs2rUrzm2XL18WEREvLy+L5V5eXnL27FljnTRp0li0dDOvY/7/pxk+fLgMHDjwZcsHAAAAAADAG8xmLdbOnz8vn332mcydO1ccHR2fuZ7JZLK4rqpxlj3pRev06tVLIiIijMv58+cTVjwAAAAAAADeeDYL1vbs2SNXr16VIkWKSKpUqSRVqlSyefNmmThxoqRKlcpoqfZky7OrV68at3l7e8uDBw8kPDz8mes8jYODg7i6ulpcAAAAAAAAgISwWbBWpUoVOXDggOzbt8+4FC1aVN577z3Zt2+f5MiRQ7y9vWXdunXG/zx48EA2b94spUuXFhGRIkWKSOrUqS3WuXTpkhw8eNBYBwAAAAAAAEgMNhtjLV26dBIYGGixzMXFRTw8PIzlnTt3lmHDhknu3Lkld+7cMmzYMHF2dpZmzZqJiIibm5u0bdtWwsLCxMPDQzJkyCDdunWToKCgOJMhAAAAAAAAAK+STScveJHu3bvLvXv3pEOHDhIeHi4lSpSQtWvXSrp06Yx1xo0bJ6lSpZJGjRrJvXv3pEqVKjJz5kxJmTKlDSsHAAAAAABAcmdXwdpvv/1mcd1kMsmAAQNkwIABz/wfR0dHmTRpkkyaNClxiwMAAAAAAABisdkYawAAAAAAAEBSRrAGAAAAAAAAWIFgDQAAAAAAALACwRoAAAAAAABgBYI1AAAAAAAAwAoEawAAAAAAAIAVCNYAAAAAAAAAKxCsAQAAAAAAAFYgWAMAAAAAAACsQLAGAAAAAAAAWIFgDQAAAAAAALACwRoAAAAAAABgBYI1AAAAAAAAwAoEawAAAAAAAIAVCNYAAAAAAAAAKxCsAQAAAAAAAFYgWAMAAAAAAACsQLAGAAAAAAAAWIFgDQAAAAAAALACwRoAAAAAAABgBYI1AAAAAAAAwAoEawAAAAAAAIAVCNYAAAAAAAAAK6SydQEAkJj8ev7y2h/zzIiar/0xAQAAAACvHy3WAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKBGsAAAAAAACAFQjWAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKBGsAAAAAAACAFRIcrG3ZskUePXoUZ/mjR49ky5Ytr6QoAAAAAAAAwN4lOFirVKmS3LhxI87yiIgIqVSp0ispCgAAAAAAALB3qRL6D6oqJpMpzvLr16+Li4vLKykKAJAwfj1/ee2PeWZEzdf+mAAAAABgT+IdrNWvX19EREwmk7Rq1UocHByM26Kjo+Xvv/+W0qVLv/oKAQAAAAAAADsU72DNzc1NRB63WEuXLp04OTkZt6VJk0ZKliwp7dq1e/UVAgDw/2iZBwAAAMCexDtYmzFjhoiI+Pn5Sbdu3ej2CQBAIiFABAAAAJKGBI+x1r9//8SoAwAAAAAAAEhSEjwr6JUrV6RFixbi4+MjqVKlkpQpU1pcAAAAAAAAgDdBglustWrVSs6dOydffPGFZM6c+akzhAIAAAAAAADJXYKDtW3btsnWrVulcOHCiVAOAAAAAAAAkDQkuCtotmzZRFUToxYAAAAAAAAgyUhwsDZ+/Hjp2bOnnDlzJhHKAQAAAAAAAJKGeHUFdXd3txhL7c6dO5IzZ05xdnaW1KlTW6x748aNV1shAAAAAAAAYIfiFayNHz8+kcsAAAAAAAAAkpZ4BWstW7ZM7DoAAAAAAACAJCXBs4JGRkY+dbnJZBIHBwdJkybNSxcFAAAAAAAA2LsEB2vp06e3GG/tSVmzZpVWrVpJ//79JUWKBM+NAAAAAAAAACQJCQ7WZs6cKX369JFWrVpJ8eLFRVVl165dMmvWLOnbt6/8999/Mnr0aHFwcJDevXsnRs0AAAAAAACAzSU4WJs1a5aMGTNGGjVqZCyrU6eOBAUFydSpU2XDhg2SPXt2GTp0KMEaAAAAAAAAkq0E99XcuXOnBAcHx1keHBwsO3fuFBGRsmXLyrlz516+OgAAAAAAAMBOJThYy5o1q0yfPj3O8unTp0u2bNlEROT69evi7u7+8tUBAAAAAAAAdirBXUFHjx4tDRs2lNWrV0uxYsXEZDLJrl275OjRo7J48WIREdm1a5c0btz4lRcLAAAAAAAA2IsEB2t16tSRY8eOyZQpU+T48eOiqlKjRg1Zvny5+Pn5iYjIxx9//KrrBAAAAAAAAOxKgoM1ERE/Pz8ZMWLEq64FAAAAAAAASDLiFaz9/fffEhgYKClSpJC///77uesWLFjwlRQGAAAAAAAA2LN4TV5QuHBhuXbtmvF3cHCwFC5cOM7labOFPs8333wjBQsWFFdXV3F1dZVSpUrJ6tWrjdtVVQYMGCA+Pj7i5OQkFStWlEOHDlncR1RUlHz66afi6ekpLi4uUqdOHblw4UKC6gAAAAAAAAASKl4t1k6fPi0ZM2Y0/n5VsmbNKiNGjJBcuXKJiMisWbOkbt26snfvXgkICJCRI0fK2LFjZebMmZInTx4ZMmSIhIaGyrFjxyRdunQiItK5c2f56aefZMGCBeLh4SFhYWFSq1Yt2bNnj6RMmfKV1QoAAAAAAADEFq9gzdfX96l/v6zatWtbXB86dKh888038vvvv0uBAgVk/Pjx0qdPH6lfv76IPA7evLy8ZN68edK+fXuJiIiQ6dOny5w5cyQkJERERObOnSvZsmWT9evXS7Vq1V5ZrQAAAAAAAEBs8eoK+qQ5c+ZImTJlxMfHR86ePSsiIuPHj5cVK1ZYXUh0dLQsWLBA7ty5I6VKlZLTp0/L5cuXpWrVqsY6Dg4OUqFCBdmxY4eIiOzZs0cePnxosY6Pj48EBgYa6zxNVFSUREZGWlwAAAAAAACAhEhwsPbNN99I165d5e2335abN29KdHS0iIikT59exo8fn+ACDhw4IGnTphUHBwf56KOPZNmyZVKgQAG5fPmyiIh4eXlZrO/l5WXcdvnyZUmTJo24u7s/c52nGT58uLi5uRmXbNmyJbhuAAAAAAAAvNkSHKxNmjRJpk2bJn369LEYw6xo0aJy4MCBBBeQN29e2bdvn/z+++/y8ccfS8uWLeXw4cPG7SaTyWJ9VY2z7EkvWqdXr14SERFhXM6fP5/gugEAAAAAAPBmi9cYa7GdPn36qbN/Ojg4yJ07dxJcQJo0aYzJC4oWLSq7du2SCRMmSI8ePUTkcau0zJkzG+tfvXrVaMXm7e0tDx48kPDwcItWa1evXpXSpUs/8zEdHBzEwcEhwbUCAIBXx6/nL6/9Mc+MqPnaHxMAAADJV4JbrPn7+8u+ffviLF+9erUUKFDgpQtSVYmKihJ/f3/x9vaWdevWGbc9ePBANm/ebIRmRYoUkdSpU1usc+nSJTl48OBzgzUAAAAAAADgZSW4xdrnn38uHTt2lPv374uqyp9//inz58+X4cOHy3fffZeg++rdu7fUqFFDsmXLJrdu3ZIFCxbIb7/9JmvWrBGTySSdO3eWYcOGSe7cuSV37twybNgwcXZ2lmbNmomIiJubm7Rt21bCwsLEw8NDMmTIIN26dZOgoCBjllAAAAAAAAAgMSQ4WGvdurU8evRIunfvLnfv3pVmzZpJlixZZMKECdKkSZME3deVK1ekRYsWcunSJXFzc5OCBQvKmjVrJDQ0VEREunfvLvfu3ZMOHTpIeHi4lChRQtauXSvp0qUz7mPcuHGSKlUqadSokdy7d0+qVKkiM2fOtBj/DQAAAAAAAHjVEhysiYi0a9dO2rVrJ9euXZOYmBjJlCmTVQ8+ffr0595uMplkwIABMmDAgGeu4+joKJMmTZJJkyZZVQMAAAAAAABgjQSPsTZt2jQ5ceKEiIh4enpaHaoBAAAAAAAASVmCg7UxY8ZI3rx5xcfHR5o2bSpTp06Vo0ePJkZtAAAAAAAAgN1KcFfQo0ePyuXLl2XTpk2yefNmGTdunHTo0EEyZswoFStWlAULFiRGnQAAAEmWX89fXvtjnhlR87U/JgAAwJvGqjHWvL29pWnTplKnTh3Ztm2bLFiwQObOnSuLFy9+1fUBAAAAAAAAdinBwdrq1atl8+bN8ttvv8n+/fslICBAypcvL0uWLJFy5colRo0AAAAAAACA3UlwsFazZk3JmDGjhIWFya+//ipubm6JURcAAAAAAABg1xI8ecHYsWOlTJkyMmrUKMmbN680btxYvvnmGzly5Ehi1AcAAAAAAADYpQQHa507d5alS5fKf//9J+vWrZNy5crJ+vXrpVChQpI5c+bEqBEAAAAAAACwO1ZNXiAisnfvXvntt99k06ZNsnXrVomJiZGsWbO+ytoAAAAAAAAAu5XgFmt16tSRDBkySLFixeSHH36QPHnyyJw5c+TGjRuya9euxKgRAAAAAAAAsDsJbrGWJ08e+fDDD6V8+fLi6uqaGDUBAAAAAAAAdi/Bwdro0aMTow4AAAAAAAAgSUlwV1AAAAAAAAAABGsAAAAAAACAVQjWAAAAAAAAACsQrAEAAAAAAABWiHew1q9fP7l7965xPTw8PFEKAgAAAAAAAJKCeM8KOnToUPnkk0/E2dlZRER8fX1l3759kiNHjkQrDgAAAEmHX89fXvtjnhlR87U/JgAAgFm8W6yp6nOvAwAAAAAAAG8SxlgDAAAAAAAArBDvrqAmk0lu3boljo6OoqpiMpnk9u3bEhkZabGeq6vrKy8SAAAAAAAAsDfxDtZUVfLkyWNxPTg42OK6yWSS6OjoV1shAAAAAAAAYIfiHaxt2rQpMesAAAAAAAAAkpR4B2sVKlRIzDoAAAAAAACAJCXewZpZRESErFu3Ts6cOSMmk0n8/f0lJCSEsdUAAAAAAADwRklQsDZ37lz55JNP4kxY4ObmJlOmTJHGjRu/0uIAAAAAAAAAe5Uiviv+9ddf0rp1a3nnnXdk7969cu/ePbl7967s3r1bateuLS1atJD9+/cnZq0AAAAAAACA3Yh3i7VJkybJO++8IzNnzrRY/tZbb8ns2bPl7t27MmHCBPn+++9fdY0AAAAAAACA3Yl3i7Xt27dL+/btn3n7Rx99JNu2bXslRQEAAAAAAAD2Lt7B2sWLFyVPnjzPvD1Pnjzy77//vpKiAAAAAAAAAHsX72Dt7t274ujo+MzbHRwc5P79+6+kKAAAAAAAAMDeJWhW0F9//VXc3NyeetvNmzdfRT0AAAAAAABAkpCgYK1ly5bPvd1kMr1UMQAAAAAAAEBSEe9gLSYmJjHrAAAAAJIEv56/vPbHPDOi5mt/TAAA8GIJarEGAAAA4M1AgAgAwIvFO1hbuXJlvNarU6eO1cUAAAAAAAAASUW8g7V33nnnheuYTCaJjo5+mXoAAAAAAACAJIEx1gAAAAAAAAArpLB1AQAAAAAAAEBS9FLBmqurq5w6depV1QIAAAAAAAAkGS8VrKnqq6oDAAAAAAAASFLoCgoAAAAAAABYId6TFzxN8+bNxdXV9VXVAgAAAACvlV/PX177Y54ZUfO1PyYAIHG8VLD2zTffvKo6AAAAAAAAgCQl3l1Bs2fPLtevXzeuf/XVVxIZGZkoRQEAAAAAAAD2Lt7B2oULFyQ6Otq43rt3b7l27VqiFAUAAAAAAADYO6snL2BGUAAAAAAAALzJmBUUAAAAAAAAsEKCJi/47rvvJG3atCIi8ujRI5k5c6Z4enparNOpU6dXVx0AAAAAAABgp+IdrGXPnl2mTZtmXPf29pY5c+ZYrGMymQjWAAAAAAAA8EaId7B25syZRCwDAAAAAAAASFriPcZa5cqV5ebNm4lYCgAAAAAAAJB0xDtY++233+TBgweJWQsAAAAAAACQZDArKAAAAAAAAGCFBM0KeuvWLXF0dHzuOq6uri9VEAAAAAAAAJAUJChYy5MnzzNvU1UxmUwSHR390kUBAAAAAAAA9i5BwdrixYslQ4YMiVULAAAAAAAAkGQkKFgrU6aMZMqUKbFqAQAAAAAAAJIMJi8AAAAAAAAArBDvYM3X11dSpkyZmLUAAAAAAAAASUa8u4KePn06MesAAAAAAAAAkhS6ggIAAAAAAABWSNDkBQAAAACApMev5y+v/THPjKj52h8TAF43WqwBAAAAAAAAViBYAwAAAAAAAKwQr66gEydOjPcddurUKd7rDh8+XJYuXSpHjx4VJycnKV26tHz55ZeSN29eYx1VlYEDB8q3334r4eHhUqJECfn6668lICDAWCcqKkq6desm8+fPl3v37kmVKlVk8uTJkjVr1njXAgAAAAAAACREvIK1cePGxevOTCZTgoK1zZs3S8eOHaVYsWLy6NEj6dOnj1StWlUOHz4sLi4uIiIycuRIGTt2rMycOVPy5MkjQ4YMkdDQUDl27JikS5dOREQ6d+4sP/30kyxYsEA8PDwkLCxMatWqJXv27JGUKVPGux4AAAAAAAAgvuIVrJ0+fTpRHnzNmjUW12fMmCGZMmWSPXv2SPny5UVVZfz48dKnTx+pX7++iIjMmjVLvLy8ZN68edK+fXuJiIiQ6dOny5w5cyQkJERERObOnSvZsmWT9evXS7Vq1RKldgAAAAAAALzZ7GqMtYiICBERyZAhg4g8DvQuX74sVatWNdZxcHCQChUqyI4dO0REZM+ePfLw4UOLdXx8fCQwMNBY50lRUVESGRlpcQEAAAAAAAASIl4t1p504cIFWblypZw7d04ePHhgcdvYsWOtKkRVpWvXrlK2bFkJDAwUEZHLly+LiIiXl5fFul5eXnL27FljnTRp0oi7u3ucdcz//6Thw4fLwIEDraoTAAAAAAAAELEiWNuwYYPUqVNH/P395dixYxIYGChnzpwRVZW33nrL6kI++eQT+fvvv2Xbtm1xbjOZTBbXVTXOsic9b51evXpJ165djeuRkZGSLVs2K6oGAAAAAADAmyrBXUF79eolYWFhcvDgQXF0dJQlS5bI+fPnpUKFCtKwYUOrivj0009l5cqVsmnTJouZPL29vUVE4rQ8u3r1qtGKzdvbWx48eCDh4eHPXOdJDg4O4urqanEBAAAAAAAAEiLBwdqRI0ekZcuWIiKSKlUquXfvnqRNm1YGDRokX375ZYLuS1Xlk08+kaVLl8rGjRvF39/f4nZ/f3/x9vaWdevWGcsePHggmzdvltKlS4uISJEiRSR16tQW61y6dEkOHjxorAMAAAAAAAC8agnuCuri4iJRUVEi8niSgH/++UcCAgJEROTatWsJuq+OHTvKvHnzZMWKFZIuXTqjZZqbm5s4OTmJyWSSzp07y7BhwyR37tySO3duGTZsmDg7O0uzZs2Mddu2bSthYWHi4eEhGTJkkG7duklQUJAxSygAAAAAAADwqiU4WCtZsqRs375dChQoIDVr1pSwsDA5cOCALF26VEqWLJmg+/rmm29ERKRixYoWy2fMmCGtWrUSEZHu3bvLvXv3pEOHDhIeHi4lSpSQtWvXSrp06Yz1x40bJ6lSpZJGjRrJvXv3pEqVKjJz5kxJmTJlQjcPAAAAAAAAiJcEB2tjx46V27dvi4jIgAED5Pbt27Jw4ULJlSuXjBs3LkH3paovXMdkMsmAAQNkwIABz1zH0dFRJk2aJJMmTUrQ4wMAAAAAAADWSnCwliNHDuNvZ2dnmTx58istCAAAAAAAAEgKEjx5QY4cOeT69etxlt+8edMidAMAAAAAAACSswQHa2fOnJHo6Og4y6OiouTff/99JUUBAAAAAAAA9i7eXUFXrlxp/P3rr7+Km5ubcT06Olo2bNggfn5+r7Q4AAAAAAAAwF7FO1h75513ROTxZAItW7a0uC116tTi5+cnY8aMeaXFAQAAAAAQX349f3ntj3lmRM3X/pgA7Ee8g7WYmBgREfH395ddu3aJp6dnohUFAAAAAACejgARsB8JnhX09OnTiVEHAAAAAAAAkKQkePICEZHNmzdL7dq1JVeuXJI7d26pU6eObN269VXXBgAAAAAAANitBAdrc+fOlZCQEHF2dpZOnTrJJ598Ik5OTlKlShWZN29eYtQIAAAAAAAA2J0EdwUdOnSojBw5Urp06WIs++yzz2Ts2LEyePBgadas2SstEAAAAAAAALBHCW6xdurUKaldu3ac5XXq1GH8NQAAAAAAALwxEhysZcuWTTZs2BBn+YYNGyRbtmyvpCgAAAAAAADA3sW7K2ibNm1kwoQJEhYWJp06dZJ9+/ZJ6dKlxWQyybZt22TmzJkyYcKExKwVAAAAAAAAsBvxDtZmzZolI0aMkI8//li8vb1lzJgx8uOPP4qISP78+WXhwoVSt27dRCsUAAAAAAAAsCfxDtZU1fi7Xr16Uq9evUQpCAAAAAAAAEgKEjTGmslkSqw6AAAAAAAAgCQl3i3WRETy5MnzwnDtxo0bL1UQAAAAAACAiIhfz19e+2OeGVHztT8mkq4EBWsDBw4UNze3xKoFAAAAAAAASDISFKw1adJEMmXKlFi1AAAAAAAAAElGvMdYY3w1AAAAAAAA4H/iHazFnhUUAAAAAAAAeNPFuytoTExMYtYBAAAAAADwRnpTJmlIjtsZ7xZrAAAAAAAAAP6HYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKBGsAAAAAAACAFQjWAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKBGsAAAAAAACAFQjWAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKBGsAAAAAAACAFQjWAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKBGsAAAAAAACAFQjWAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKBGsAAAAAAACAFQjWAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKNg3WtmzZIrVr1xYfHx8xmUyyfPlyi9tVVQYMGCA+Pj7i5OQkFStWlEOHDlmsExUVJZ9++ql4enqKi4uL1KlTRy5cuPAatwIAAAAAAABvIpsGa3fu3JFChQrJV1999dTbR44cKWPHjpWvvvpKdu3aJd7e3hIaGiq3bt0y1uncubMsW7ZMFixYINu2bZPbt29LrVq1JDo6+nVtBgAAAAAAAN5AqWz54DVq1JAaNWo89TZVlfHjx0ufPn2kfv36IiIya9Ys8fLyknnz5kn79u0lIiJCpk+fLnPmzJGQkBAREZk7d65ky5ZN1q9fL9WqVXvqfUdFRUlUVJRxPTIy8hVvGQAAAAAAAJI7ux1j7fTp03L58mWpWrWqsczBwUEqVKggO3bsEBGRPXv2yMOHDy3W8fHxkcDAQGOdpxk+fLi4ubkZl2zZsiXehgAAAAAAACBZsttg7fLlyyIi4uXlZbHcy8vLuO3y5cuSJk0acXd3f+Y6T9OrVy+JiIgwLufPn3/F1QMAAAAAACC5s2lX0PgwmUwW11U1zrInvWgdBwcHcXBweCX1AQAAAAAA4M1kty3WvL29RUTitDy7evWq0YrN29tbHjx4IOHh4c9cBwAAAAAAAEgMdhus+fv7i7e3t6xbt85Y9uDBA9m8ebOULl1aRESKFCkiqVOntljn0qVLcvDgQWMdAAAAAAAAIDHYtCvo7du35eTJk8b106dPy759+yRDhgySPXt26dy5swwbNkxy584tuXPnlmHDhomzs7M0a9ZMRETc3Nykbdu2EhYWJh4eHpIhQwbp1q2bBAUFGbOEAgAAAAAAAInBpsHa7t27pVKlSsb1rl27iohIy5YtZebMmdK9e3e5d++edOjQQcLDw6VEiRKydu1aSZcunfE/48aNk1SpUkmjRo3k3r17UqVKFZk5c6akTJnytW8PAAAAAAAA3hw2DdYqVqwoqvrM200mkwwYMEAGDBjwzHUcHR1l0qRJMmnSpESoEAAAAAAAAHg6ux1jDQAAAAAAALBnBGsAAAAAAACAFQjWAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKBGsAAAAAAACAFQjWAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKBGsAAAAAAACAFQjWAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKBGsAAAAAAACAFQjWAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKBGsAAAAAAACAFQjWAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKBGsAAAAAAACAFQjWAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKBGsAAAAAAACAFQjWAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKBGsAAAAAAACAFQjWAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKySZYmzx5svj7+4ujo6MUKVJEtm7dauuSAAAAAAAAkIwli2Bt4cKF0rlzZ+nTp4/s3btXypUrJzVq1JBz587ZujQAAAAAAAAkU8kiWBs7dqy0bdtWPvjgA8mfP7+MHz9esmXLJt98842tSwMAAAAAAEAylcrWBbysBw8eyJ49e6Rnz54Wy6tWrSo7dux46v9ERUVJVFSUcT0iIkJERCIjIxP8+DFRdxP8Py/LmjpfhTdlW9nOxMN2Jh62M/GwnYnnTdlOkTdnW9nOxMN2Jh62M/GwnYnnTdlOkTdnW9nOxGPNdpr/R1VfuK5J47OWHbt48aJkyZJFtm/fLqVLlzaWDxs2TGbNmiXHjh2L8z8DBgyQgQMHvs4yAQAAAAAAkIScP39esmbN+tx1knyLNTOTyWRxXVXjLDPr1auXdO3a1bgeExMjN27cEA8Pj2f+z6sWGRkp2bJlk/Pnz4urq+treUxbYDuTF7Yz+XlTtpXtTF7YzuSF7Uxe3pTtFHlztpXtTF7YzuSF7Uw8qiq3bt0SHx+fF66b5IM1T09PSZkypVy+fNli+dWrV8XLy+up/+Pg4CAODg4Wy9KnT59YJT6Xq6trsv4AmLGdyQvbmfy8KdvKdiYvbGfywnYmL2/Kdoq8OdvKdiYvbGfywnYmDjc3t3itl+QnL0iTJo0UKVJE1q1bZ7F83bp1Fl1DAQAAAAAAgFcpybdYExHp2rWrtGjRQooWLSqlSpWSb7/9Vs6dOycfffSRrUsDAAAAAABAMpUsgrXGjRvL9evXZdCgQXLp0iUJDAyUVatWia+vr61LeyYHBwfp379/nC6pyQ3bmbywncnPm7KtbGfywnYmL2xn8vKmbKfIm7OtbGfywnYmL2ynfUjys4ICAAAAAAAAtpDkx1gDAAAAAAAAbIFgDQAAAAAAALACwRoAAAAAAABgBYI1AAAAAAAAwAoEawAAAACAeGP+OwD2xNb7JII12A3zhyEmJsbGlbx+tt4RAG8CVeWz9oZJLt8n5u3g/Yvk6t9//7V1CYinnj17yk8//SQmk8nWpdgU++PkLzo62tYlIB769+8vZ86csfk+iWAtmUiqO3fzj4WHDx8aH4aIiAhblpTonvZD78GDBzaoBHhz3L9/X0wmk5hMJtm7d68cP37c1iXZraT6fSIisnv3buPvCRMmyMaNG21YzauTIsXjw7VLly6JSNJ+jYAnjRkzRgYPHiz379/nvW3nbty4IQ8fPhRfX19j2Zv4mvXr1082bdpk6zJeivl1u379erI5CfWy/vzzT+PvsWPHyrp162xYzetjPvGcFIPE8PBw2bt3r9y+fdtYZqt9EsFaEmV+w5jfRLZOaK2VIkUKOXv2rEycOFFERH788UfJmjWrXL9+3caVJZ4UKVLIqVOn5MCBAyIisnTpUnn//ffl/v37Nq7s1TG/Pw8cOCCHDh2ycTX2I6kdfF65ckXCw8Pl7t27ti7lpVy8eFGCg4Pl9OnTsmbNGqlUqZKEh4fbuiy7YX5fRkRESHR0dJL9Pjl27Ji899578umnn0rXrl0lLCxMsmfPbuuyXkrsHzu//vqrlClTRvbu3SsmkynJ7U/wbG/6a+nr6ytdunQRR0dHix9HyV1SDDMyZMggI0aMkIIFC8q6detk2bJlb+T+6MCBA5IpUyZbl5Fgjx49EpHH+xyTySS//fab1KhRQyIjI21cme0dP35cWrZsKe3atZMuXbpI9+7dxd/f39ZlJSrzPujGjRtiMpkkZcqUsn37dtm+fbuNK4s/d3d3WbJkiQQGBsqGDRvkn3/+sdk+iWAtiTKZTPLLL79I06ZNpVKlSjJjxowk14y+R48eMmXKFJk/f74MHDhQmjVrJi1btpSvvvpKPDw8bF1eoomJiZGwsDApV66cjB49Who0aCC1a9cWR0dHW5f2Spi/rJctWybvvvuuzJs3T65du2brsl4b8458z549snjxYpk2bZpcuHDBaJWZVA4+hwwZIo0aNZKCBQvKZ599lqRb/kREREhQUJAUL15c6tSpI99//72UKFHC1mXZDZPJJCtXrpR3331XSpQoIRMmTJATJ07YuqwEy5w5s3Tp0kXmzp0r06ZNk/3790uePHnk4cOHti7NKjExMUZLtWXLlsmKFSvkwoUL0r59e9mzZ0+S2p8kpjlz5kivXr1kyZIlcvHiRVuX80I7duyQ4cOHy+DBg2X16tUi8vgzmBRDllelQYMGkjdvXtmxY4d07NhR9uzZY+uSEsWZM2fk0KFDcuTIERH5X0vUpCZ16tRy//594zhvxYoVb8z+yLyNy5Ytk8DAQNm4caOsXbvWCKzs2bfffiszZ86Uu3fvGifQLl26JFmzZpX06dPbtjg7kCVLFvn8889l2bJl8t1338lff/0lefPmTbLHEPGxZ88eefjwoRQtWlQWLlwoa9eulQoVKiSZnlTm783UqVNLZGSkTJgwQQoVKiSnT5+2zT5JkSRt375dHR0d9fPPP9fq1atroUKFtH379vrPP//YurR4mTp1qqZIkUIPHz6sqqoffvihmkwmrV+/vt6+fdvG1b0e+fLlUwcHBx00aJCtS3nlfv75Z3V0dNQpU6bojRs3bF3Oa7do0SJ1c3PTEiVKqLOzsxYsWFAHDx6sd+7cUVXVmJgYG1f4fH379lUPDw9duHChLliwQCtXrqz58+fXn3/+2dalJUjs53n27NlqMpnUzc3N2O88evTIVqXZlT/++ENdXFy0b9++2qxZMy1UqJC2aNFC9+/fb+vS4iU6Otr4e926dZoxY0bNlSuXdurUyVielF/rsLAwzZEjh/br109bt26tuXPn1uDgYP3jjz9U1f73J4mpf//+6ubmpuXLl9e0adNqmzZt9Pfff7d1Wc+0ZMkSdXNz03r16mmpUqW0VKlS2r9/f+P22O/lN9EPP/ygefPm1TZt2ujevXttXc4rtXjxYs2TJ49mzpxZc+TIoaGhoRoeHq6qSfczfPz4ce3UqZO6urrq0qVLVTXpbktCmbczNDRUXVxcdN26dfrw4UMbV/V81apV0zx58ujcuXP11q1bqqo6atQorVmzpo0rs63Y+92VK1eqp6en5s6dW9u3b2+8zkn5GOJZwsLCNGfOnLpv3z7t06ePurq6aurUqY3PclL6Pvrll1909OjReujQIa1Ro4b6+PgYmcjr3CcRrCVBZ86c0QEDBuiYMWOMZV999ZWWKlVK27Zta/fh2qNHj7Rdu3b6/vvvq6rqjz/+qGXLltVWrVpp9uzZdfDgwXrx4kVVTX5f0ObtefDggWbJkkX9/PzUz88vSR9Arly5Us+ePWtcj4yM1Dp16ujgwYNVVfXWrVt64sQJHTlypM6dO1ejoqJsVWqiif0+PXDggHp7e+v06dP19u3b+uDBA/3ss8+0XLlyOmzYMLs/8FqzZo0GBAQYP07Xr1+vjo6OWrJkSc2XL5+uWbPGxhUm3K+//qrff/+9Tp48WVu0aKGZMmXSP//8U1XV7l+PxHbq1CkdOHCgfvnll8ayOXPmaNmyZbVZs2ZJJlxTVe3QoYO2b99e9+7dq19//bUGBgbqRx99FGe9pHSAvG/fPvX19dV169YZy3755RetWbOmBgcH619//aWqye+78kViYmL07t272qBBA922bZuqqq5YsUKLFSumTZo00Z07d9q4wri2b9+u2bJl06lTp6qq6t69e9XNzU19fHy0S5cuxnpJ6cdMYvjhhx+0SJEi2rJlyyR9bBTb5s2b1cnJSadMmaLbt2/Xn376SQMCAjQ4ONgIOOz9M2yuLzw8XP/77z9j+enTp7VDhw7q6uqqy5Yts1g3OYu9jTVr1tTMmTPr2rVr7fKYInatTZo00YCAAJ09e7aqqg4fPlzffvttW5VmV8y/PY8fP67ffvutFipUSFu3bh1nPXt8jRNq8+bNmj59emMfaz757OjoqPPmzTPWSwrfR3v27FFXV1edN2+ePnz4UM+ePashISE2CdcI1uzcpEmT9JdffjGuHz16VEuUKKHZs2fXr7/+2mLdr776SkuWLKkffvihHj9+/HWXmiDTp09Xk8mkvXr1UpPJpHPmzFFV1cGDB2vWrFl18ODBeunSJWP9f//911alvjLmD/X+/fv19OnTxvIqVaqor69vnANIe2+5FxMTo9u3b9fcuXMbX0ZmlSpV0latWumNGze0Y8eOWr58ec2TJ4+mTp3a4ux8Urd48WLdt2+fqv7v9f3pp580Z86cFs/J7du3tUOHDlq4cGG7b8F37Ngx/fzzz1VVddWqVerp6anTpk3TXbt2qa+vr+bOnVsXLVpk4ypfzPx67Nu3T1OmTKkLFizQhw8f6sGDB7Vhw4aaKVMm3b17t7H+6tWr9cSJE7Yq1yZOnTqlxYoVUx8fHx0xYoTFbXPmzNEyZcpoixYtjPDGnp0+fVoDAgJ0y5YtqqoaERGh48aN06CgIO3YsaOxXvfu3Y11koI9e/aos7NznJoXL16srq6u+tZbb+muXbtU9c34MWt28OBBPXnypLZq1UovX75sLF+5cqUWL15cmzZtajfhmvl1mTBhgrZs2VJVH79fc+TIoc2bN9devXqpp6en9uvXz4ZVvn7m5+XAgQO6bds2PXjwoHHb7Nmzk1W4Nnz4cK1Tp47FsvPnz2u+fPm0Vq1aNqoq4ZYtW6YFCxbUgIAAbdCggV69elVVVc+dOxcnXEuOYu9jnwwcqlatanfhWux6Y59QatCggebNm1eXLFmiPXv21C5duuitW7f00qVLeuXKFY2IiNDDhw8boe+bYMWKFWoymXTz5s2qqnrjxg2dOHGiFipUSD/44ANjva5du+rGjRttVeYr8/vvv2tQUJBu2bJFFy9erKVLl9bvv/9eBwwYoOnSpdNp06ap6uP3kD2Ha3///bd+//332r17d4vlscO1U6dOqerrOUYiWLNjp0+f1mbNmsX5sdezZ0/NlCmT1q9f3+KskarqN998o/ny5dNPP/3Ubnbsz1KtWjU1mUz66aefWiwfPHiwZs+eXQcNGqTHjx/XAQMGaPr06fXu3btJ9oeDue7Fixerv7+/9uzZ00jRb926pVWqVLFouTZy5Eht1qxZkmhZce3aNVV9HPqePHlSVR+HvPny5dNUqVJpvXr1jDNjffv21UqVKun9+/dtVu+rcujQIQ0ODtbatWtb/CD46aefNHv27Mbr++DBA1V93JIvderUunDhQpvU+yKxD6AiIyP14cOHWqtWLYsgtGrVqpovXz5t0aKFDSpMuN27dxsHjrEdPHhQGzVqpJ6enrpkyRLjh+25c+dsVKntfPnll5otWzatVq2aRctT1cctRwICArRdu3Z23dJ06NCh2rp1a/3ggw8svvdu3ryp48eP14CAAK1QoYJWr15ds2TJYrffjbG/38x/nz17VosXL67jx4/Xe/fuWaxfokQJDQ4O1uDgYKOFaVL9jkyIsLAw9fHxUScnJ02fPr3FyUfVx/vgUqVKabVq1Sz2zbYWHR2t+/fv1zt37mjFihW1VatWqvo4lMicObM6ODgYJzXeFIsXL1ZPT0/19PTUokWLap8+fYzbzOFamzZtjBbGSVX79u01ICDAuG7eB82fP1/z5csXZ99rj3bt2qUeHh76xRdf6Pjx4zVXrlwaHBysR44cUdXH7+NOnTqpyWTSn376ycbVvnrmfeuGDRs0LCxM69Wrp0uXLrVoBGAO1+yhW6g5DLl9+7ZGRkZqRESExe3169fXwoULa548edRkMmmRIkU0ffr06uXlpblz59Y8efLE+Y2ZnJ09e1abNWumzs7ORrgWHh6ukyZN0oIFC2rJkiW1evXq6uPjY/PX9lU4e/ashoaGasmSJdVkMuncuXON5T179tR06dLp999/b6y/aNEi3bFjh63KjSMmJkbv37+vHh4eajKZtEmTJnHWOXv2rFavXl0dHBwsGrQkJoI1O2cek+n333/XxYsXG8v79eunQUFB2rdvX71y5YrF/0ybNu21vYGsderUKQ0ICNAqVaqoyWTSJUuWWNw+fPhwzZEjhwYEBGjmzJntesyU+Nq4caO6uLjolClT4nzB3bp1S6tWrapOTk5atWpVdXR0tPtWIubQLzo6Ws+fP69eXl766aef6pUrVzQqKkqPHz+uq1atsvifNm3aaMuWLZPFl5Lq41Y9lStX1nr16unff/+tqqr//fefenh4xGk+fvnyZS1cuLCuX7/eFqU+17fffqvBwcEWwdK1a9fUz89PJ02apKqq169f18aNG+uiRYuSxI/3+/fvGweM9evXj1PzsWPHtE2bNurl5aWBgYFGq5/k7Fmv25gxYzQoKEi7du2qZ86csbht4cKFdv198vDhQ/3iiy/UZDJpiRIljB8T5v1TZGSkLl68WN977z1t06aNEXTb20kLc12qjwPBmzdvGtc/+OAD9fPz05UrVxoB53///af169fXqVOnar169bR48eJGl8jk7Pfff9ccOXLo2rVrdcqUKVq2bFmtUKGCRVdZ1cdDTHzwwQc2P9O+c+dOnTJlig4cONBodXju3DnNnz+/7tmzR1UfD+9Rr149HT16dJzPX3IVExOjN2/e1AoVKujs2bN1z5492rdvXy1YsKB26NDBWG/u3LmaM2dO/fjjj5PcCbnTp08b+84NGzZo7ty5debMmRbrrFmzRn19fe3+df/77791+fLlOnDgQGNZeHi4BgYGauHChfXo0aOq+nibu3XrZlxP6p78zly2bJm6ublp48aNtW3btpouXTrt2bOnRYD/9ttva5o0aWzaqsm83zt06JBWrVpVg4OD1cfHR+fOnWtx/N2iRQv18vLSLl266N9//6379+/X3bt36/Hjx+36e/9lPfm6mq9fuHBB33//fU2TJo0RrkVEROjy5cu1TZs22q5dO+P5s7djiIQwb+/gwYPVZDJp4cKFdevWrcbt586d0169eqmLi4t+8cUX2r17d3V0dLTLoaYuXLigefLkUX9/f929e3ec1/bUqVNar16919aTj2DNzsXExGh4eLjWrVtXixYtatHEulevXhocHKx9+vQxmmMnFbdv39Z//vlHb926ZZzhejJc27x5s/78889JfuceHR2tjx490g4dOuiHH36oqv/bqT25Yx42bJgOGjTIOAOYFJhbrI0dO1Z9fX31888/j3OQePLkSe3evbu6u7vrgQMHbFHmKxX7wGTGjBlaq1YtrVevnh46dEhVH4/plTZtWm3ZsqXu379f//nnH+3bt69mzpzZ7lpFrVq1SseNG6cmk0nr1q1rdLu+deuWNm3aVMuXL6/jxo3TkJAQLVOmjHHAZusfrPFx9uxZLVu2rGbPnt14bZ508uTJJLf/tIZ5n7N161bt27ev9u/fX7/77jvj9pEjR2rhwoW1c+fOdt164mnhYHh4uI4ePVpNJpNOmDDBWP6s96g9BfuxxzJRVR0wYIAWKVJE33rrLYuugXXr1tUcOXJomzZtdMSIEVq+fHktX768qqpu27ZNK1eurBUqVNB79+4lieDbGt9//722a9fOohXt+vXrtXbt2lqlSpVnnrSw1b7KPFFBkyZNtHTp0lq0aFHt2LGjHj16VLNkyaIjR47UBw8eaJ8+fbRatWrGd2lyZn5v3r9/XyMiIvTdd981uvLeuHFDR48erYGBgRbh2sKFC42uPEnF0qVL9a233tKxY8fqjRs39Pz589qkSROtUaOG0QokKipKe/XqpW+99ZZev37dxhU/2+3bt9Xb21tNJlOcMSvDw8M1ICBAixYtaoRL9rR/fRXMx+m7d+9WX19fo4ucqqqzs7NmyJBBO3ToYBEm1q9fX48dO/baa1X932fs0KFD6uHhoV26dNF58+Zp165dNXXq1HG6Vjds2FADAwN14cKFRmOON8XEiRONk+Kxw7UWLVpomjRpjBZaT36HJPX3uHlbP//8c+3du7eWLl1a3377bV29erWxzsWLF3XUqFGaK1cuLVmypHEiyJaedWxz4cIF9fb21kqVKj319/PrfL0I1pKI3377TRs2bKgVK1a0CKB69eqlxYsX186dO9t1k13zh+Gff/7RAwcOGONSqT4+824O18wzkSRHtWrV0ubNmz/1ttg/+pNCYGH2119/aZYsWTQyMlJVH3cB9fHx0e7duxuB6MaNG7Vt27aaL1++ZDFWiur/3s/r1q3TTz/9VIOCgjRFihQW4dr69evVx8dHs2XLpv7+/urv728XX0yxde/eXbNmzapDhw7Vli1bqpeXl5YvX94YH2716tXasGFDDQgI0Fq1ahmtauzxPWp+TY4ePaq7du0yWoecP39eAwMDtWjRonYXar5uS5YsUWdnZ61Zs6aWKlVK06ZNq++8847x3A0fPlyLFSum7dq1s8vnKvb77t9//41zBnLgwIFqMpmMweFVH78vntbF0h6sX79eTSaTfvHFF6r6eEzVTJky6ahRo7Rbt27q6Oho0e166NChWr9+fS1WrJg2bNjQogXP1q1b9fz58699G16Xf//9V+vXr69ubm768ccfW9xmDteqVq0ap1uorRw5ckR9fX11ypQpqqp6+PBhdXZ21t69e+vNmze1c+fOxuRFnp6edt9C/VVauXKllitXTt99910NCgqy+Fybw7XChQsbE1wlNatXr1ZHR0edOHGiRTfBw4cPa9OmTTVHjhzq5+enFSpUUHd39yTx2h84cECDgoK0SJEicSYXCw8PVx8fHy1XrpxFy9ukbNq0aRbH6w8ePNA1a9Zo7969VfVxK1NfX1/t3LmzzpgxQ00mk3bt2tVujnGvX7+uVatWtZgZW/Xx+MfmZbGHd2jSpIl6e3vrggUL7Oo7MjFduXJFy5Urp97e3kYYY972EydOaL58+dTV1VV/++03i/9Lys/Ps2r/66+/tHjx4nHCNdXHLfbMsxfbkrn2bdu26cSJE7V79+568uRJYxibc+fOaaZMmbRy5co2bTFLsGaHnvXG37x5s9arVy9OuNapUyetUKGC3ba6iD2+WM6cOTVr1qzq7e2tNWvWNFpG/Pfff/rZZ59pmjRpdP78+bYs95WLjo7W6Ohobd68uZYtW9biwCMmJkavXbumXbt2tRhIPamIiorSHDlyaK9evYxlkydP1ixZsmiPHj300qVLevv2bV27dm2y+9Fn/lE8YcIEXbNmjfbv318LFSpkEa5dv35dt2zZolu2bLG7CTj++usv9fT0tJjlc//+/erv769ly5Y1WhHcv39fw8PDjc+xPZ6pM9e2bNky9fPz0/z586uTk5O2atVKL168qOfOndOAgAAtVqxYsnsfxteZM2fU39/faNF19+5d3bp1q/r4+Gj9+vWN9QYMGKDly5e3GBDeHsT+Xuzbt68GBgZq+vTpNTg4WEePHm0c+A0aNEhTpEih3377rY0qjb+7d+/q9OnTNU2aNDpw4ECdNm2aRav01atXq6urq0W4FhMTYzEeoj2Pffeq7dixQ5s2bapubm5xxnDasGGDlipVSj/77DPbFPeEdevWaZEiRVT1cVcUX19fo8W66uNx4DZs2KCzZ89Ocq2xXsbOnTvV0dFRO3TooPXq1VNnZ2dt2rSpxTo3btzQQYMGaenSpS2CKXsXExOjt2/f1jp16hgBjJn5e/PSpUv6559/au/evXXq1Kl2OWHOs05EHDx4UDNnzqzVq1c3TuSbb79586ZddhOzRlRUlA4dOlTz58+vn3zyibH8/PnzevjwYX3w4IHWrVtX27RpY5zcyJ8/v6ZJk0Z79uypUVFRNg9fLl++rMWLFzdOMJrD67Zt2+p7771nrBe710zLli2TzWv4NE97TXbv3q116tTRrFmz6uHDhy1ua9iwofr4+Bgtw5O62L0WxowZo2FhYbpp0yYjO4gdrv3666+2LDUOc+1Lly5Vd3d3DQ0N1bfeekuzZ8+u3377rXG8eu7cOc2SJYsWKVLEZpM4EqzZmdhv/H79+unnn39uMQNf7HAt9gG4vYZqZlu2bFEXFxf97rvvdMeOHbp582bNmTOnFi1a1AgcLl26pB988IG6u7vrrVu3bP7FZK1ndfM8cuSIpk2bVj/88EOLlga9evXSAgUKxJlZ0948+Xo8fPhQHz16pL169dLq1atbdGX45ptv1NfXVzt06JCkDozjw9wC5qOPPrIIJFQfdwstUKCA1qtXL86XtL3Ztm2benp6Gt12zQde27dvVycnJ61bt67xnkwK3T9//fVXTZ8+vU6dOlWjoqJ01apVajKZtHHjxnr+/Hk9d+6cFi5cWHPlyqUXLlywdbmvRezP7IkTJzR79uxx3pebNm1SV1dXixMa9twtafjw4erh4aELFizQ7du3a9u2bbVkyZIaFhamkZGRGh0drcOGDVOTyaTLly+3dbnPFPu1+frrr9XZ2VkdHBziTG6yZs0adXV1jTNm45P3kVxFRkZanC3fv3+/Nm3aVAMCAuK0Ttu9e7fd7KNWrlypVatW1dOnT2vWrFn1ww8/NI4Jtm/frn369IkzPm5yd+DAAV2zZo2OHDlSVR+HMXPmzFEfH584rdPCw8Ptej/0LDExMRocHKzDhw83rsdmbycsnhS7NX7Xrl21du3aOnPmTKMl1oEDB9Tb21urV69udF1OjvuhGzdu6Pjx4/Wtt96yCMRVH38/Fi1a1BjsPTIyUtu2batjxoyxq6A0drBgPqHfr1+/OJNP2ftM9a9C7O+FK1euWAx3cfToUa1Ro4ZmzZrVeP3u3bunTZs21Q0bNiSr9/fixYvV2dlZa9eurf7+/sbsvuYeCvv27dPSpUtr2bJl7W7m023btmnmzJmNrvR37txRk8mkOXLk0IkTJxo5yOnTpzV37tw2G7eSYM2OmD+8S5YsUVdXV23SpIlWqlQpzlnYzZs3a8OGDbVw4cJJZuadkSNHatWqVS12bhEREern56f16tUzlv333392f+DxPObXcO3atdqxY0cNDQ3VGTNmGM1SV6xYoenSpdMSJUpojRo1tH79+po+fXq77grw5IDBTzYJPnr0qDo7OxuD3JuNHTtW8+fPn2x/PHTp0kXLlSsXZ6a+nj17qoODg1auXPmZ43rZg/DwcHV3dzd+5JhduXJFAwMD1dHRUatUqWKj6hImIiJCP/zwQ2Ng5VOnTmnOnDm1QYMG6ubmpnXq1NEzZ87omTNntFSpUm9UC5GlS5fqxIkT9b///lNXV9c4g2ebx8gZP368jSqMH/Ng5+XKlYuzrxkyZIgGBQUZQVpkZKTOmjXLLltXqj7uHj9nzhxVVf3444+1TZs2OnPmTE2XLl2cWbJVH4fGJpNJhw0b9rpLtalhw4ZpmTJltECBAlqzZk3je3L//v363nvvaWBgYJxuK6r2cQLg5MmT6uTkpCaTKU53rE6dOmnVqlWTZHBkrevXrxuzt8VuzXX79m2dO3eu+vj4PDU8TkoePXqkt27d0oIFCxqf49gnWE+fPq0jR460+xM7S5cuVUdHR33//fc1NDRUCxYsqOXLl9cNGzao6uNwLXv27FqqVKlk9x6OiYkxXrN9+/Zp3759NUOGDNqtWzdjHXM376FDh+q+ffu0X79+GhAQYNGS2J7E3h/26dNHq1atalwfNmyYjhkzRh88eJCsAqRn6d27twYEBBjHheYxTo8fP641a9bUNGnSaKtWrTQ4OFiLFi1qMUlbUmc+Lv7mm2+MZd99952GhoZqkyZNjKB87969WqVKFbsYDiT2e3LKlCnavXt3VX08rJSfn5927NhR27Vrp87OzvrVV18ZDXVseexHsGZndu7cqb6+vkY3lsOHD2v69Ok1c+bM2qZNG2O99evXa4sWLex+JiGzDh06aOHChY3r5jDi559/1uzZsyepwfpfZNmyZeri4qKffPKJtm7dWkuVKqUNGzY0BnY9e/asdu3aVdu0aaM9e/a069mTPvvsM504caJF3/bQ0FDt1auXRkVFGWfBBg8erKVKlYrTjNwe+uUnlgkTJmjWrFnjzFg7f/58LViwoL733nt21+3w2rVrevPmTeN1MQ+cPH36dGOdW7duaatWrXTDhg2aIUMG/fLLL21UbfxFRUXpokWL9OTJk3r9+nUNDg7Wtm3bqurjweFNJpPWqFFDL1y4YLdhS2LYt2+fZsyYUadMmaK3b9/WVq1aadWqVeMM8l6+fHkdO3asjaqMv6ioKC1WrJgOGTJEVS0PnsxjNj3Jnl7vmJgYjYyM1NDQUK1QoYLWqlVL3dzc9NChQxoTE6PTp0/XVKlSad++feP87x9//GFX25LY+vXrp56enjp+/HidMmWKFi1aVHPnzq0rV65UVdVdu3Zpy5YtNWPGjLpz504bV/t08+fPVxcXF+3Ro4ceP35cDxw4oN26ddP06dMni0l8EiI6OlpXr16t+fLli3PC5vbt2zpv3jx1dHSMMzh+UmCe5d38I3zmzJlqMpksJodRfTxQeJkyZew6jLp06ZIGBwdbTAKzfv16bdasmVaqVMk4jt2/f7/mz5/frie6eRk//vijFitWTOvXr68+Pj7q7u6uHTt2NG4fPny4uri4aI4cOdTb29vuxs99kvkYvm/fvlqjRg1VVWM27dhjXic3sQOxr7/+Wr28vHT69On6448/atWqVbVUqVLGsU94eLgOGTJEGzRooB9//LFdjylsjd27d2vmzJktGnI8fPhQp0yZogUKFLAYjshWQ0yYn+vYQybt2bNHHzx4oCdPntTDhw/r3bt3tUqVKsYxflRUlHp6eqqXl5dOnTpVHz16ZNOQmGDNDsQ+o/Xdd98ZzXRPnz6tOXLk0Pfff18HDx6sHh4eFi3X7t69+7pLjRfzG/r8+fNG08wtW7ZoxowZ4xxo/Prrr5ojR45k8+X8119/ac6cOY3tjIiIUDc3N82ZM6fWqVPH+AIzv+b2foZo3LhxFjvhI0eOaJcuXTRPnjxaoEABHTx4sJ45c0b//vtvzZ8/v65du1ZV/7dTtPfti4/YMyzt2bPH4vkoV66c5sqVS3fs2GFM4NCjRw/t0aOH3R08DxkyRENDQzVnzpzatGlTXbdund68eVPbtWunefLk0Xbt2unkyZO1QoUKWrJkSb19+7aWLVtWO3fubOvS48Uc1v/www9aqlQpI9ScP3++VqxYUX19fZPNfiY+jh07pv3799fPP//cWLZ161YNCQnRypUr6+TJk3XHjh3atWtXdXd315MnT9qw2riedjD76NEjrVGjhpYrVy7OmeQePXrou+++myT2OdevX9e8efOqyWQyuoypPn4Pf/fdd5oqVSpjQoMnvQnh2oULF7RAgQK6YMECi+W1atXSXLlyGcMLbNmyRQcNGhRn2AV78eDBA505c6a6urpq1qxZtUCBAlqoUCG7bqGemO7fv69r165VDw8PbdSokcVtt27d0h9//NFm4+JYa+XKlVqxYkWtXLmyfv3118Z7s2fPnmoymbRt27YaFhamrVu3VldXV7sZ3P5Zzp49qz4+Prp48WKL5WvXrtX8+fNbjO+cXMd3PHTokLq7u+vkyZM1IiJC//vvP+3Tp48GBARYTJyydetW3blzp92dQH0a8/dk//799cMPP9RRo0apg4OD3QeCr8qWLVt0xIgRFi32r127pp9++qkWK1ZMt27daiyPHeok5e/bJ4+FDh48qLly5TJ6usU+xsqUKZNFi3hbHkedOnVKQ0ND9dGjR/rjjz+qq6ur7tq1y7j9yJEjWrBgQWNSiZMnT2rjxo31o48+sovjWII1GzC/mWM3G469c9u7d68+fPhQQ0JCtFWrVqr6eAfg6+urDg4O2r59e1W1z9DCXNPy5cu1XLly+v333+utW7f033//1Y8//ljLlCljhE737t3Tvn37aqFChZL0NPPmbY6KitI///xT27dvrzExMUYw+tFHH+nMmTPVw8ND69WrZ3FWwB5fw6f55ZdfLH4ARkVFabdu3bRKlSrq7u6u3333nebNm1eDg4PjdI1MDhYtWqQZM2bUrFmzqr+/v/br109VH79+5cuX12zZsmlwcLBWrlxZ06RJY5zVtRd9+vRRDw8PXbp0qf78889asWJFTZ8+vd66dUtPnjypU6dO1fz582upUqW0Vq1axgFzSEiI0b0yqbxXhwwZooGBgca4IT179tRJkyYlm9nKniX263Pt2jV96623NEOGDHHGh9m6dat+9NFH6ubmpvny5dOgoCC7+7EX+4Dv8OHDxhh5qo+7AHh6emqTJk00MjJSo6Ki9OHDh1qmTBnt0KGDrUpOkPDwcH377be1fPnyGhoaanQLVf3fhAaOjo5xuhC+Kc6cOaNZsmQxWlbG/k7x8/OzmCzHzF7DNdXHJxm3bt2q+/bts+vZ218V875o9+7dOmfOHJ08ebJxoik6OlrXrl2rGTJkiBOuJZXvGLPdu3erm5ub9u3bV2vXrq0lSpTQVq1aGeHa4sWLtUqVKlqlShVt1qyZ3R0XqP7vOd+7d6+eO3fOaPH91VdfqarlvrhEiRJJvrtufKxatUqzZs1qMeHU1atXtXv37urq6mpxsiqpGTJkiJpMJnVzc7MIK5KzY8eOqclkUpPJZPTAML/vb926pbly5TK6GCYXsXsZrVu3TlUff0eWKlXK4sSz6uMTHhUqVNAZM2bYotQ4zp8/r9myZdOAgAA1mUw6a9YsVbXcpsyZM+uSJUv06tWrOmDAAK1Zs6bd/PYkWLORc+fOaYMGDXTjxo26ePFiNZlMumPHDuP2EydOaIECBXT79u2q+niq+QYNGui4cePsvtXF8uXL1cnJSUeNGmXx4T1y5Ih+9NFH6u7urrlz59aSJUuqh4dHsjh7u3LlSh0/frxev35dz5w5o9HR0dqgQQNt2bKlccBfqlQp9fLy0mbNmsUZt8xexD6Iih1EjBs3Tk0mk44dO9ZioNMrV67ohAkTjNfSzc3N7ifSiK/YU8kHBgbqzJkzdcuWLTpmzBh1cHDQsLAwY91p06bpgAEDtGfPnnbXrfncuXNaqlQpY3wU82DoU6dOtVjv0aNHFq/5559/rpkzZ7arwXjjY+/everg4KBlypTRKlWqqKurq+7fv9/WZSUK8+c1dsuB3bt36507d3TFihUaFBSk+fLls/huUf3fbMRnz56164GLu3fvrr6+vpo5c2bNmzevfv3116qq+ttvv6mnp6cGBARo2bJltVSpUlqgQIEkd3b50qVL+vbbb2ulSpWMgbBVH+97R44cqRUrVkxyYcPLiD3TYO7cubVdu3bGbeaZ9mrUqJGkf9gmd7HHCvbx8dHg4GANDg5WLy8v/eOPP4z11q5dq15eXlq9enVblfrS1qxZoz169DCuT548WcuUKaPNmzc3jtPv3LmjqvbZuiv2bNo+Pj5GF/SPPvooThfrmJgYrVmzptENPznbu3ev+vr66qpVqyyWX7hwQb29vdXBwcFuZh9OqF27dqnJZLLr8X9f1tO+M1etWqXu7u5at25dvXHjhsU6bdq00caNGyeb79rY++CMGTNqhw4djBOTV69eVV9fXy1RooTOnz9ft2zZoj169LC7XgvffPONmkwmzZ07t9HVPrZ69epp+vTpNXfu3JohQwa7anlJsGYjBw4c0DJlymhwcLA6ODjo7NmzVfV/P5TMrZ2++OILvXXrlvbp00crVapkd2c7nxwf7MKFC1qoUCFjcOmoqCi9ceOGrlq1yvjQ7tq1S7/44gudNm1akvvRHpt55/X333+rk5OTzp492wjRwsPDNSgoyJi95NatW/ree+/piBEjLM6C2aPz588bZ5dXrlxpvDfHjBmjJpNJR40aFWfstH/++UdXrlyZ5LpxvMj69eu1a9eu2qFDB6Pr9Z07d/Tbb7/V1KlTa9euXW1c4YsdPXpUfXx89MqVK7py5UpNmzatMXjp3bt3dcqUKRZfqLt379ZPPvlEs2XLlmRD7x07dmjz5s21Y8eOdtlK4FU6d+6cBgQEGGFa+vTpjR9EK1as0LfeekubN29u0VLWXgOo2Ae2K1as0MyZM+uqVat08eLFOmDAAE2RIoXxw+769es6aNAg7dmzpw4dOtTYJnvdtmc5deqU1qxZU0NDQ/X777/XR48eaZUqVTQsLMx4PpLLAf/zfPnll9qoUSPjfTpnzhz18/MzWgebFStWzGhFC/v022+/aYYMGYzeCUeOHFGTyaRZs2Y1TvCoPh5jN0eOHHY/mP+TduzYobNnz9bevXvHGQ/RHK61bNnSYpIce/0M//zzz+rk5KTTpk2zOBHesGFDzZQpk44YMUKnT5+uXbt2VVdXV7s7cfiynva6XLhwQYsWLapNmza1ODa6fPmyvvPOOzpq1KgkM77109y+fdvWJSSa2I0DzKG22fLly9XBwUE//vhj/ffffzUmJkbv3bunwcHBFuPnJQfr1q1TZ2dnnTFjRpyWXNeuXdPQ0FDNnTu3+vr62uXwBFu2bNGxY8dqgQIFtFixYkYwGPv4bsmSJfrDDz/EGdvb1gjWXrPYM87Mnz9fU6ZMqQUKFDDGpjKvc/v2be3Zs6f6+vpqtmzZNFOmTHaVyKo+rt/b29uiS6t5GurZs2drZGSk9u/fX8uWLasZM2bUtGnTGgMPJxd//vmnLl682Dhraf6SvnLlilasWFHbt2+vO3fu1C+++EKDgoLsvjVXRESEVq9eXUNCQvT7779Xk8lkMc7NqFGjjHDtaWcRkpOoqCgdOHCgpk6dWgsVKmRxmzlcc3Z2tuh+Zk8Hz0uXLtUzZ87ohQsXtHTp0jpgwAB1c3OzmBFo3759+u677+qWLVuMZY8ePdIVK1Yk6QNH1ccHWPb0eiSWs2fPasWKFdXb21tTpkwZZ1yqRYsWadGiRbV58+Z29x3yLCtXrtQPPvhAhw4darF8xowZcfZJsdlzd8DnOXXqlNavX1/z58+v/v7+GhgYaLRweRPewz169NBMmTLp/PnzjR+y//33n44YMUK9vLw0NDRUO3TooOXKldP8+fMnufD0TXLv3j0dMmSIDhgwQFUfB//Zs2fXDz/8UN99913NmDGjbt682Vj/yR+/9m7JkiXq7Oys/v7+6uLiov7+/nrx4kWLdaZOnaqBgYH64Ycf2vU+6d69e9qwYUNjltY7d+7o8ePHdfTo0bpmzRqtW7euVqpUSXPlyqUVKlSwuyEDXpZ537phwwbt27ev9u7d2/iRvm3bNnV3d9fGjRvr4sWL9cSJE9qjRw8tW7as3R/HQ3XEiBFav359rV+/vu7Zs8c4Mb506VJ1cHDQoKAgbdiwob7zzjtasGBBu2xRaq3o6Gjt1q2bMRFMRESE7ty5Uz/66CPt0aOHEY6fPXtWjx07ZhdDMZk/i0eOHNHff//dOMF29uxZDQgI0KJFi1qcgFm/fr3dvmYEazYyZ84crVSpks6ZM0erVaum1apV02XLllmsc+PGDd25c6cuXLjQbn/kmpu7m1vSXb16VWvUqKHly5fXtGnT6jvvvKMTJkzQo0ePamhoaJJo4RNfUVFRGhQUpCaTSWvXrh3nAGr8+PFauHBhzZw5s/r6+iaJH7WPHj3SZcuWaZ48eTR16tRG16vYXVfN4drYsWP15s2btir1tTh37pwOHTpUTSaTjhkzxuK2O3fu6MSJEzVjxox65coVu/oB3KtXL82SJYtOnDhRVR83dTeZTBZdqG7fvq1vv/22Vq9e3TjLl1xmP3rTzJkzR00mk2bIkMHYF8fu1rto0SItVaqU1qlTxy5/HMV+3x07dkyLFSumbm5uxgD+MTExGh0drY8ePdJmzZpps2bN9MGDB8kqYLl48aL+9NNP+t133yXZ1nfW2LZtm+bIkUM3btwY57bw8HDdtGmT1qlTR5s2baodO3Y0nhN7DizedFu3btU9e/ZoZGSkli5d2hjn0dwNzcnJySJcSyoiIyO1S5cuxtjBc+fO1dKlS2tISEicVnfff/+9nj592jaFxtPdu3e1aNGi+umnn+r169f1k08+0fLlyxvHrGPGjNEbN27of//9l2xPpK5YsUKdnZ21fPnymi9fPnVxcTHGpNq5c6eWK1dOs2XLptmyZdPMmTMnieP4N9348eM1Q4YM2rNnTw0ICNCcOXPqzJkzjQnGfvrpJ3Vzc9OgoCDdtGmT8V2SnMbhbd68uQYEBOixY8e0adOmGhISomXKlNFcuXJprVq17GpbY3dJ9/Pz03z58qmTk5O2atVKL168qOfOndPAwEAtUqSIbtq0SXv27Kmenp5GKzZ7Q7D2GpnfPCdOnND06dPryJEjVfVxq5EqVapotWrVdMWKFcb65oF77d3ff/+tzs7ORmu0Q4cO6dy5c/Xbb781dmSqqrVr1zbOYiYX//77r1apUkWzZMlijOMUO2AxzyRp790/Vf/34/b48eOaPXt2zZ49u9atW9c4mxE7XDN3C504caJdBUovw7wdly9f1n/++cd4796/f1+/+OILTZs2rY4fP97if+7evRunW6ytDRo0SD09PfXPP/80ajMHEt7e3vrJJ5/oZ599phUrVtTAwMBkN6X4m8L8fr17964eOnRIZ8yYoTVq1FAfHx+j1U/sM3qLFy/WChUq2N2+KPb7bsWKFXrt2jVdvny5Fi1aVP39/S26sKqqfvLJJxoaGvq6y3zt3pTgaMGCBZojRw6Ls+bm98SzvlvehMAxqXhed+U///xTixYtahwb7du3T5s2bapt27ZNcl0K//jjD/Xz89OKFStajNm5ZMkSY1bQpNalVVV11qxZ6uTkpK6urlqvXj1joPBPP/1UK1eunKw/a3fu3NGBAwcaXZavXLmibdu2VWdnZ129erWqPu42d/z4cd26dWuclomwD08euw4YMECXLl1qXG/WrJnmy5fPCMRVH7eKT506tX722WcWPcmSoqfte0+cOKF58uRRNzc3bdSokfH7fMWKFRoQEGB3w0r9+uuvmj59ep06dapGRUXpqlWr1GQyaePGjfX8+fN6+fJlfeuttzRnzpzq5+dn1wE3wdpr9scff+ioUaOMgc/NO4T9+/drSEiIVq9eXSdOnKgDBgxQk8lkt4lsbDExMdqkSRNNnz69/vLLL3Fuj4iI0F69emmmTJnijMmWlJh3XpGRkXrnzh1jnIIrV65oUFCQFipUyBhTI6mFTeZ6z507p4cPH9ajR4/qsmXLtHTp0vr2228/NVybOnVqshkANfYZk6CgIM2ZM6cGBQVp165d9fz58xoREaEDBw7UdOnSGa3A7NH169c1JCTEGAj9woULumnTJv3ggw/0hx9+0BYtWmjTpk31nXfe0d69e79RLWOSE/P7dc2aNdqpUydjqvjTp09rSEiIZs6c2aK1xM8//6y3b9+2u25XsfeTvXr1Um9vb6OV7JIlS7R8+fJavXp1Y/yP27dva/ny5bVFixY2qRevjvnYZ/HixZozZ049duyYxW0xMTH6ww8/WAygDvti/vxu3LhRP/74Yx00aJDR2kf1cUvZlClT6vHjx/XRo0f6xRdfaN26de22C8/zbN26VStWrKiOjo5xjnuWLFmiISEh+tZbb9ndiYv4OHTokDEcjflz2bFjR33//fftdqKtl7V7925Nnz69xcROqo/Dtg8++ECdnJwshuiBfYp9DLFq1SpdsGCBtmzZUjdt2mSx3nvvvaf58uXTGTNmGK0vly9fri4uLtq2bdskuU9S/d/279y5U0eNGqUTJkwwfoc/ePAgzsRdYWFhGhISYjGEk61FRETohx9+aIydeurUKc2ZM6c2aNBA3dzctHbt2sZMy/v379crV67YstwXIlh7ja5du6bvvPOOOjs7a+PGjVX18Vlpc1J+4MABbdiwoQYHB2vevHntMpF93rhFLVu21LRp0xpnelRV582bp82bN9fs2bPb3eCICWHe5p9++knr1Kmj+fPn1xYtWui0adNU9XErp0KFCmnhwoXtvvn/k2KHSubZL+/evauPHj3SH374QUuXLq21atUyJjQYN26cxQx2ycX69evVxcVFx40bp7du3dLevXuro6Ojzp8/X1Ufv8aDBw9Wk8lkMU6ZPblx44b6+Phonz59dPPmzdq4cWMtXry4Fi1aVLNkyaKTJ09WVcuDkaR8pu5NtnTpUnV0dNRhw4bp33//bSw/e/ashoaGGgP/d+vWTTNlymTXs0nHbmUZu3v58uXLtUyZMpouXTotX768Nm7cWAsXLvxGjT+W3B09elTTpUunnTp1sjjYv3///hszC2FStmbNGk2VKpXWrVtX/f39tUyZMjpu3Djj9vLly2vq1Km1aNGimi5dOrvsih4fMTExum3bNi1RooTmzJkzzjhb8+bN09q1a9vtsC3xdeTIEe3du7e6ubnpgQMHbF1Oojl37pzWq1dPTSaTEUSYQ8W7d+9q+/bt1WQyxQloYD9if/937dpV3dzcNGvWrGoymbRdu3Zxhqpp2bKlpk+fXn/++Wdj2aJFi9TLy0svX7782up+1RYvXmwcIxUsWFBTpUqlnTp1slhn+/bt+vnnn6ubm5vu27fPRpU+XVRUlC5atEhPnjyp169f1+DgYG3btq2qPt6vmkwmrVq16v+1d+dxNebv/8DfR5QmbVRDxWkhbce0qEFZMw2GxpayTEhFohBGtiyJocyHLFOSNWSXQmNNpow2E99kKhFTfJQUI6XO6/dHv3N/OhNmhjHn3Lme/7nvu8fjSufc7/d93df7evPm3kqJtX9ZYmIihgwZAlVVVW6JS11dHXdDLy8vx4MHD+SuOeYfd5H5+eefsXPnTuzdu1dqJ0gPDw+oqqpyybXbt28jPDxc7nbteBcnT55E69atsXbtWhw5coQbeK9evQqgIfFia2uLTp068eYGIHHq1CkoKyvj+++/l3oAlyTXevfuDXNzc+53bk4TLsn3z9fXlxuMHj58CAMDA6mNCerq6lBWVobvvvtOrisvo6OjoampCTU1NcyfP5+rIBg/fjw8PDxkHB35J+Tn56NLly5vTPD+9ttvGDFiBDp27Ahzc/MmyynlyeuqLC9cuAAvLy8cOHAA69evh4ODA2xtbbkXGUDz6ofyMdmxYweWLl2K5cuXczv2Hj16FAoKCpg0aRJiY2Nx+vRpDBw4EN26daNqWjl27949LFu2jLsP5efnw9/fH9bW1li3bh2AhmRFeHg4Nm7cyLtdwx8+fMjNyYGG3+XKlStwdHSEubl5k8qJxq1P+CgjIwNjx46FmZmZ3D18fwhFRUVwcXGBlpYWtzRZkqz5/fff4e/vz7slyx+jrKwsDBkyBKmpqfjvf/+LmTNnwtraGqtWrWrSG3DFihVNxhR5qt76u3799Vfo6upylf4VFRU4dOgQVFRUMHfuXAAN9+WZM2fC1ta2SQWbvJDsXBobG4uePXtyOxTv378f/fr1g1AolOuXw41RYu0Dktygq6urpQbcq1evcmXjkioued7BLjQ0FOPHj+f6Cxw/fhwtW7aEnZ0dWrduDXt7e6neaRMnToSmpiaOHz8OoHn0bnr+/DlGjBjB9cV7/Pgx9PT0MGPGDKnrSktL4ejoyJtEolgsxosXLzB48GDMnz9f6pxk8Kmvr8f58+fh5eUFFxcXXifVGn/H/vhg7urqitjYWDx+/Bi6urrw8fHhrj9x4gSSkpIA8OPzfO/ePamHmPr6ejg5OWHRokUyjIr8U9LS0mBgYCD1XXzd+HHjxg2566XxR2+rsmzfvj0iIyNx6NAhODs74+uvv6YHHR4LDAyEpqYmHBwcYG1tjZYtW3LJ0nPnzqF79+7Q19eHlZUVvvrqK+4eTVW18ueXX35B//79YWlpKbURwZ07dxAQEAArKyusX79ehhG+n/j4ePTo0QNmZmawtbXlEv+SyjVHR0d069aNW6LUHLx48QKXL1/mRQuav6Nxq5Pi4mKpudH9+/cxePBgaGtrc2MLH+Z4pMH+/fvh5OSEMWPGSI0TAQEBsLW1fW1yDeB3+5PGc72MjAx07ty5yXd2//79UFZWxuXLl1FfX4/CwkK5X0IJACEhIbC0tMSTJ08AAAsWLEBERASvXqRSYu0DkXzwExISMGTIEFhaWsLV1RUnT56EWCxGcnIyhg0bhu7du3Ol8fKaWIuPj4dAIMC0adOQm5uL3r17IzIyErW1tbh//z7mz58PW1tbrFixgvsZV1dX6OvrN6l045PGf4+qqipYWFjg3LlzKCkpgZ6eHry9vbnzcXFxUhWIfFJdXQ1zc3NERUUBaBq/ZAkogGbRb6NxyfePP/6IAwcOAGio6LK1tYWBgYHU7nPV1dUYN24cVq5cybvB+NmzZ0hJScHQoUMhEol4Fz+R1jjRq62tzVVSNO4PcvXqVameMXzwpirLcePGcUsCDhw4AGdnZ/Tv35+rdCL88euvv2L06NHIysriqoSXLFmCVq1acffgsrIybhcwyWed7lnyKTMzEy4uLlBVVZVa+gk0VALNmTMHBgYGiIiIkE2A7+HkyZNQUVFBeHg4zp8/j9mzZ0MgECAyMhJAw334p59+gqWlJXr06EGJGDnWeMwUiUQwMTHBp59+KrUR1YMHD7iNf2hs4Y/6+noEBQXByMgIXbt2bfLsMmvWLNjb2+Pbb7/l9bPo68THxyMuLg75+flo2bIl1w9Q8nkvKSmBsbExtxkJX2RnZ0NJSQkODg5wcnKCmpqa3FbZvQkl1j6ghIQEqKioYMmSJbh06RIcHBxgaGiI9PR0AA1vaIcPHw5jY2O5/eBIblRnzpxBixYtMHnyZAwbNkyqJLO0tBRz5sxBr169pHZF4tsOOpLJUeMG35cvX0Z+fj5qamowdOhQrFmzBoaGhvD29uauf/jwISZPnozY2FjeTrAsLCzg6enJ/Vvyd799+zZ++OEHrupFXpO/f9XTp09hamoKHx8fnDx5EgKBgKusLCwshEgkgp6eHne9WCzGwoUL0alTJ94tYxGLxbh48SKGDh2KL7/8kqo/eOp137nnz59DT08Prq6uTc7NmjULCxcu5F0S/E1VlgsWLOCO7dq1Cy4uLtwyAcIPsbGx6Nq1K2xsbPDw4UOpcTIwMBDa2tqvnS/wdTz9WOTk5GDMmDGwsbFp0ne1oKAAQUFB3IZOfFFcXAwnJycu8VJSUgIDAwNYWVlBIBBwS67q6+tx9epV3vXU/RglJiaiTZs2iIiIQF5eHtasWQOBQIBly5Zx86EHDx6gV69e6NKlC6+qYz4mrxsPamtrERYWBmNjY0ydOrVJX7VJkybB09OT988ujaWnp0NdXR1RUVGoqKjAiBEjMHz4cKmWH7W1tbCzs8P27dtlGOm7SU1NxYQJE+Dn58fLRDcl1j6A+vp6VFVVwdnZGaGhoQAakjX6+vqYOXOm1Bc8KSkJ7u7ucjv5aHwjS0lJgYKCAgQCAS5duiR1XX5+vlSSgq9+++03dOnSBbm5uTh48CBat26Nc+fOAQBWrVoFgUCAL774QmrgDQoKgomJCS/6qkk+e3l5eUhPT+f+jhs3boSlpSXCw8Olrp87dy4+//xzriyX76qqqnDw4EFoamqidevWOHjwIICGqoiamhrExcWhffv2EIlE3GDVrl073m688fLlS2RlZXHfY6r+4BfJ9zU1NRWrVq3C4sWLuc00jhw5gnbt2mHEiBHIzc1FWloaFixYAHV1dV7v1vtnVZZ872P0MYqOjkbPnj2hoaHBVQxLEr/Xr1+Hnp4efvrpJ1mGSN5Cch/KyclBYmIijh49yj3A3rhxA+7u7nBwcGiSXOPjeFNSUoKlS5eitLQUJSUlMDMzg4+PD548eQI3NzcIBAKpaici3x49eoThw4dzbVyKi4thZGSEPn36QEFBAQsXLuQqviXVskT+NH4WvXnzJm7fvo3c3FwADfeZ1atX4/PPP4efn1+TOYLkZ5tDcq2goADBwcFYvHgxd+zo0aPo06cPhg4diuPHj+PGjRuYP38+tLW1eZv4l+f2WH+GEmv/ALFYDLFYLPXFr6+vh729PW7duoX79+9zPZskEhMTuW25G1dIyaPk5GT4+Pjg6dOnyMjIgIKCAtzc3KSq1p4+fQqRSISjR4/KMNL3V1NTg1GjRkFLSwstWrRoUkY7e/ZsKCkpITAwEPPmzYOnpyfU1NR4sdNV490/DQwMYGZmBmVlZfj5+eHixYvw8/ODpaUl3N3dERISgm+++QZqamrNroltVlYWBAIBVFRU4OfnJ3Xu1atXuHv3Lvz9/eHj44OQkBDeVaq9CVV/8JMkgfb111/D09MTAoEAixcvRkVFBc6dOwcTExPo6urC0NAQIpGIt0lg4O1VlnydZJGGv19cXBxMTEzQp08flJWVcefy8/Ohq6uLCxcuyDBC8mcku+cZGxtDX18f7du3x5kzZwA09FsbO3Ys+vXrx8sKCaBhGbJkuZhkTr506VIMGTIEFRUVABpeourr66Nt27YoLy+nexIPlJeXY8OGDSguLsajR49gaWkJLy8vAMD8+fMhEAgwb948quSXY42/Z0FBQejSpQt0dXWho6ODRYsW4dWrV3j16hVWrVqFnj17YubMmU0q15rD/Pfu3buwtbXFp59+iqCgIKlzx44dg5ubG1q2bAkzMzOYmJjwei7IZ5RYew+SL3vj7HhmZiby8vJQU1MDU1NTfPvtt+jcuTN8fHy4h4TS0lIMHz6cqzyQdzExMejQoQOmT5+O58+f48qVK1BQUMDo0aNx5swZbntuVVVV3mbHG5P0lFNXV39t/7uwsDCMGDECvXr1gq+vL69KVZOSkqChoYHIyEjU1NQgMTERAoEAU6dOxaVLl7Br1y707dsXvXr1gqurK683KniTp0+fIjU1FXFxcdDR0ZHqlcfHN+ykeWk8AczPz4dQKMSmTZsANCxXUVZWRkBAAHdNTU0N0tLScPPmTbnbTfpdUJVl81BUVISSkhKuubtkh2k7OzvY2Njg7NmzSEhIwFdffQVra2t6sJVjGRkZUFdXx44dO/DgwQM8ePAAEyZMgJqaGtfPMTMzE1999RUGDRr02mbh8uzYsWNwcHBAly5dEBwcjMzMTADAqFGjMG7cOO66WbNmYceOHbz7/T4WYrGYu4+UlZU1qVxau3YtnJycuNYma9euhampKbS1tXnR2P1jFxYWhnbt2uHChQu4ePEiYmJioKioyCVKa2trsWrVKhgbGzdZfcNXf0zeb9q0CUKhEHZ2dsjLy5M6V1tbi4KCAuTl5cn9plXNGSXW3lNpaSl69OiBM2fOIDExES1atMCVK1cAAFFRUVBXV0fPnj2lfmbRokUwMzPjxdJBiV27dqFLly6YOnUqfv/9dy65JhAIMHLkSAwcOJAXVVt/xePHj3Hw4EGMHTsWWlpaSElJAdD0jUdtbS2vHvoqKyvh4+OD5cuXA2jYvcvY2BijRo2Cmpoa3NzcpBKjzaXPhGRgunv3Ln799VduslVVVYUdO3ZAR0cHU6dO5a6Pjo5GXFyc1M8S8qFJGrgD/7vXXLt2Db179wbQkKjQ09PDtGnTuOuayz33TZrDW+aP0fLly2FnZwehUIhBgwbhxIkTABqSpPv27YOJiQkUFRXh6uqK4OBgvHjxAgD1f5QnkrGvrq4O8fHx6N69OyorK6XGxLFjx6Jjx4549uwZgIZloY377PJBZmYm1NXVsWLFCgQEBMDGxgYjR45EZmYmYmJi0KpVKyxZsgSTJk2ClpZWs6lgb04SExOlVlYcOXIE9vb2MDIywvDhwxEdHQ0A8Pb2xhdffMFdN3fuXOzcubPZNbZvLhrfa+rr6zF8+PAmO9tfuHABAoGA2ySlpqYGu3btahZjieT3v3DhAsLCwrhnsm3btsHS0hLTp09Hfn4+dz3Nl+QDJdbeU05ODry8vCAUCqGkpIRDhw5x5yRLytq1awd/f3+EhIRgypQpvFg6WFhYyC1VldixYwdMTEzg7e2N6upqZGZmQiAQIDAwkNd9byQ3r/LycqkGyvX19RgxYgS0tLSQmprKHY+NjUVBQcG/Huf7qqmpwaFDh1BQUIDy8nJYW1tzO+7t27cPAoEAX375Jfe7Naek0pEjR9C+fXsYGhpCV1cXSUlJABqWfEiSa19++SUCAgIgEAiavAki5EO6f/8+lJSU4OzsLHX84sWLMDc3x6VLlyAUCuHj48NNGK9du4bRo0fz8l5Emq8lS5ZAW1sbJ06cwPnz5zFs2DCoqqpyLytevXqFvXv3YsCAARg0aBC3LLS6ulqWYZPXiI+Px7p167B582a0adOGOy75W+Xl5UFPT4+3y3gLCgqwcuVKhISEcMcSEhLQv39/DB8+HHFxcVi7di1EIhH69+8v9/P2j9HDhw9haGiIyZMno7CwEP/3f/8HNTU1hISEYM2aNZg+fToUFRWxZcsWpKSkcJuwjR49GhoaGlyfLiJfGieJJNVXFhYWmDdvHoCG5xNJomnWrFkYMGBAk+fQ5pBcO3z4MDQ1NTF9+nSp1VGbN2+GtbV1k+QakT1KrP0D9u7dC4FAgA4dOiAxMVHqXHFxMbZv3w4rKyv07dsXEydOlPvG0k+ePEGHDh2wcOHCJjt1RUdHQ0FBAb6+vqisrERqamqzGJiOHj2KHj16QCgUIjAwkFsKIBaLMXLkSLRr1w7R0dEICAiAmpoab29kkglxbGwsevbsye2ut3//fvTr1w9CoVCqdx5fSfoeAg2TZ6FQiIiICJw9exZTpkxB69atsW/fPgAN/yenTp3iHvSaW085wg/Jycno1KkTBg8ezB3Lz89Hnz59oKqqKrUkCQDmzZuHgQMHSvWrIkSWkpOTYWNjw1Xtnz59Gqqqqujbty/atGmDw4cPA2hIru3evRu9evWCi4tLs1jCzHeJiYnc7vSSsXPMmDHYsGEDnj9/jq5du8LPz0+qSj8/Px9GRkbc35tPKisr0b17d+jo6EjtPAwAJ0+exIABA+Dq6sqtWKCqJvmVmZmJ7t27w8/PD4sWLcLcuXO5c5WVlYiIiICioiJiYmKwd+9e9O7dGyNHjuQ+70S+NE6qhYeHw9fXF7/99htWrVoFQ0NDpKenA/jffWrx4sUYOHCgTGL9kLKzs6GlpYVt27a99vzmzZthZ2cHDw8PFBYW/svRkTehxNp7kGTDU1JSsG3bNkyfPh2mpqbcToONSW4AfFled/HiRRgYGGD58uVNKtdsbGygqqqKwMBA3lY1NY47PT0d2traWLJkCVatWgWhUIgRI0ZwvUMAwMPDAyYmJvjss8+4pBufhYSEwNLSktvtc8GCBYiIiODN5/NN/vjG6tKlS4iNjUVgYKDUcX9/f6nkmgRNnomsiMVipKSkoEOHDhg0aBB3PCIiAu3atYOfnx/S0tKQnZ2NOXPmQENDAzk5OTKMmJD/efbsGf773/9i4cKFqK+vR1JSEnR0dPDDDz/gzp076NatGz755BPs3LkTQMPD04EDB2Bubo4xY8bQMhYZalz10/jFb9++fREWFoZXr17hu+++g4ODA3x9fVFdXY3S0lIsXboUhoaGTeaIfJGVlQUTExM4ODg06ZWbkJAAKysrjBs3jtvBlsivzMxM2NvbQygUNtmU6unTp/D09OReTj179oz+pjwg2dly3759uHfvHjIzMzFs2DAMHjwYGRkZABrm7M7Ozpg0aZKMo30/ly9fbnLs8OHDcHR0RGVlJZdv+OM4GRYWhj59+nC9TInsUWLtHUiSMhUVFdw2zUBDg1dPT0+Ymppyb2aBhgH61q1bUj/LBykpKdDX18eKFSu4yrUXL15g2rRpCA0N5WWG/MCBA9zfAmioZlq3bh1WrlzJHUtPT4etrS2+/vprqeRaYWEhtzsU32VnZ0NJSQkODg5wcnKCmpoa79/ezZo1CwEBAVLl3yNGjIBAIEC/fv2aLDXy9/eHqqoqdu7cKfU9JuTf9McxISUlBUKhEE5OTtyxdevWwdHREYqKirCysoKNjQ0tSyJyIywsDNOmTcPdu3e5+6ybmxvmz5/Pfb5dXV1hbm4OZ2dn7h5dV1eHQ4cONYtNj/guMzMTdnZ28PLy4jYtGjRoEJcIffToEdatW4euXbuiZcuWEIlEaN++Pe9fNP7yyy+wsrKCj49Pk+RaUlISr3ohf+x++eUXGBgYwNTUtMn4uHDhQnTr1o3mejxx9uxZGBoaNqmGPXHiBFxcXKCiooLu3btDJBLB0tKSKwrg0zO2xPnz56GqqorHjx9LxR8eHo62bdtyVcKNk2rp6enccUmBBJEPlFh7R8ePH4eVlRU+//xzuLm5ccezs7MxZcoUdO3aFRs3bkRwcDBat27NLbnjm5SUFBgYGGDGjBnYt28fFi1aBHNzc17uinT//n04OjqiuLgYQMPNSE9PD8rKypg5c6bUtT///DNsbGwwatQonDp1ShbhfnCpqamYMGEC/Pz8eLWz6ZucPXuW215aMnmqra2Fj48PVFRUpJKkEp6enmjfvj2vewQS/pJMotLS0rB161aEhobi/PnzSE5ORteuXaWSayUlJcjMzERRURHKy8tlFTIhUhpXFUgSZE+fPkXnzp2xevVqAA2VxK6uroiPj5dqik/kS1ZWFmxsbODp6YkbN27A3d0dZ8+elbpGLBZj27ZtuHr1KjeX4jvJ7+3l5SX3rVrI2+Xk5EAkEmHy5MlSybWpU6fCycmJViXwxPbt22FhYcEVMzROKhUWFuL06dNYsWIFtm7dyiWY+LSZXGPV1dXcrrSNE/mXL19G165dsXXrVu5zW1dXB7FYjLFjx2Lz5s0yiZe8nQAAGPlLADCBQMAyMjJY//792axZs5iCggLbvXs3a9u2LTtz5gzT0tJiN27cYDt27GBHjhxhGhoaLCYmhtna2so6/HeWkZHB5syZw+7evcvatGnD9u7dy2xsbGQd1juprq5mysrK7MaNG0xfX5/dvn2bubm5sU6dOrGIiAhmZWXFXZuRkcHGjBnDevXqxaKiotgnn3wiu8A/ELFYzAQCARMIBLIO5b2IxWLWokULxhhjp0+fZseOHWPLli1jurq6rL6+nrm5ubHk5GR27Ngx5ujoKPWzjx49Yp9++qkswiaEHT16lHl6erLBgweze/fuMbFYzEQiEfPw8GDu7u5MJBKxM2fOyDpMQpo4d+4c8/HxYXv27GEODg5S52bMmMFOnTrFPDw82MWLF9nLly9ZamoqU1BQkLpfE/mSnZ3NfHx8mIWFBTty5AjT0dFhRkZGDAATi8VMQUGB6evrs8jISKaoqCjrcP8x2dnZbNq0aczIyIgFBwczU1NTWYdE3lF2djbz8PBgv//+O+vbty9TUlJihw8fZufOnZOa4xP5I3nO3rJlC4uIiGBpaWlMQ0ND6v5z6NAhZmNjw4yNjbmfq6+vZwoKCjKM/P0VFRUxY2NjtnbtWjZ37lxWW1vL3N3dWUlJCRs/fjybPHkye/bsGduyZQuLjo5mycnJzMTERNZhkz+SZVaPj65fv47z588jNDSUO5afnw9LS0tYW1tL7XD16NGjZtOUt6qqCsXFxc3i96msrIRIJMLYsWNRXl6OtLQ0dOzYEZMmTWrSsygzMxN37tyRUaTkXSQkJEAgEMDX15dbwlxXV4eRI0dCS0uLl42WSfN069YtCIVC/PDDDwCA3NxcKCsrY/HixQAaKoaNjY3Ro0cPWYZJyGv9saoAkK7CDAwMhJ2dHUaPHs0t1aFeavIvMzMTIpGI6zG2a9cubNiwAcHBwQgNDW0WFe6vc+3aNfTt27fJpl2Ef3JyctC5c2d06tQJq1evpiW9PJObmwsFBQUEBwdLHX/27BlcXFywadMm2QT2Ab169QrLli2DoqIiwsPDATS0X/rmm28gEomgpKQEW1tb6OnpcatziPyhxNrfUFFRgfbt20MgEGDOnDlS5yTJNXt7e66kk8iv9PR0dO/eHZ6ennjy5AmuXLnCJdck/UUIP0ge5MrKyrglnZcuXYKCggK8vb2lkmtjxoyBQCBAWlqazOIlROLs2bOwtbUFANy5cwdCoRDe3t7c+fT0dJw/fx4WFhbNZtkV4T/JPXfz5s0wNTXlEmtisZhLnB07dgxZWVnc0hWAv0t1PkbZ2dlcz7WPKSnxx16shL8yMjLwxRdfNIuCgI9RZGQkWrVqBX9/f/z444+4dOkSnJ2d0a1bt2YxlkjGxdzcXKSkpHBzvLCwMAgEAoSFhQFoaGlz69Yt7Nq1C0lJSTQXlHOUWPsTf2yEePHiRdjZ2cHOzo77YkuuKSgogK6uLvr3709vZXkgKysLVlZWUsk1IyMjjBo1ivps8MyxY8fg4OCAzp07Y/HixSgrK0NaWtprk2seHh64ffu2jCMmBIiPj4ezszOKioqgr68PHx8frvdUamoqFi1ahLt37+LFixcyjpSQpt5UVVBVVQUXFxds3LiRO8bHptIfu6ysLNjb28PNzQ25ubmyDoeQv40SpfwlFotx/PhxdOrUCXp6erCwsICzszNX/dwc+nQeO3YMKioqMDIygpKSErZt24ZHjx5h/fr1EAgEWL9+vaxDJH8T9Vh7C/z/td5Xr15l169fZxUVFczOzo4pKiqyqVOnMqFQyPW+kVxbVFTEADAjIyMZR0/+iuzsbObp6clsbGxYeHg4u379Ops5cyZLSkpiurq6sg6P/AVZWVlswIABLDAwkJWXl7Pk5GQmFArZxo0bWUlJCXN0dGTe3t5s8eLFTE9PT9bhEsIpLCxkIpGIvXz5ks2cOZNt2LCBOxcQEMBu3brFDh48yDQ0NGQXJCFvERUVxWbMmMF8fX3Z0KFDmaKiIgsNDWUPHz5kmZmZrGXLlrIOkbyH9PR0Nm/ePLZ//37WoUMHWYdDCPnIlJWVscrKSiYWi5mxsTFr0aIFq6ur4/XYIhaLWWVlJRs2bBjz8PBgAwYMYHFxcWzJkiVs9erVbOLEiWz//v0sKCiILV++nH377beyDpn8RZRY+xN/1lj6s88+Y6dOnWKM/S+5RvhF0qzXyMiIRUVFMUVFRaasrCzrsMhfUFhYyPbv388EAgFbtGgRY4yxxMREFhYWxlRVVdmmTZtYaWkp69mzJ/P392fh4eG8b3BKmpcDBw4wLy8vNmPGDDZlyhRWU1PDdu3axaKjo1lKSgqztLSUdYiEvBEAFh8fz/z9/Vl9fT3T0NBgenp6LCEhgbVq1apZNJX+2L18+ZK1bt1a1mEQQgivN7+R5AlevnzJALCQkBA2d+5cpqmpyRhjbMOGDWz27Nlcci0mJoaFh4ezgoIC7hoi3yix9hZ5eXls0KBBLCgoiE2dOpXdunWL2drassDAQLZy5Up25coVNmnSJKajo8NSU1NlHS55D+np6Wzu3LnswIED9FaWJ6qqqpiTkxMrLi5mnp6ebPXq1dy5hIQEFhYWxjQ1Ndn333/PysrKmIqKCjMzM5NhxIQ09erVK7Zv3z7m7+/P1NTUmJqaGmvVqhXbsWMHs7a2lnV4hPwlzbGqgBBCCPknnThxgm3dupUVFxczACwuLo5169aNO79hwwY2f/58FhQUxHx9fVmrVq1Y27ZtZRgx+TsosfYW586dYwsWLGAZGRmsqKiI9e/fnzk7O7OoqCjGGGMZGRmsqqqK+fv7s9OnT7OOHTvKOGLyPuitLP9kZ2czd3d3pq2tzSIjI5mFhQV37tSpU2zhwoXMzMyM7dmzhx7wiFx78OABu3v3LlNVVWV6enpMS0tL1iER8s74XFVACCGE/NMyMjKYk5MTGz9+PKuurmaxsbFs+vTpbPbs2UwoFHLXrVmzhq1du5bl5+ezdu3ayTBi8ndRYu0tTp48yTZt2sQiIyNZ79692ZAhQ9iWLVuYgoICS0tLY4mJiczb25vp6OjQ0kFCZCQnJ4dNnDiR2dvbM39/f6nk2o8//si6du0qNWARQgghhBBCyL+hsLCQ7d69mykrK7MFCxYwxhjbunUrCw0NZRMmTGDTpk2TelapqKig5Z88RK8T38Lc3JylpKQwIyMjNnLkSBYZGcn1Cjlw4AC7du0aU1dXp6QaITLUrVs3FhMTwzIyMth//vMflpuby51zdnampBohhBBCCCHkX1dVVcXc3d3Zli1b2LNnz7jjvr6+bMGCBWzPnj1s27ZtrKioiDtHm1bxEyXW3sLY2JjFxMSwTz75hCkrK7P8/Hx28+ZNNm/ePLZ79262fv16+uATIgesra1ZdHQ0y8nJYStXrmR5eXmyDokQQgghhBDyEVNTU2NRUVFMU1OTJScns5s3b3Ln/Pz82OLFi1l4eDjbs2cPq6urY4wx2gyRp2gp6J+gxtKE8Ed6ejqbN28e279/P21CQQghhBBCCJG5t7Wu2b59O+vTpw/r0qWLDCMk74sSa38RNZYmhB9oEwpCCCGEEEKIPMnOzmZeXl7MxsaGzZ49m5mbm8s6JPIPosQaIYQQQgghhBBCyAeUnZ3Npk2bxoyMjFhwcDAzNTWVdUjkH0I91gghhBBCCCGEEEI+IGtra7Zp0yZWWlrK1NXVZR0O+QdRxRohhBBCCCGEEELIv4Ba1zQ/lFgjhBBCCCGEEEIIIeQd0FJQQgghhBBCCCGEEELeASXWCCGEEEIIIYQQQgh5B5RYI4QQQgghhBBCCCHkHVBijRBCCCGEEEIIIYSQd0CJNUIIIYQQQgghhBBC3gEl1gghhBBCCCGEEEIIeQeUWCOEEEIIIYQQQggh5B1QYo0QQgghhBBCCCGEkHdAiTVCCCGEEEIIIYQQQt7B/wOMM7wvSnjWrQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Publisher_10ton  Publisher_11  Publisher_17  Publisher_1c  \\\n",
      "0                  0.0           0.0           0.0           0.0   \n",
      "1                  0.0           0.0           0.0           0.0   \n",
      "2                  0.0           0.0           0.0           0.0   \n",
      "3                  0.0           0.0           0.0           0.0   \n",
      "4                  0.0           0.0           0.0           0.0   \n",
      "...                ...           ...           ...           ...   \n",
      "10778              0.0           0.0           0.0           0.0   \n",
      "10779              0.0           0.0           0.0           0.0   \n",
      "10780              0.0           0.0           0.0           0.0   \n",
      "10781              0.0           0.0           0.0           0.0   \n",
      "10782              0.0           0.0           0.0           0.0   \n",
      "\n",
      "       Publisher_2k  Publisher_3d  Publisher_3do  Publisher_505  \\\n",
      "0               0.0           0.0            0.0            0.0   \n",
      "1               0.0           0.0            0.0            0.0   \n",
      "2               0.0           0.0            0.0            0.0   \n",
      "3               0.0           0.0            0.0            0.0   \n",
      "4               0.0           0.0            0.0            0.0   \n",
      "...             ...           ...            ...            ...   \n",
      "10778           0.0           0.0            0.0            0.0   \n",
      "10779           0.0           0.0            0.0            0.0   \n",
      "10780           0.0           0.0            0.0            0.0   \n",
      "10781           0.0           0.0            0.0            0.0   \n",
      "10782           0.0           0.0            0.0            0.0   \n",
      "\n",
      "       Publisher_acclaim  Publisher_activis  Publisher_adventur  \\\n",
      "0                    0.0                0.0                 0.0   \n",
      "1                    0.0                0.0                 0.0   \n",
      "2                    0.0                0.0                 0.0   \n",
      "3                    0.0                0.0                 0.0   \n",
      "4                    0.0                0.0                 0.0   \n",
      "...                  ...                ...                 ...   \n",
      "10778                0.0                0.0                 0.0   \n",
      "10779                0.0                0.0                 0.0   \n",
      "10780                0.0                0.0                 0.0   \n",
      "10781                0.0                0.0                 0.0   \n",
      "10782                0.0                0.0                 0.0   \n",
      "\n",
      "       Publisher_agetec  Publisher_aksi  Publisher_america  \\\n",
      "0                   0.0             0.0                0.0   \n",
      "1                   0.0             0.0                0.0   \n",
      "2                   0.0             0.0                0.0   \n",
      "3                   0.0             0.0                0.0   \n",
      "4                   0.0             0.0                0.0   \n",
      "...                 ...             ...                ...   \n",
      "10778               0.0             0.0                0.0   \n",
      "10779               0.0             0.0                0.0   \n",
      "10780               0.0             0.0                0.0   \n",
      "10781               0.0             0.0                0.0   \n",
      "10782               0.0             0.0                0.0   \n",
      "\n",
      "       Publisher_annapurna  Publisher_arc  Publisher_art  Publisher_aspyr  \\\n",
      "0                      0.0            0.0       0.000000              0.0   \n",
      "1                      0.0            0.0       0.706743              0.0   \n",
      "2                      0.0            0.0       0.000000              0.0   \n",
      "3                      0.0            0.0       0.000000              0.0   \n",
      "4                      0.0            0.0       0.000000              0.0   \n",
      "...                    ...            ...            ...              ...   \n",
      "10778                  0.0            0.0       0.000000              0.0   \n",
      "10779                  0.0            0.0       0.000000              0.0   \n",
      "10780                  0.0            0.0       0.000000              0.0   \n",
      "10781                  0.0            0.0       0.000000              0.0   \n",
      "10782                  0.0            0.0       0.000000              0.0   \n",
      "\n",
      "       Publisher_atari  Publisher_atlu  Publisher_bam  Publisher_bandai  \\\n",
      "0                  0.0             0.0            0.0               0.0   \n",
      "1                  0.0             0.0            0.0               0.0   \n",
      "2                  0.0             0.0            0.0               0.0   \n",
      "3                  0.0             0.0            0.0               0.0   \n",
      "4                  0.0             0.0            0.0               0.0   \n",
      "...                ...             ...            ...               ...   \n",
      "10778              0.0             0.0            0.0               0.0   \n",
      "10779              0.0             0.0            0.0               0.0   \n",
      "10780              0.0             0.0            0.0               0.0   \n",
      "10781              0.0             0.0            0.0               0.0   \n",
      "10782              0.0             0.0            0.0               0.0   \n",
      "\n",
      "       Publisher_bethesda  Publisher_big  Publisher_bigben  ...  \\\n",
      "0                0.000000            0.0               0.0  ...   \n",
      "1                0.000000            0.0               0.0  ...   \n",
      "2                0.000000            0.0               0.0  ...   \n",
      "3                0.000000            0.0               0.0  ...   \n",
      "4                0.000000            0.0               0.0  ...   \n",
      "...                   ...            ...               ...  ...   \n",
      "10778            0.000000            0.0               0.0  ...   \n",
      "10779            0.000000            0.0               0.0  ...   \n",
      "10780            0.000000            0.0               0.0  ...   \n",
      "10781            0.000000            0.0               0.0  ...   \n",
      "10782            0.708515            0.0               0.0  ...   \n",
      "\n",
      "       Publisher_system  Publisher_taketwo  Publisher_tdk  Publisher_team  \\\n",
      "0                   0.0                0.0            0.0             0.0   \n",
      "1                   0.0                0.0            0.0             0.0   \n",
      "2                   0.0                0.0            0.0             0.0   \n",
      "3                   0.0                0.0            0.0             0.0   \n",
      "4                   0.0                0.0            0.0             0.0   \n",
      "...                 ...                ...            ...             ...   \n",
      "10778               0.0                0.0            0.0             0.0   \n",
      "10779               0.0                0.0            0.0             0.0   \n",
      "10780               0.0                0.0            0.0             0.0   \n",
      "10781               0.0                0.0            0.0             0.0   \n",
      "10782               0.0                0.0            0.0             0.0   \n",
      "\n",
      "       Publisher_team17  Publisher_technolog  Publisher_tecmo  \\\n",
      "0                   0.0                  0.0              0.0   \n",
      "1                   0.0                  0.0              0.0   \n",
      "2                   0.0                  0.0              0.0   \n",
      "3                   0.0                  0.0              0.0   \n",
      "4                   0.0                  0.0              0.0   \n",
      "...                 ...                  ...              ...   \n",
      "10778               0.0                  0.0              0.0   \n",
      "10779               0.0                  0.0              0.0   \n",
      "10780               0.0                  0.0              0.0   \n",
      "10781               0.0                  0.0              0.0   \n",
      "10782               0.0                  0.0              0.0   \n",
      "\n",
      "       Publisher_telltal  Publisher_thq  Publisher_tripwir  Publisher_ubisoft  \\\n",
      "0                    0.0            0.0                0.0                0.0   \n",
      "1                    0.0            0.0                0.0                0.0   \n",
      "2                    0.0            0.0                0.0                0.0   \n",
      "3                    0.0            0.0                0.0                0.0   \n",
      "4                    0.0            0.0                0.0                0.0   \n",
      "...                  ...            ...                ...                ...   \n",
      "10778                0.0            0.0                0.0                0.0   \n",
      "10779                0.0            0.0                0.0                0.0   \n",
      "10780                0.0            0.0                0.0                0.0   \n",
      "10781                0.0            0.0                0.0                0.0   \n",
      "10782                0.0            0.0                0.0                0.0   \n",
      "\n",
      "       Publisher_univers  Publisher_valv  Publisher_versu  Publisher_vista  \\\n",
      "0                    0.0             0.0              0.0              0.0   \n",
      "1                    0.0             0.0              0.0              0.0   \n",
      "2                    0.0             0.0              0.0              0.0   \n",
      "3                    0.0             0.0              0.0              0.0   \n",
      "4                    0.0             0.0              0.0              0.0   \n",
      "...                  ...             ...              ...              ...   \n",
      "10778                0.0             0.0              0.0              0.0   \n",
      "10779                0.0             0.0              0.0              0.0   \n",
      "10780                0.0             0.0              0.0              0.0   \n",
      "10781                0.0             0.0              0.0              0.0   \n",
      "10782                0.0             0.0              0.0              0.0   \n",
      "\n",
      "       Publisher_viva  Publisher_vivendi  Publisher_vu  Publisher_warner  \\\n",
      "0                 0.0                0.0           0.0               0.0   \n",
      "1                 0.0                0.0           0.0               0.0   \n",
      "2                 0.0                0.0           0.0               0.0   \n",
      "3                 0.0                0.0           0.0               0.0   \n",
      "4                 0.0                0.0           0.0               0.0   \n",
      "...               ...                ...           ...               ...   \n",
      "10778             0.0                0.0           0.0               0.0   \n",
      "10779             0.0                0.0           0.0               0.0   \n",
      "10780             0.0                0.0           0.0               0.0   \n",
      "10781             0.0                0.0           0.0               0.0   \n",
      "10782             0.0                0.0           0.0               0.0   \n",
      "\n",
      "       Publisher_wayforward  Publisher_wire  Publisher_work  Publisher_world  \\\n",
      "0                       0.0             0.0             0.0              0.0   \n",
      "1                       0.0             0.0             0.0              0.0   \n",
      "2                       0.0             0.0             0.0              0.0   \n",
      "3                       0.0             0.0             0.0              0.0   \n",
      "4                       0.0             0.0             0.0              0.0   \n",
      "...                     ...             ...             ...              ...   \n",
      "10778                   0.0             0.0             0.0              0.0   \n",
      "10779                   0.0             0.0             0.0              0.0   \n",
      "10780                   0.0             0.0             0.0              0.0   \n",
      "10781                   0.0             0.0             0.0              0.0   \n",
      "10782                   0.0             0.0             0.0              0.0   \n",
      "\n",
      "       Publisher_xbox  Publisher_xseed  \n",
      "0                 0.0              0.0  \n",
      "1                 0.0              0.0  \n",
      "2                 0.0              0.0  \n",
      "3                 0.0              0.0  \n",
      "4                 0.0              0.0  \n",
      "...               ...              ...  \n",
      "10778             0.0              0.0  \n",
      "10779             0.0              0.0  \n",
      "10780             0.0              0.0  \n",
      "10781             0.0              0.0  \n",
      "10782             0.0              0.0  \n",
      "\n",
      "[10783 rows x 161 columns]\n",
      "      Publisher_10ton  Publisher_11  Publisher_17  Publisher_1c  Publisher_2k  \\\n",
      "0                 0.0           0.0           0.0           0.0           0.0   \n",
      "1                 0.0           0.0           0.0           0.0           0.0   \n",
      "2                 0.0           0.0           0.0           0.0           0.0   \n",
      "3                 0.0           0.0           0.0           0.0           0.0   \n",
      "4                 0.0           0.0           0.0           0.0           0.0   \n",
      "...               ...           ...           ...           ...           ...   \n",
      "3590              0.0           0.0           0.0           0.0           0.0   \n",
      "3591              0.0           0.0           0.0           0.0           0.0   \n",
      "3592              0.0           0.0           0.0           0.0           0.0   \n",
      "3593              0.0           0.0           0.0           0.0           1.0   \n",
      "3594              0.0           0.0           0.0           0.0           0.0   \n",
      "\n",
      "      Publisher_3d  Publisher_3do  Publisher_505  Publisher_acclaim  \\\n",
      "0              0.0            0.0            0.0                0.0   \n",
      "1              0.0            0.0            0.0                0.0   \n",
      "2              0.0            0.0            0.0                0.0   \n",
      "3              0.0            0.0            0.0                0.0   \n",
      "4              0.0            0.0            0.0                0.0   \n",
      "...            ...            ...            ...                ...   \n",
      "3590           0.0            0.0            0.0                0.0   \n",
      "3591           0.0            0.0            0.0                0.0   \n",
      "3592           0.0            0.0            0.0                0.0   \n",
      "3593           0.0            0.0            0.0                0.0   \n",
      "3594           0.0            0.0            0.0                0.0   \n",
      "\n",
      "      Publisher_activis  Publisher_adventur  Publisher_agetec  Publisher_aksi  \\\n",
      "0                   0.0                 0.0               0.0             0.0   \n",
      "1                   0.0                 0.0               0.0             0.0   \n",
      "2                   0.0                 0.0               0.0             0.0   \n",
      "3                   0.0                 0.0               0.0             0.0   \n",
      "4                   0.0                 0.0               0.0             0.0   \n",
      "...                 ...                 ...               ...             ...   \n",
      "3590                0.0                 0.0               0.0             0.0   \n",
      "3591                0.0                 0.0               0.0             0.0   \n",
      "3592                0.0                 0.0               0.0             0.0   \n",
      "3593                0.0                 0.0               0.0             0.0   \n",
      "3594                0.0                 0.0               0.0             0.0   \n",
      "\n",
      "      Publisher_america  Publisher_annapurna  Publisher_arc  Publisher_art  \\\n",
      "0                   0.0                  0.0            0.0       0.000000   \n",
      "1                   0.0                  0.0            0.0       0.000000   \n",
      "2                   0.0                  0.0            0.0       0.000000   \n",
      "3                   0.0                  0.0            0.0       0.000000   \n",
      "4                   0.0                  0.0            0.0       0.000000   \n",
      "...                 ...                  ...            ...            ...   \n",
      "3590                0.0                  0.0            0.0       0.000000   \n",
      "3591                0.0                  0.0            0.0       0.000000   \n",
      "3592                0.0                  0.0            0.0       0.706743   \n",
      "3593                0.0                  0.0            0.0       0.000000   \n",
      "3594                0.0                  0.0            0.0       0.000000   \n",
      "\n",
      "      Publisher_aspyr  Publisher_atari  Publisher_atlu  Publisher_bam  \\\n",
      "0                 0.0              0.0             0.0            0.0   \n",
      "1                 0.0              0.0             0.0            0.0   \n",
      "2                 0.0              0.0             0.0            0.0   \n",
      "3                 0.0              0.0             0.0            0.0   \n",
      "4                 0.0              0.0             0.0            0.0   \n",
      "...               ...              ...             ...            ...   \n",
      "3590              0.0              0.0             0.0            0.0   \n",
      "3591              0.0              0.0             0.0            0.0   \n",
      "3592              0.0              0.0             0.0            0.0   \n",
      "3593              0.0              0.0             0.0            0.0   \n",
      "3594              0.0              0.0             0.0            0.0   \n",
      "\n",
      "      Publisher_bandai  Publisher_bethesda  Publisher_big  Publisher_bigben  \\\n",
      "0                  0.0                 0.0            0.0               0.0   \n",
      "1                  0.0                 0.0            0.0               0.0   \n",
      "2                  0.0                 0.0            0.0               0.0   \n",
      "3                  0.0                 0.0            0.0               0.0   \n",
      "4                  0.0                 0.0            0.0               0.0   \n",
      "...                ...                 ...            ...               ...   \n",
      "3590               0.0                 0.0            0.0               0.0   \n",
      "3591               0.0                 0.0            0.0               0.0   \n",
      "3592               0.0                 0.0            0.0               0.0   \n",
      "3593               0.0                 0.0            0.0               0.0   \n",
      "3594               0.0                 0.0            0.0               0.0   \n",
      "\n",
      "      ...  Publisher_system  Publisher_taketwo  Publisher_tdk  Publisher_team  \\\n",
      "0     ...               0.0                0.0            0.0             0.0   \n",
      "1     ...               0.0                0.0            0.0             0.0   \n",
      "2     ...               0.0                0.0            0.0             0.0   \n",
      "3     ...               0.0                0.0            0.0             0.0   \n",
      "4     ...               0.0                0.0            0.0             0.0   \n",
      "...   ...               ...                ...            ...             ...   \n",
      "3590  ...               0.0                0.0            0.0             0.0   \n",
      "3591  ...               0.0                0.0            0.0             0.0   \n",
      "3592  ...               0.0                0.0            0.0             0.0   \n",
      "3593  ...               0.0                0.0            0.0             0.0   \n",
      "3594  ...               0.0                0.0            0.0             0.0   \n",
      "\n",
      "      Publisher_team17  Publisher_technolog  Publisher_tecmo  \\\n",
      "0                  0.0                  0.0              0.0   \n",
      "1                  0.0                  0.0              0.0   \n",
      "2                  0.0                  0.0              0.0   \n",
      "3                  0.0                  0.0              0.0   \n",
      "4                  0.0                  0.0              0.0   \n",
      "...                ...                  ...              ...   \n",
      "3590               0.0                  0.0              0.0   \n",
      "3591               0.0                  0.0              0.0   \n",
      "3592               0.0                  0.0              0.0   \n",
      "3593               0.0                  0.0              0.0   \n",
      "3594               0.0                  0.0              0.0   \n",
      "\n",
      "      Publisher_telltal  Publisher_thq  Publisher_tripwir  Publisher_ubisoft  \\\n",
      "0                   0.0            0.0                0.0                0.0   \n",
      "1                   0.0            0.0                0.0                0.0   \n",
      "2                   0.0            0.0                0.0                0.0   \n",
      "3                   0.0            0.0                0.0                0.0   \n",
      "4                   0.0            0.0                0.0                0.0   \n",
      "...                 ...            ...                ...                ...   \n",
      "3590                0.0            0.0                0.0                0.0   \n",
      "3591                0.0            0.0                0.0                0.0   \n",
      "3592                0.0            0.0                0.0                0.0   \n",
      "3593                0.0            0.0                0.0                0.0   \n",
      "3594                0.0            0.0                0.0                0.0   \n",
      "\n",
      "      Publisher_univers  Publisher_valv  Publisher_versu  Publisher_vista  \\\n",
      "0                   0.0             0.0              0.0              0.0   \n",
      "1                   0.0             0.0              0.0              0.0   \n",
      "2                   0.0             0.0              0.0              0.0   \n",
      "3                   0.0             0.0              0.0              0.0   \n",
      "4                   0.0             0.0              0.0              0.0   \n",
      "...                 ...             ...              ...              ...   \n",
      "3590                0.0             0.0              0.0              0.0   \n",
      "3591                0.0             0.0              0.0              0.0   \n",
      "3592                0.0             0.0              0.0              0.0   \n",
      "3593                0.0             0.0              0.0              0.0   \n",
      "3594                0.0             0.0              0.0              0.0   \n",
      "\n",
      "      Publisher_viva  Publisher_vivendi  Publisher_vu  Publisher_warner  \\\n",
      "0                0.0                0.0           0.0               0.0   \n",
      "1                0.0                0.0           0.0               0.0   \n",
      "2                0.0                0.0           0.0               0.0   \n",
      "3                0.0                0.0           0.0               0.0   \n",
      "4                0.0                0.0           0.0               0.0   \n",
      "...              ...                ...           ...               ...   \n",
      "3590             0.0                0.0           0.0               0.0   \n",
      "3591             0.0                0.0           0.0               0.0   \n",
      "3592             0.0                0.0           0.0               0.0   \n",
      "3593             0.0                0.0           0.0               0.0   \n",
      "3594             0.0                0.0           0.0               0.0   \n",
      "\n",
      "      Publisher_wayforward  Publisher_wire  Publisher_work  Publisher_world  \\\n",
      "0                      0.0             0.0             0.0              0.0   \n",
      "1                      0.0             0.0             0.0              0.0   \n",
      "2                      0.0             0.0             0.0              0.0   \n",
      "3                      0.0             0.0             0.0              0.0   \n",
      "4                      0.0             0.0             0.0              0.0   \n",
      "...                    ...             ...             ...              ...   \n",
      "3590                   0.0             0.0             0.0              0.0   \n",
      "3591                   0.0             0.0             0.0              0.0   \n",
      "3592                   0.0             0.0             0.0              0.0   \n",
      "3593                   0.0             0.0             0.0              0.0   \n",
      "3594                   0.0             0.0             0.0              0.0   \n",
      "\n",
      "      Publisher_xbox  Publisher_xseed  \n",
      "0                0.0              0.0  \n",
      "1                0.0              0.0  \n",
      "2                0.0              0.0  \n",
      "3                0.0              0.0  \n",
      "4                0.0              0.0  \n",
      "...              ...              ...  \n",
      "3590             0.0              0.0  \n",
      "3591             0.0              0.0  \n",
      "3592             0.0              0.0  \n",
      "3593             0.0              0.0  \n",
      "3594             0.0              0.0  \n",
      "\n",
      "[3595 rows x 161 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Developer_1  Developer_10ton  Developer_2k  Developer_3do  Developer_5  \\\n",
      "0              0.0              0.0           0.0            0.0          0.0   \n",
      "1              0.0              0.0           0.0            0.0          0.0   \n",
      "2              0.0              0.0           0.0            0.0          0.0   \n",
      "3              0.0              0.0           0.0            0.0          0.0   \n",
      "4              0.0              0.0           0.0            0.0          0.0   \n",
      "...            ...              ...           ...            ...          ...   \n",
      "10778          0.0              0.0           0.0            0.0          0.0   \n",
      "10779          0.0              0.0           0.0            0.0          0.0   \n",
      "10780          0.0              0.0           0.0            0.0          0.0   \n",
      "10781          0.0              0.0           0.0            0.0          0.0   \n",
      "10782          0.0              0.0           0.0            0.0          0.0   \n",
      "\n",
      "       Developer_5pb  Developer_6  Developer_7  Developer_989  Developer_ab  \\\n",
      "0                0.0          0.0          0.0            0.0           0.0   \n",
      "1                0.0          0.0          0.0            0.0           0.0   \n",
      "2                0.0          0.0          0.0            0.0           0.0   \n",
      "3                0.0          0.0          0.0            0.0           0.0   \n",
      "4                0.0          0.0          0.0            0.0           0.0   \n",
      "...              ...          ...          ...            ...           ...   \n",
      "10778            0.0          0.0          0.0            0.0           0.0   \n",
      "10779            0.0          0.0          0.0            0.0           0.0   \n",
      "10780            0.0          0.0          0.0            0.0           0.0   \n",
      "10781            0.0          0.0          0.0            0.0           0.0   \n",
      "10782            0.0          0.0          0.0            0.0           0.0   \n",
      "\n",
      "       Developer_acclaim  Developer_ace  Developer_acquir  Developer_amaz  \\\n",
      "0                    0.0            0.0               0.0             0.0   \n",
      "1                    0.0            0.0               0.0             0.0   \n",
      "2                    0.0            0.0               0.0             0.0   \n",
      "3                    0.0            0.0               0.0             0.0   \n",
      "4                    0.0            0.0               0.0             0.0   \n",
      "...                  ...            ...               ...             ...   \n",
      "10778                0.0            0.0               0.0             0.0   \n",
      "10779                0.0            0.0               0.0             0.0   \n",
      "10780                0.0            0.0               0.0             0.0   \n",
      "10781                0.0            0.0               0.0             0.0   \n",
      "10782                0.0            0.0               0.0             0.0   \n",
      "\n",
      "       Developer_angel  Developer_ant  Developer_arc  Developer_argonaut  \\\n",
      "0                  0.0            0.0            0.0                 0.0   \n",
      "1                  0.0            0.0            0.0                 0.0   \n",
      "2                  0.0            0.0            0.0                 0.0   \n",
      "3                  0.0            0.0            0.0                 0.0   \n",
      "4                  0.0            0.0            0.0                 0.0   \n",
      "...                ...            ...            ...                 ...   \n",
      "10778              0.0            0.0            0.0                 0.0   \n",
      "10779              0.0            0.0            0.0                 0.0   \n",
      "10780              0.0            0.0            0.0                 0.0   \n",
      "10781              0.0            0.0            0.0                 0.0   \n",
      "10782              0.0            0.0            0.0                 0.0   \n",
      "\n",
      "       Developer_arkan  Developer_art  Developer_artifici  Developer_asobo  \\\n",
      "0                  0.0            0.0                 0.0              0.0   \n",
      "1                  0.0            0.0                 0.0              0.0   \n",
      "2                  0.0            0.0                 0.0              0.0   \n",
      "3                  0.0            0.0                 0.0              0.0   \n",
      "4                  0.0            0.0                 0.0              0.0   \n",
      "...                ...            ...                 ...              ...   \n",
      "10778              0.0            0.0                 0.0              0.0   \n",
      "10779              0.0            0.0                 0.0              0.0   \n",
      "10780              0.0            0.0                 0.0              0.0   \n",
      "10781              0.0            0.0                 0.0              0.0   \n",
      "10782              0.0            0.0                 0.0              0.0   \n",
      "\n",
      "       Developer_assembl  Developer_atari  Developer_atlu  ...  \\\n",
      "0                    0.0              0.0             0.0  ...   \n",
      "1                    0.0              0.0             0.0  ...   \n",
      "2                    0.0              0.0             0.0  ...   \n",
      "3                    0.0              0.0             0.0  ...   \n",
      "4                    0.0              0.0             0.0  ...   \n",
      "...                  ...              ...             ...  ...   \n",
      "10778                0.0              0.0             0.0  ...   \n",
      "10779                0.0              0.0             0.0  ...   \n",
      "10780                0.0              0.0             0.0  ...   \n",
      "10781                0.0              0.0             0.0  ...   \n",
      "10782                0.0              0.0             0.0  ...   \n",
      "\n",
      "       Developer_triac  Developer_tt  Developer_two  Developer_ubisoft  \\\n",
      "0                  0.0           0.0            0.0                0.0   \n",
      "1                  0.0           0.0            0.0                0.0   \n",
      "2                  0.0           0.0            0.0                0.0   \n",
      "3                  0.0           0.0            0.0                0.0   \n",
      "4                  0.0           0.0            0.0                0.0   \n",
      "...                ...           ...            ...                ...   \n",
      "10778              0.0           0.0            0.0                0.0   \n",
      "10779              0.0           0.0            0.0                0.0   \n",
      "10780              0.0           0.0            0.0                0.0   \n",
      "10781              0.0           0.0            0.0                0.0   \n",
      "10782              0.0           0.0            0.0                0.0   \n",
      "\n",
      "       Developer_unlimit  Developer_valv  Developer_vancouv  Developer_vicari  \\\n",
      "0                    0.0             0.0                0.0               0.0   \n",
      "1                    0.0             0.0                0.0               0.0   \n",
      "2                    0.0             0.0                0.0               0.0   \n",
      "3                    0.0             0.0                0.0               0.0   \n",
      "4                    0.0             0.0                0.0               0.0   \n",
      "...                  ...             ...                ...               ...   \n",
      "10778                0.0             0.0                0.0               0.0   \n",
      "10779                0.0             0.0                0.0               0.0   \n",
      "10780                0.0             0.0                0.0               0.0   \n",
      "10781                0.0             0.0                0.0               0.0   \n",
      "10782                0.0             0.0                0.0               0.0   \n",
      "\n",
      "       Developer_viciou  Developer_view  Developer_vision  Developer_visual  \\\n",
      "0                   0.0             0.0               0.0               0.0   \n",
      "1                   0.0             0.0               0.0               0.0   \n",
      "2                   0.0             0.0               0.0               0.0   \n",
      "3                   0.0             0.0               0.0               0.0   \n",
      "4                   0.0             0.0               0.0               0.0   \n",
      "...                 ...             ...               ...               ...   \n",
      "10778               0.0             0.0               0.0               0.0   \n",
      "10779               0.0             0.0               0.0               0.0   \n",
      "10780               0.0             0.0               0.0               0.0   \n",
      "10781               0.0             0.0               0.0               0.0   \n",
      "10782               0.0             0.0               0.0               0.0   \n",
      "\n",
      "       Developer_volit  Developer_voltag  Developer_wale  Developer_ward  \\\n",
      "0                  0.0               0.0             0.0             0.0   \n",
      "1                  0.0               0.0             0.0             0.0   \n",
      "2                  0.0               0.0             0.0             0.0   \n",
      "3                  0.0               0.0             0.0             0.0   \n",
      "4                  0.0               0.0             0.0             0.0   \n",
      "...                ...               ...             ...             ...   \n",
      "10778              0.0               0.0             0.0             0.0   \n",
      "10779              0.0               0.0             0.0             0.0   \n",
      "10780              0.0               0.0             0.0             0.0   \n",
      "10781              0.0               0.0             0.0             0.0   \n",
      "10782              0.0               0.0             0.0             0.0   \n",
      "\n",
      "       Developer_way  Developer_wayforward  Developer_white  Developer_work  \\\n",
      "0                0.0                   0.0              0.0             0.0   \n",
      "1                0.0                   0.0              0.0             0.0   \n",
      "2                0.0                   0.0              0.0             0.0   \n",
      "3                0.0                   0.0              0.0             0.0   \n",
      "4                0.0                   0.0              0.0             0.0   \n",
      "...              ...                   ...              ...             ...   \n",
      "10778            0.0                   0.0              0.0             0.0   \n",
      "10779            0.0                   0.0              0.0             0.0   \n",
      "10780            0.0                   0.0              0.0             0.0   \n",
      "10781            0.0                   0.0              0.0             0.0   \n",
      "10782            0.0                   0.0              0.0             0.0   \n",
      "\n",
      "       Developer_world  Developer_yuke  Developer_zaxi  Developer_zenimax  \\\n",
      "0                  0.0             0.0             0.0                0.0   \n",
      "1                  0.0             0.0             0.0                0.0   \n",
      "2                  0.0             0.0             0.0                0.0   \n",
      "3                  0.0             0.0             0.0                0.0   \n",
      "4                  0.0             0.0             0.0                0.0   \n",
      "...                ...             ...             ...                ...   \n",
      "10778              0.0             0.0             0.0                0.0   \n",
      "10779              0.0             0.0             0.0                0.0   \n",
      "10780              0.0             0.0             0.0                0.0   \n",
      "10781              0.0             0.0             0.0                0.0   \n",
      "10782              0.0             0.0             0.0                0.0   \n",
      "\n",
      "       Developer_zoink  \n",
      "0                  0.0  \n",
      "1                  0.0  \n",
      "2                  0.0  \n",
      "3                  0.0  \n",
      "4                  0.0  \n",
      "...                ...  \n",
      "10778              0.0  \n",
      "10779              0.0  \n",
      "10780              0.0  \n",
      "10781              0.0  \n",
      "10782              0.0  \n",
      "\n",
      "[10783 rows x 338 columns]\n",
      "      Developer_1  Developer_10ton  Developer_2k  Developer_3do  Developer_5  \\\n",
      "0             0.0              0.0           0.0            0.0          0.0   \n",
      "1             0.0              0.0           0.0            0.0          0.0   \n",
      "2             0.0              0.0           0.0            0.0          0.0   \n",
      "3             0.0              0.0           0.0            0.0          0.0   \n",
      "4             0.0              0.0           0.0            0.0          0.0   \n",
      "...           ...              ...           ...            ...          ...   \n",
      "3590          0.0              0.0           0.0            0.0          0.0   \n",
      "3591          0.0              0.0           0.0            0.0          0.0   \n",
      "3592          0.0              0.0           0.0            0.0          0.0   \n",
      "3593          0.0              0.0           0.0            0.0          0.0   \n",
      "3594          0.0              0.0           0.0            0.0          0.0   \n",
      "\n",
      "      Developer_5pb  Developer_6  Developer_7  Developer_989  Developer_ab  \\\n",
      "0               0.0          0.0          0.0            0.0           0.0   \n",
      "1               0.0          0.0          0.0            0.0           0.0   \n",
      "2               0.0          0.0          0.0            0.0           0.0   \n",
      "3               0.0          0.0          0.0            0.0           0.0   \n",
      "4               0.0          0.0          0.0            0.0           0.0   \n",
      "...             ...          ...          ...            ...           ...   \n",
      "3590            0.0          0.0          0.0            0.0           0.0   \n",
      "3591            0.0          0.0          0.0            0.0           0.0   \n",
      "3592            0.0          0.0          0.0            0.0           0.0   \n",
      "3593            0.0          0.0          0.0            0.0           0.0   \n",
      "3594            0.0          0.0          0.0            0.0           0.0   \n",
      "\n",
      "      Developer_acclaim  Developer_ace  Developer_acquir  Developer_amaz  \\\n",
      "0                   0.0            0.0               0.0             0.0   \n",
      "1                   0.0            0.0               0.0             0.0   \n",
      "2                   0.0            0.0               0.0             0.0   \n",
      "3                   0.0            0.0               0.0             0.0   \n",
      "4                   0.0            0.0               0.0             0.0   \n",
      "...                 ...            ...               ...             ...   \n",
      "3590                0.0            0.0               0.0             0.0   \n",
      "3591                0.0            0.0               0.0             0.0   \n",
      "3592                0.0            0.0               0.0             0.0   \n",
      "3593                0.0            0.0               0.0             0.0   \n",
      "3594                0.0            0.0               0.0             0.0   \n",
      "\n",
      "      Developer_angel  Developer_ant  Developer_arc  Developer_argonaut  \\\n",
      "0                 0.0            0.0            0.0                 0.0   \n",
      "1                 0.0            0.0            0.0                 0.0   \n",
      "2                 0.0            0.0            0.0                 0.0   \n",
      "3                 0.0            0.0            0.0                 0.0   \n",
      "4                 0.0            0.0            0.0                 0.0   \n",
      "...               ...            ...            ...                 ...   \n",
      "3590              0.0            0.0            0.0                 0.0   \n",
      "3591              0.0            0.0            0.0                 0.0   \n",
      "3592              0.0            0.0            0.0                 0.0   \n",
      "3593              0.0            0.0            0.0                 0.0   \n",
      "3594              0.0            0.0            0.0                 0.0   \n",
      "\n",
      "      Developer_arkan  Developer_art  Developer_artifici  Developer_asobo  \\\n",
      "0                 0.0            0.0                 0.0              0.0   \n",
      "1                 0.0            0.0                 0.0              0.0   \n",
      "2                 0.0            0.0                 0.0              0.0   \n",
      "3                 0.0            0.0                 0.0              0.0   \n",
      "4                 0.0            0.0                 0.0              0.0   \n",
      "...               ...            ...                 ...              ...   \n",
      "3590              0.0            0.0                 0.0              0.0   \n",
      "3591              0.0            0.0                 0.0              0.0   \n",
      "3592              0.0            0.0                 0.0              0.0   \n",
      "3593              0.0            0.0                 0.0              0.0   \n",
      "3594              0.0            0.0                 0.0              0.0   \n",
      "\n",
      "      Developer_assembl  Developer_atari  Developer_atlu  ...  \\\n",
      "0                   0.0              0.0             0.0  ...   \n",
      "1                   0.0              0.0             0.0  ...   \n",
      "2                   0.0              0.0             0.0  ...   \n",
      "3                   0.0              0.0             0.0  ...   \n",
      "4                   0.0              0.0             0.0  ...   \n",
      "...                 ...              ...             ...  ...   \n",
      "3590                0.0              0.0             0.0  ...   \n",
      "3591                0.0              0.0             0.0  ...   \n",
      "3592                0.0              0.0             0.0  ...   \n",
      "3593                0.0              0.0             0.0  ...   \n",
      "3594                0.0              0.0             0.0  ...   \n",
      "\n",
      "      Developer_triac  Developer_tt  Developer_two  Developer_ubisoft  \\\n",
      "0                 0.0           0.0            0.0                0.0   \n",
      "1                 0.0           0.0            0.0                0.0   \n",
      "2                 0.0           0.0            0.0                0.0   \n",
      "3                 0.0           0.0            0.0                0.0   \n",
      "4                 0.0           0.0            0.0                0.0   \n",
      "...               ...           ...            ...                ...   \n",
      "3590              0.0           0.0            0.0                0.0   \n",
      "3591              0.0           0.0            0.0                0.0   \n",
      "3592              0.0           0.0            0.0                0.0   \n",
      "3593              0.0           0.0            0.0                0.0   \n",
      "3594              0.0           0.0            0.0                0.0   \n",
      "\n",
      "      Developer_unlimit  Developer_valv  Developer_vancouv  Developer_vicari  \\\n",
      "0                   0.0             0.0                0.0               0.0   \n",
      "1                   0.0             0.0                0.0               0.0   \n",
      "2                   0.0             0.0                0.0               0.0   \n",
      "3                   0.0             0.0                0.0               0.0   \n",
      "4                   0.0             0.0                0.0               0.0   \n",
      "...                 ...             ...                ...               ...   \n",
      "3590                0.0             0.0                0.0               0.0   \n",
      "3591                0.0             0.0                0.0               0.0   \n",
      "3592                0.0             0.0                0.0               0.0   \n",
      "3593                0.0             0.0                0.0               0.0   \n",
      "3594                0.0             0.0                0.0               0.0   \n",
      "\n",
      "      Developer_viciou  Developer_view  Developer_vision  Developer_visual  \\\n",
      "0                  0.0             0.0               0.0               0.0   \n",
      "1                  0.0             0.0               0.0               0.0   \n",
      "2                  0.0             0.0               0.0               0.0   \n",
      "3                  0.0             0.0               0.0               0.0   \n",
      "4                  0.0             0.0               0.0               0.0   \n",
      "...                ...             ...               ...               ...   \n",
      "3590               0.0             0.0               0.0               0.0   \n",
      "3591               0.0             0.0               0.0               0.0   \n",
      "3592               0.0             0.0               0.0               0.0   \n",
      "3593               0.0             0.0               0.0               0.0   \n",
      "3594               0.0             0.0               0.0               0.0   \n",
      "\n",
      "      Developer_volit  Developer_voltag  Developer_wale  Developer_ward  \\\n",
      "0                 0.0          0.000000             0.0             0.0   \n",
      "1                 0.0          0.000000             0.0             0.0   \n",
      "2                 0.0          0.000000             0.0             0.0   \n",
      "3                 0.0          0.000000             0.0             0.0   \n",
      "4                 0.0          0.000000             0.0             0.0   \n",
      "...               ...               ...             ...             ...   \n",
      "3590              0.0          0.000000             0.0             0.0   \n",
      "3591              0.0          0.000000             0.0             0.0   \n",
      "3592              0.0          0.000000             0.0             0.0   \n",
      "3593              0.0          0.676946             0.0             0.0   \n",
      "3594              0.0          0.000000             0.0             0.0   \n",
      "\n",
      "      Developer_way  Developer_wayforward  Developer_white  Developer_work  \\\n",
      "0               0.0                   0.0              0.0             0.0   \n",
      "1               0.0                   0.0              0.0             0.0   \n",
      "2               0.0                   0.0              0.0             0.0   \n",
      "3               0.0                   0.0              0.0             0.0   \n",
      "4               0.0                   0.0              0.0             0.0   \n",
      "...             ...                   ...              ...             ...   \n",
      "3590            1.0                   0.0              0.0             0.0   \n",
      "3591            0.0                   0.0              0.0             0.0   \n",
      "3592            0.0                   0.0              0.0             0.0   \n",
      "3593            0.0                   0.0              0.0             0.0   \n",
      "3594            0.0                   0.0              0.0             0.0   \n",
      "\n",
      "      Developer_world  Developer_yuke  Developer_zaxi  Developer_zenimax  \\\n",
      "0                 0.0             0.0             0.0                0.0   \n",
      "1                 0.0             0.0             0.0                0.0   \n",
      "2                 0.0             0.0             0.0                0.0   \n",
      "3                 0.0             0.0             0.0                0.0   \n",
      "4                 0.0             0.0             0.0                0.0   \n",
      "...               ...             ...             ...                ...   \n",
      "3590              0.0             0.0             0.0                0.0   \n",
      "3591              0.0             0.0             0.0                0.0   \n",
      "3592              0.0             0.0             0.0                0.0   \n",
      "3593              0.0             0.0             0.0                0.0   \n",
      "3594              0.0             0.0             0.0                0.0   \n",
      "\n",
      "      Developer_zoink  \n",
      "0                 0.0  \n",
      "1                 0.0  \n",
      "2                 0.0  \n",
      "3                 0.0  \n",
      "4                 0.0  \n",
      "...               ...  \n",
      "3590              0.0  \n",
      "3591              0.0  \n",
      "3592              0.0  \n",
      "3593              0.0  \n",
      "3594              0.0  \n",
      "\n",
      "[3595 rows x 338 columns]\n",
      "0\n",
      "0\n",
      "(10783, 1222)\n",
      "(3595, 1222)\n"
     ]
    }
   ],
   "source": [
    "tfidf_columns = ['Name', 'Publisher', 'Developer']\n",
    "tfidf_columns_variables = ['tfidf_Name', 'tfidf_Publisher', 'tfidf_Developer']\n",
    "\n",
    "\n",
    "tfidf_dfs = []\n",
    "X_train_keep = pd.DataFrame()\n",
    "\n",
    "for i, col in enumerate(tfidf_columns):\n",
    "\n",
    "    globals()[tfidf_columns_variables[i]] = TfidfVectorizer(tokenizer = my_tokenizer, min_df=10)\n",
    "\n",
    "    # Fit and transform the text data\n",
    "    transformed_train = globals()[tfidf_columns_variables[i]].fit_transform(X_train[col])\n",
    "    transformed_test = globals()[tfidf_columns_variables[i]].transform(X_test[col])\n",
    "    \n",
    "    # store my vectorizers\n",
    "    tfidf_dfs.append(globals()[tfidf_columns_variables[i]])\n",
    "\n",
    "    # Convert the transformed data into a dataframe\n",
    "    tfidf_df_train = pd.DataFrame(transformed_train.toarray(),\n",
    "                                   columns=globals()[tfidf_columns_variables[i]].get_feature_names_out())\n",
    "\n",
    "    tfidf_df_test = pd.DataFrame(transformed_test.toarray(),\n",
    "                                   columns=globals()[tfidf_columns_variables[i]].get_feature_names_out())\n",
    "\n",
    "\n",
    "    # Join the 2 tfidf_df with the 2 dfs\n",
    "    tfidf_df_train = tfidf_df_train.add_prefix(f'{col}_')\n",
    "    tfidf_df_test = tfidf_df_test.add_prefix(f'{col}_')\n",
    "    X_train = pd.concat([X_train, tfidf_df_train], axis=\"columns\")\n",
    "    X_test = pd.concat([X_test, tfidf_df_test], axis=\"columns\")\n",
    "    \n",
    "    X_train_keep[col] = X_train[col]\n",
    "    \n",
    "    X_train.drop(col, axis = 1, inplace=True)\n",
    "    X_test.drop(col, axis = 1, inplace=True)\n",
    "    \n",
    "    word_counts = pd.DataFrame(\n",
    "        {\"counts\": transformed_train.toarray().sum(axis=0)},\n",
    "        index=globals()[tfidf_columns_variables[i]].get_feature_names_out()\n",
    "    ).sort_values(\"counts\", ascending=False)\n",
    "\n",
    "    word_counts.head(20).plot(kind=\"bar\", figsize=(15, 5), legend=False)\n",
    "    plt.title(f\"Top 20 highest weighted words by TF-IDF in {col}\")\n",
    "    plt.ylabel(\"Total TF-IDF weight\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "    \n",
    "    print(tfidf_df_train)\n",
    "    print(tfidf_df_test)\n",
    "\n",
    "# checking for null values and the shapes\n",
    "print(X_train.isna().sum().sum())\n",
    "print(X_test.isna().sum().sum())\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "de19e973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre_Action</th>\n",
       "      <th>Genre_Action-Adventure</th>\n",
       "      <th>Genre_Adventure</th>\n",
       "      <th>Genre_Board Game</th>\n",
       "      <th>Genre_Fighting</th>\n",
       "      <th>Genre_MMO</th>\n",
       "      <th>Genre_Misc</th>\n",
       "      <th>Genre_Music</th>\n",
       "      <th>Genre_Party</th>\n",
       "      <th>Genre_Platform</th>\n",
       "      <th>Genre_Puzzle</th>\n",
       "      <th>Genre_Racing</th>\n",
       "      <th>Genre_Role-Playing</th>\n",
       "      <th>Genre_Sandbox</th>\n",
       "      <th>Genre_Shooter</th>\n",
       "      <th>Genre_Simulation</th>\n",
       "      <th>Genre_Sports</th>\n",
       "      <th>Genre_Strategy</th>\n",
       "      <th>Genre_Visual Novel</th>\n",
       "      <th>Platform_Brand_Microsoft</th>\n",
       "      <th>Platform_Brand_Nintendo</th>\n",
       "      <th>Platform_Brand_PC</th>\n",
       "      <th>Platform_Brand_Sony</th>\n",
       "      <th>Platform_Type_Handheld</th>\n",
       "      <th>Platform_Type_HomeConsole</th>\n",
       "      <th>...</th>\n",
       "      <th>Developer_treyarch</th>\n",
       "      <th>Developer_triac</th>\n",
       "      <th>Developer_tt</th>\n",
       "      <th>Developer_two</th>\n",
       "      <th>Developer_ubisoft</th>\n",
       "      <th>Developer_unlimit</th>\n",
       "      <th>Developer_valv</th>\n",
       "      <th>Developer_vancouv</th>\n",
       "      <th>Developer_vicari</th>\n",
       "      <th>Developer_view</th>\n",
       "      <th>Developer_vision</th>\n",
       "      <th>Developer_visual</th>\n",
       "      <th>Developer_volit</th>\n",
       "      <th>Developer_voltag</th>\n",
       "      <th>Developer_ward</th>\n",
       "      <th>Developer_way</th>\n",
       "      <th>Developer_wayforward</th>\n",
       "      <th>Developer_white</th>\n",
       "      <th>Developer_work</th>\n",
       "      <th>Developer_world</th>\n",
       "      <th>Developer_yacht</th>\n",
       "      <th>Developer_yuke</th>\n",
       "      <th>Developer_zaxi</th>\n",
       "      <th>Developer_zen</th>\n",
       "      <th>Developer_zenimax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1242 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Genre_Action  Genre_Action-Adventure  Genre_Adventure  Genre_Board Game  \\\n",
       "0             0                       0                0                 0   \n",
       "1             0                       0                0                 0   \n",
       "2             0                       0                0                 0   \n",
       "3             1                       0                0                 0   \n",
       "4             0                       0                0                 0   \n",
       "\n",
       "   Genre_Fighting  Genre_MMO  Genre_Misc  Genre_Music  Genre_Party  \\\n",
       "0               1          0           0            0            0   \n",
       "1               0          0           0            0            0   \n",
       "2               0          0           0            0            0   \n",
       "3               0          0           0            0            0   \n",
       "4               0          0           1            0            0   \n",
       "\n",
       "   Genre_Platform  Genre_Puzzle  Genre_Racing  Genre_Role-Playing  \\\n",
       "0               0             0             0                   0   \n",
       "1               0             0             0                   0   \n",
       "2               0             0             0                   1   \n",
       "3               0             0             0                   0   \n",
       "4               0             0             0                   0   \n",
       "\n",
       "   Genre_Sandbox  Genre_Shooter  Genre_Simulation  Genre_Sports  \\\n",
       "0              0              0                 0             0   \n",
       "1              0              0                 0             1   \n",
       "2              0              0                 0             0   \n",
       "3              0              0                 0             0   \n",
       "4              0              0                 0             0   \n",
       "\n",
       "   Genre_Strategy  Genre_Visual Novel  Platform_Brand_Microsoft  \\\n",
       "0               0                   0                         1   \n",
       "1               0                   0                         0   \n",
       "2               0                   0                         0   \n",
       "3               0                   0                         1   \n",
       "4               0                   0                         0   \n",
       "\n",
       "   Platform_Brand_Nintendo  Platform_Brand_PC  Platform_Brand_Sony  \\\n",
       "0                        0                  0                    0   \n",
       "1                        1                  0                    0   \n",
       "2                        1                  0                    0   \n",
       "3                        0                  0                    0   \n",
       "4                        0                  1                    0   \n",
       "\n",
       "   Platform_Type_Handheld  Platform_Type_HomeConsole  ...  Developer_treyarch  \\\n",
       "0                       0                          1  ...                 0.0   \n",
       "1                       0                          1  ...                 0.0   \n",
       "2                       1                          0  ...                 0.0   \n",
       "3                       0                          1  ...                 0.0   \n",
       "4                       0                          0  ...                 0.0   \n",
       "\n",
       "   Developer_triac  Developer_tt  Developer_two  Developer_ubisoft  \\\n",
       "0              0.0           0.0            0.0                0.0   \n",
       "1              0.0           0.0            0.0                0.0   \n",
       "2              0.0           0.0            0.0                0.0   \n",
       "3              0.0           0.0            0.0                0.0   \n",
       "4              0.0           0.0            0.0                0.0   \n",
       "\n",
       "   Developer_unlimit  Developer_valv  Developer_vancouv  Developer_vicari  \\\n",
       "0                0.0             0.0                0.0               0.0   \n",
       "1                0.0             0.0                0.0               0.0   \n",
       "2                0.0             0.0                0.0               0.0   \n",
       "3                0.0             0.0                0.0               0.0   \n",
       "4                0.0             0.0                0.0               0.0   \n",
       "\n",
       "   Developer_view  Developer_vision  Developer_visual  Developer_volit  \\\n",
       "0             0.0          0.000000               0.0              0.0   \n",
       "1             0.0          0.000000               0.0              0.0   \n",
       "2             0.0          0.000000               0.0              0.0   \n",
       "3             0.0          0.587313               0.0              0.0   \n",
       "4             0.0          0.000000               0.0              0.0   \n",
       "\n",
       "   Developer_voltag  Developer_ward  Developer_way  Developer_wayforward  \\\n",
       "0               0.0             0.0            0.0                   0.0   \n",
       "1               0.0             0.0            0.0                   0.0   \n",
       "2               0.0             0.0            0.0                   0.0   \n",
       "3               0.0             0.0            0.0                   0.0   \n",
       "4               0.0             0.0            0.0                   0.0   \n",
       "\n",
       "   Developer_white  Developer_work  Developer_world  Developer_yacht  \\\n",
       "0              0.0             0.0              0.0              0.0   \n",
       "1              0.0             0.0              0.0              0.0   \n",
       "2              0.0             0.0              0.0              0.0   \n",
       "3              0.0             0.0              0.0              0.0   \n",
       "4              0.0             0.0              0.0              0.0   \n",
       "\n",
       "   Developer_yuke  Developer_zaxi  Developer_zen  Developer_zenimax  \n",
       "0             0.0             0.0            0.0                0.0  \n",
       "1             0.0             0.0            0.0                0.0  \n",
       "2             0.0             0.0            0.0                0.0  \n",
       "3             0.0             0.0            0.0                0.0  \n",
       "4             0.0             0.0            0.0                0.0  \n",
       "\n",
       "[5 rows x 1242 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "11aee03f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10783 entries, 0 to 10782\n",
      "Columns: 1242 entries, Genre_Action to Developer_zenimax\n",
      "dtypes: float64(1216), int32(26)\n",
      "memory usage: 101.1 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3595 entries, 0 to 3594\n",
      "Columns: 1242 entries, Genre_Action to Developer_zenimax\n",
      "dtypes: float64(1216), int32(26)\n",
      "memory usage: 33.7 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X_train.info())\n",
    "print(X_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894420b5",
   "metadata": {},
   "source": [
    "Before modeling, dropping one last column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "6dc8270c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dropping at the beginning, keeping this if needed\n",
    "\n",
    "# X_train.drop('Release_Date', axis = 1, inplace=True)\n",
    "# X_test.drop('Release_Date', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eddc5de",
   "metadata": {},
   "source": [
    "\n",
    "<div id=\"heading--3-5\"/>\n",
    "\n",
    "## 3.5 - Variance Threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811061ce",
   "metadata": {},
   "source": [
    "With the variance threshold, I will only keep values that have a variance over the threshold. This way, all the columns that I don't need can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "3aa59e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of features to keep: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 39, 41, 43, 44, 45, 46, 47, 62, 63, 64, 66, 67, 73, 74, 75, 79, 80, 81, 82, 91, 96, 100, 101, 103, 109, 111, 112, 114, 115, 116, 117, 121, 122, 124, 125, 130, 131, 135, 139, 148, 149, 153, 156, 158, 159, 162, 163, 165, 167, 169, 170, 172, 174, 175, 186, 188, 197, 199, 201, 203, 204, 207, 209, 213, 216, 221, 223, 226, 227, 231, 234, 235, 236, 239, 241, 243, 244, 248, 249, 252, 253, 257, 260, 261, 266, 271, 273, 274, 275, 277, 278, 281, 282, 283, 285, 286, 291, 292, 301, 305, 312, 313, 315, 319, 321, 322, 329, 333, 335, 336, 337, 339, 340, 344, 356, 358, 359, 362, 367, 368, 369, 381, 382, 384, 388, 390, 391, 393, 394, 396, 398, 399, 402, 403, 405, 406, 409, 410, 411, 413, 415, 419, 421, 423, 428, 431, 432, 434, 441, 444, 445, 447, 451, 457, 458, 459, 460, 462, 464, 466, 467, 468, 469, 470, 472, 474, 475, 477, 479, 482, 483, 484, 485, 488, 493, 494, 497, 500, 501, 502, 503, 504, 506, 508, 509, 510, 511, 515, 520, 523, 526, 529, 532, 534, 535, 538, 539, 541, 542, 543, 551, 555, 558, 561, 563, 565, 566, 567, 570, 584, 585, 587, 592, 596, 599, 604, 605, 608, 610, 611, 616, 617, 622, 623, 625, 628, 629, 633, 636, 637, 638, 642, 650, 651, 652, 653, 654, 656, 657, 660, 661, 662, 667, 675, 676, 678, 683, 684, 686, 687, 698, 701, 703, 705, 707, 710, 714, 716, 719, 723, 725, 735, 737, 738, 741, 744, 746, 747, 748, 749, 751, 752, 753, 754, 755, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 771, 772, 774, 775, 776, 777, 778, 779, 780, 782, 783, 784, 786, 787, 788, 789, 790, 791, 793, 794, 795, 796, 798, 799, 800, 802, 804, 805, 807, 809, 810, 811, 812, 813, 814, 818, 819, 820, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 850, 851, 852, 853, 855, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 869, 870, 871, 872, 873, 877, 879, 880, 882, 883, 884, 888, 889, 893, 894, 895, 898, 899, 900, 901, 903, 904, 905, 906, 907, 910, 911, 913, 915, 916, 917, 919, 921, 922, 923, 928, 930, 932, 933, 934, 935, 936, 937, 938, 940, 941, 942, 943, 945, 947, 948, 950, 951, 953, 954, 956, 957, 958, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 974, 975, 976, 977, 978, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 998, 1000, 1001, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1013, 1014, 1015, 1018, 1020, 1021, 1022, 1023, 1027, 1030, 1031, 1034, 1035, 1036, 1037, 1039, 1040, 1042, 1045, 1046, 1047, 1048, 1049, 1051, 1052, 1053, 1054, 1055, 1058, 1059, 1060, 1061, 1062, 1064, 1065, 1067, 1069, 1071, 1073, 1074, 1076, 1077, 1078, 1079, 1082, 1085, 1086, 1087, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1105, 1106, 1109, 1110, 1111, 1114, 1115, 1116, 1118, 1120, 1121, 1124, 1126, 1129, 1131, 1133, 1134, 1135, 1137, 1138, 1140, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1150, 1154, 1156, 1157, 1158, 1159, 1160, 1162, 1163, 1164, 1165, 1166, 1170, 1173, 1174, 1175, 1176, 1177, 1179, 1182, 1183, 1184, 1185, 1186, 1188, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1199, 1200, 1201, 1202, 1203, 1204, 1206, 1207, 1209, 1210, 1213, 1214, 1215, 1217, 1218, 1221, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1233, 1235, 1236, 1238, 1239, 1240]\n"
     ]
    }
   ],
   "source": [
    "# # setting the threshold\n",
    "\n",
    "# threshold_value = 0.001\n",
    "# selector = VarianceThreshold(threshold=threshold_value)\n",
    "\n",
    "# # Fit and transform the selector to X_train\n",
    "# X_selected = selector.fit_transform(X_train)\n",
    "\n",
    "# # Get the support mask\n",
    "# support_mask = selector.get_support()\n",
    "\n",
    "# # Get the indices of features to keep\n",
    "# indices_to_keep = [i for i, support in enumerate(support_mask) if support]\n",
    "\n",
    "# # Print the indices of features to keep\n",
    "# print(\"Indices of features to keep:\", indices_to_keep)\n",
    "\n",
    "# X_train = X_train.iloc[:,indices_to_keep]\n",
    "# X_test = X_test.iloc[:,indices_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0fda18d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10783 entries, 0 to 10782\n",
      "Columns: 645 entries, Genre_Action to Developer_zen\n",
      "dtypes: float64(620), int32(25)\n",
      "memory usage: 52.0 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3595 entries, 0 to 3594\n",
      "Columns: 645 entries, Genre_Action to Developer_zen\n",
      "dtypes: float64(620), int32(25)\n",
      "memory usage: 17.3 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# sanity check to confirm the number of columns\n",
    "\n",
    "print(X_train.info())\n",
    "print(X_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65cef1b",
   "metadata": {},
   "source": [
    "Because I removed a lot of columns, it created duplicated rows. So I will check where they are and remove them in both the X and y, train and test dfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e18cbc4e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1409\n",
      "318\n"
     ]
    }
   ],
   "source": [
    "# checking the number of duplicated rows\n",
    "\n",
    "print(X_train.duplicated().sum())\n",
    "print(X_test.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8703d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40718233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "82ea439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the duplicated rows on all the dfs\n",
    "\n",
    "# list of indices of the duplicated rows in X_train\n",
    "duplicate_indices = X_train[X_train.duplicated()].index\n",
    "\n",
    "# Remove duplicate rows from X_train\n",
    "X_train = X_train.drop_duplicates()\n",
    "\n",
    "# Remove corresponding rows from y_train\n",
    "y_train = y_train.drop(index=duplicate_indices)\n",
    "\n",
    "\n",
    "# list of indices of the duplicated rows in X_test\n",
    "duplicate_indices = X_test[X_test.duplicated()].index\n",
    "\n",
    "# Remove duplicate rows from X_test\n",
    "X_test = X_test.drop_duplicates()\n",
    "\n",
    "# Remove corresponding rows from y_test\n",
    "y_test = y_test.drop(index=duplicate_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32fd099",
   "metadata": {},
   "source": [
    "<div id=\"heading--4\"/>\n",
    "\n",
    "## 4. Part 4 - Modeling\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa962b3",
   "metadata": {},
   "source": [
    "I will start the modeling with different models at first.\n",
    "\n",
    "I will also store the test scores in the df_scores dataframe.\n",
    "\n",
    "### This part is still under construction. Some cells are work in progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "bd6fa5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [score]\n",
       "Index: []"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating df_scores to store scores\n",
    "\n",
    "df_scores=pd.DataFrame(columns=['score'])\n",
    "\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "789552dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TRAIN set has 5248 data points.\n",
      "The VALIDATION set has 1313 data points.\n",
      "The TEST set has 2813 data points.\n"
     ]
    }
   ],
   "source": [
    "# Split the data into remainder and test sets\n",
    "X_rem_logit, X_test_logit, y_rem_logit, y_test_logit = train_test_split(X_train, y_train, test_size=0.3, random_state=26, stratify=y_train)\n",
    "\n",
    "# Split the remainder set into train and validation sets\n",
    "X_train_logit, X_val_logit, y_train_logit, y_val_logit = train_test_split(X_rem_logit, y_rem_logit, test_size=0.2, random_state=96, stratify=y_rem_logit)\n",
    "\n",
    "# Print info on how the data has been split\n",
    "print(f'The TRAIN set has {len(X_train_logit)} data points.')\n",
    "print(f'The VALIDATION set has {len(X_val_logit)} data points.')\n",
    "print(f'The TEST set has {len(X_test_logit)} data points.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895fa7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4e2d9cad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(9631) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(9632) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(9634) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(9635) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(9636) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(9637) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(9638) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(9639) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(9640) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(9641) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(9642) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(9643) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(9644) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(9645) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(9646) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(9647) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.5154639175257731\n",
      "CPU times: user 293 ms, sys: 622 ms, total: 915 ms\n",
      "Wall time: 4.09 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline log reg : C=1.0</th>\n",
       "      <td>0.515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          score\n",
       "Baseline log reg : C=1.0  0.515"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Baseline logistic regression\n",
    "\n",
    "# Instantiate and fit to the train\n",
    "baseline_logreg = LogisticRegression(max_iter = 5000, n_jobs=-1).fit(X_rem_logit, y_rem_logit)\n",
    "\n",
    "\n",
    "# Print the accuracies\n",
    "print(f'Accuracy on test set: {baseline_logreg.score(X_test_logit, y_test_logit)}')\n",
    "\n",
    "df_scores.loc[f\"Baseline log reg : C={baseline_logreg.get_params()['C']}\"]=round(baseline_logreg.score(X_test_logit, y_test_logit),3)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c345188c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.7 s, sys: 5.54 s, total: 38.2 s\n",
      "Wall time: 4.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Let's try a modest range of C values\n",
    "c_values = [.00001, .0001, .001, .1, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "# Set up empty lists\n",
    "train_accuracies = []\n",
    "validation_accuracies = []\n",
    "\n",
    "# Iterate over the C values\n",
    "for value in c_values:\n",
    "\n",
    "    # Instantiate a log reg and fit to the train set\n",
    "    logreg = LogisticRegression(C=value, random_state=1).fit(X_train_logit, y_train_logit)\n",
    "\n",
    "    # Score on the train set and append this accuracy to its respective list\n",
    "    train_accuracies.append(logreg.score(X_train_logit, y_train_logit))\n",
    "    \n",
    "    # Score on the validation set and append this accuracy to its respective list\n",
    "    validation_accuracies.append(logreg.score(X_val_logit, y_val_logit))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6ecaf03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a dataframe\n",
    "scores_df=pd.DataFrame({'C value': c_values, 'train accuracy': train_accuracies, 'validation accuracy': validation_accuracies})\n",
    "\n",
    "# Plot the accuracies\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(c_values, train_accuracies, label='Train', marker='.')\n",
    "plt.plot(c_values, validation_accuracies, label='Validation', marker='.')\n",
    "plt.legend()\n",
    "plt.title('Effect of Varying C on Logistic Regression Accuracies')\n",
    "plt.xscale('log') # Put the x-axis on a log scale; this is important because the C values vary in orders of magnitude\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f7126c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_c=c_values[np.argmax(validation_accuracies)]\n",
    "# best_c\n",
    "\n",
    "best_c = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "695c263b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.5251112523839797\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a log reg and fit to the remainder set\n",
    "validated_logreg = LogisticRegression(C=best_c, random_state=1).fit(X_rem_logit, y_rem_logit)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f'Accuracy on test set: {validated_logreg.score(X_test_logit, y_test_logit)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "61a0e768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline log reg : C=1.0</th>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One-Fold : C=1</th>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          score\n",
       "Baseline log reg : C=1.0  0.525\n",
       "One-Fold : C=1            0.525"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores.loc[f\"One-Fold : C={validated_logreg.get_params()['C']}\"]=round(validated_logreg.score(X_test_logit, y_test_logit),3)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "49c9dd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a C value of 1e-05, the cross-validated accuracy is 0.348188\n",
      "For a C value of 0.0001, the cross-validated accuracy is 0.34846\n",
      "For a C value of 0.001, the cross-validated accuracy is 0.40679\n",
      "For a C value of 0.01, the cross-validated accuracy is 0.44699\n",
      "For a C value of 0.1, the cross-validated accuracy is 0.491822\n",
      "For a C value of 1, the cross-validated accuracy is 0.502585\n",
      "For a C value of 10, the cross-validated accuracy is 0.501224\n",
      "For a C value of 100, the cross-validated accuracy is 0.500816\n",
      "For a C value of 1000, the cross-validated accuracy is 0.500543\n",
      "For a C value of 10000, the cross-validated accuracy is 0.500815\n",
      "CPU times: user 707 ms, sys: 524 ms, total: 1.23 s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# This is the same range of C values that I used before\n",
    "c_values = [.00001, .0001, .001, 0.01, .1, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "# Set up an empty list\n",
    "cv_accuracies = []\n",
    "\n",
    "# Iterate over the C values\n",
    "for value in c_values:\n",
    "\n",
    "    # Instantiate a log reg\n",
    "    logreg = LogisticRegression(C=value, random_state=11, n_jobs=-1, max_iter=20000)\n",
    "\n",
    "    # Pass the model and the remainder set into the cross-validation function, then get cross-validated accuracy by taking the mean\n",
    "    cv_accuracy = np.mean(cross_val_score(logreg, X_rem_logit, y_rem_logit, cv=5, n_jobs=-1))\n",
    "\n",
    "    # Append the cross-validated accuracy to the list set up above\n",
    "    cv_accuracies.append(cv_accuracy)\n",
    "\n",
    "    # Print something at the end of each iteration\n",
    "    print(f'For a C value of {value}, the cross-validated accuracy is {round(cv_accuracy, 6)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d3b94037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracies\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(c_values, cv_accuracies, marker = '.')\n",
    "plt.title('Effect of Varying C on Cross-Validated Logistic Regression Accuracies')\n",
    "plt.xscale('log') # Put the x-axis on a log scale; this is important because the C values vary in orders of magnitude\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "86a2b2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on remainder set: 0.5651403652221314\n",
      "Accuracy on test set: 0.5079465988556897\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a log reg and fit to the remainder set\n",
    "cross_validated_logreg = LogisticRegression(C=1, random_state=11).fit(X_rem_logit, y_rem_logit)\n",
    "\n",
    "# Print the accuracies\n",
    "print(f'Accuracy on remainder set: {cross_validated_logreg.score(X_rem_logit, y_rem_logit)}')\n",
    "print(f'Accuracy on test set: {cross_validated_logreg.score(X_test_logit, y_test_logit)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a02a9300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline log reg : C=1.0</th>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One-Fold : C=1</th>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-Fold : C=0.1</th>\n",
       "      <td>0.508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          score\n",
       "Baseline log reg : C=1.0  0.525\n",
       "One-Fold : C=1            0.525\n",
       "5-Fold : C=0.1            0.508"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores.loc[f\"5-Fold : C={cross_validated_logreg.get_params()['C']}\"]=round(cross_validated_logreg.score(X_test_logit, y_test_logit),3)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a7a595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f900fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eebf94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8e9b00ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a directory to cache the pipeline results - if the same step with the same parameters is called again,\n",
    "# the cached result is used instead of re-computing it.\n",
    "cachedir = mkdtemp()\n",
    "\n",
    "# Set up a pipeline\n",
    "# The steps here act as placeholders and will be changed when we pass the pipeline into the grid search later\n",
    "my_pipeline = Pipeline(steps=[\n",
    "                        ('scaler', StandardScaler()),\n",
    "                        ('dim_reducer', PCA()),\n",
    "                        ('model', LogisticRegression())],\n",
    "                        memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b55a72ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(memory=&#x27;/var/folders/78/w0cjxhcs0bs0nxt9vj1kv61m0000gn/T/tmpw2b5np0d&#x27;,\n",
       "         steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;dim_reducer&#x27;, PCA()),\n",
       "                (&#x27;model&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(memory=&#x27;/var/folders/78/w0cjxhcs0bs0nxt9vj1kv61m0000gn/T/tmpw2b5np0d&#x27;,\n",
       "         steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;dim_reducer&#x27;, PCA()),\n",
       "                (&#x27;model&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(memory='/var/folders/78/w0cjxhcs0bs0nxt9vj1kv61m0000gn/T/tmpw2b5np0d',\n",
       "         steps=[('scaler', StandardScaler()), ('dim_reducer', PCA()),\n",
       "                ('model', LogisticRegression())])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the first pipeline\n",
    "\n",
    "pipeline_test=my_pipeline.fit(X_train,y_train)\n",
    "pipeline_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "19b51db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the pipeline_test score in the df_scores\n",
    "\n",
    "pipeline_test.score(X_test,y_test)\n",
    "df_scores.loc[f\"pipeline_test: \"]=round(baseline_logreg.score(X_test, y_test),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a5d2dce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform the training data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the scaler fitted on the training data\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3d018d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on train: 0.4402899656619611\n",
      "Score on test: 0.40229885057471265\n"
     ]
    }
   ],
   "source": [
    "# work in progress\n",
    "\n",
    "# 1. Instantiate model\n",
    "videogames_rfc = RandomForestClassifier(max_depth = 5, max_features = 1000)\n",
    "\n",
    "# 2. Fit model\n",
    "videogames_rfc.fit(X_train, y_train);\n",
    "\n",
    "\n",
    "print(f'Score on train: {videogames_rfc.score(X_train, y_train)}')\n",
    "print(f'Score on test: {videogames_rfc.score(X_test, y_test)}')\n",
    "\n",
    "df_scores.loc[f\"RandomForestClassifier: \"]=round(videogames_rfc.score(X_test, y_test),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2a8832d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          Weak\n",
      "1          Okay\n",
      "2        Strong\n",
      "3        Strong\n",
      "4          Weak\n",
      "          ...  \n",
      "12213      Weak\n",
      "12215    Strong\n",
      "12216    Strong\n",
      "12217    Strong\n",
      "12219    Strong\n",
      "Name: Metascore_Range, Length: 10508, dtype: object\n",
      "0         Weak\n",
      "1         Okay\n",
      "2         Weak\n",
      "3         Weak\n",
      "4         Okay\n",
      "         ...  \n",
      "2152      Weak\n",
      "2153    Strong\n",
      "2154      Weak\n",
      "2155      Weak\n",
      "2156      Weak\n",
      "Name: Metascore_Range, Length: 1987, dtype: object\n",
      "[2 0 1 ... 1 1 1]\n",
      "[2 0 2 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "print(y_train)\n",
    "print(y_test)\n",
    "print(y_train_encoded)\n",
    "print(y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "461c88c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:\n",
      "AdaBoost train score : 0.47727757627480266\n",
      "AdaBoost test score: 0.4586512053707659\n",
      "Random Forest train score: 0.9395135481117985\n",
      "Random Forest test score: 0.5486725663716814\n",
      "XG Boost train score: 0.7598677192233838\n",
      "XG Boost test score: 0.5505035093072933\n",
      "NN Boost train score: 0.7677618946020909\n",
      "NN Boost test score: 0.5276167226121452\n",
      "DecisionTreeClassifier train score: 1.0\n",
      "DecisionTreeClassifier test score: 0.5099176075678975\n",
      "BaggingClassifier train score: 0.974823981224664\n",
      "BaggingClassifier test score: 0.5282270369240158\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# testing a few different models, some have been optimized, some no\n",
    "# work in progress\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.fit_transform(y_test)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_train, y_encoded,\n",
    "#                                                     test_size=0.3, stratify = y_encoded)\n",
    "\n",
    "xgb_model = XGBClassifier(colsample_bytree= 0.75,\n",
    "                          learning_rate= 0.1, max_depth= 7,\n",
    "                          n_estimators= 500, subsample= 1)\n",
    "ab_model = AdaBoostClassifier()\n",
    "rf_model = RandomForestClassifier(max_depth= 5, max_features= 'sqrt',\n",
    "                                  min_samples_leaf= 1, min_samples_split= 10, n_estimators= 300)\n",
    "nn_model = MLPClassifier(hidden_layer_sizes=(5,5,5,5))\n",
    "dtc_model = DecisionTreeClassifier()\n",
    "bag_model = BaggingClassifier()\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "ab_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "nn_model.fit(X_train, y_train)\n",
    "dtc_model.fit(X_train, y_train)\n",
    "bag_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Scores:\")\n",
    "print(f\"AdaBoost train score : {ab_model.score(X_train, y_train)}\")\n",
    "print(f\"AdaBoost test score: {ab_model.score(X_test, y_test)}\")\n",
    "print(f\"Random Forest train score: {rf_model.score(X_train, y_train)}\")\n",
    "print(f\"Random Forest test score: {rf_model.score(X_test, y_test)}\")\n",
    "print(f\"XG Boost train score: {xgb_model.score(X_train, y_train)}\")\n",
    "print(f\"XG Boost test score: {xgb_model.score(X_test, y_test)}\")\n",
    "print(f\"NN Boost train score: {nn_model.score(X_train, y_train)}\")\n",
    "print(f\"NN Boost test score: {nn_model.score(X_test, y_test)}\")\n",
    "print(f\"DecisionTreeClassifier train score: {dtc_model.score(X_train, y_train)}\")\n",
    "print(f\"DecisionTreeClassifier test score: {dtc_model.score(X_test, y_test)}\")\n",
    "print(f\"BaggingClassifier train score: {bag_model.score(X_train, y_train)}\")\n",
    "print(f\"BaggingClassifier test score: {bag_model.score(X_test, y_test)}\")\n",
    "\n",
    "\n",
    "\n",
    "df_scores.loc[f\"AdaBoost: \"]=round(ab_model.score(X_test, y_test),3)\n",
    "df_scores.loc[f\"Random Forest: \"]=round(rf_model.score(X_test, y_test),3)\n",
    "df_scores.loc[f\"XG Boost: \"]=round(xgb_model.score(X_test, y_test),3)\n",
    "df_scores.loc[f\"NN Boost: \"]=round(nn_model.score(X_test, y_test),3)\n",
    "df_scores.loc[f\"DecisionTreeClassifier: \"]=round(dtc_model.score(X_test, y_test),3)\n",
    "df_scores.loc[f\"BaggingClassifier: \"]=round(bag_model.score(X_test, y_test),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcd1490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "24a00159",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "Best parameters: {'colsample_bytree': 0.75, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500, 'subsample': 1.0}\n",
      "Test accuracy of best model: 0.5392303848075962\n",
      "CPU times: user 1min 29s, sys: 9.12 s, total: 1min 38s\n",
      "Wall time: 26min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# work in progress, it takes a long time\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'subsample': [0.5, 0.75, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.75, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# Initialize GridSearchCV with the specified parameter grid and XGBoost model\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "\n",
    "# Perform grid search on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found by grid search\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "accuracy = best_xgb_model.score(X_test, y_test)\n",
    "print(\"Test accuracy of best model:\", accuracy)\n",
    "\n",
    "df_scores.loc[f\"Best XGB Model: \"]=round(best_xgb_model.score(X_test, y_test),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a409dce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "932e943b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  31.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  27.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  25.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  25.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  26.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  24.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  25.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.8min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  42.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  43.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  14.2s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  41.2s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  40.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  41.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  26.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   8.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  41.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  25.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  24.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  42.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  12.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   4.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  10.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  18.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   3.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   4.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  10.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  10.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  18.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  41.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  14.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  15.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  14.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  43.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  43.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  31.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  18.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  19.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  32.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   6.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  30.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  24.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  23.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  24.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  24.5s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 2.1min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  28.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  23.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  26.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  22.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  52.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  45.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  44.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  45.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  14.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  26.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  24.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  25.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  43.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  14.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  13.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  12.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  11.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.1min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  13.6s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Test accuracy of best model: 0.544727636181909\n",
      "CPU times: user 8.12 s, sys: 1.87 s, total: 9.99 s\n",
      "Wall time: 31min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Initialize Random Forest classifier\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Initialize GridSearchCV with the specified parameter grid and Random Forest model\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "\n",
    "# Perform grid search on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found by grid search\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "accuracy = best_rf_model.score(X_test, y_test)\n",
    "print(\"Test accuracy of best model:\", accuracy)\n",
    "\n",
    "df_scores.loc[f\"Best RF Model: \"]=round(best_rf_model.score(X_test, y_test),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f8b649a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# work in progress, it takes a long time\n",
    "\n",
    "# Let's try the same range of C values from earlier\n",
    "c_values = [.00001, .0001, .001, .01, .1, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "# Parameter grid\n",
    "logreg_param_grid = [\n",
    "\n",
    "    # l1 with PCA\n",
    "    {'scaler': [StandardScaler(), MinMaxScaler(), RobustScaler()],\n",
    "     'dim_reducer': [PCA()],\n",
    "     'dim_reducer__n_components': [0.95, 0.9, 0.85, 0.8],\n",
    "     'model': [LogisticRegression(solver='saga',penalty='l1', random_state=1, n_jobs=-1, max_iter=1000)],\n",
    "     'model__C': c_values},\n",
    "\n",
    "\n",
    "    # l2 (default) with PCA\n",
    "    {'scaler': [StandardScaler(), MinMaxScaler(), RobustScaler()],\n",
    "     'dim_reducer': [PCA()],\n",
    "     'dim_reducer__n_components': [0.95, 0.9, 0.85, 0.8],\n",
    "     'model': [LogisticRegression(penalty='l2',random_state=1, n_jobs=-1, max_iter=1000)],\n",
    "     'model__C': c_values}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "55049584",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370: UserWarning: Persisting input arguments took 0.69s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370: UserWarning: Persisting input arguments took 1.17s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370: UserWarning: Persisting input arguments took 1.11s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370: UserWarning: Persisting input arguments took 1.17s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370: UserWarning: Persisting input arguments took 1.04s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370: UserWarning: Persisting input arguments took 0.50s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370: UserWarning: Persisting input arguments took 1.79s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370: UserWarning: Persisting input arguments took 0.67s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370: UserWarning: Persisting input arguments took 0.94s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370: UserWarning: Persisting input arguments took 0.80s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370: UserWarning: Persisting input arguments took 0.75s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370: UserWarning: Persisting input arguments took 0.81s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370: UserWarning: Persisting input arguments took 0.54s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370: UserWarning: Persisting input arguments took 0.83s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370: UserWarning: Persisting input arguments took 0.58s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370: UserWarning: Persisting input arguments took 0.66s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370: UserWarning: Persisting input arguments took 0.64s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370: UserWarning: Persisting input arguments took 0.68s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370: UserWarning: Persisting input arguments took 0.73s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370: UserWarning: Persisting input arguments took 1.00s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370: UserWarning: Persisting input arguments took 1.10s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  31.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  28.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  25.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  27.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  25.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 2.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  43.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  14.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 1.1min\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   8.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  40.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   8.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  41.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   8.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  42.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  24.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  25.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  24.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   4.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   4.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   4.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  18.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   4.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  10.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  18.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  17.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  14.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  14.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  14.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  43.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  42.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  33.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   6.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  31.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  32.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  18.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  18.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  20.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 2.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 2.6min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 2.1min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  52.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  43.2s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  13.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  40.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  42.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   9.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  44.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   8.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  42.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  25.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  26.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  25.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   4.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   4.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   4.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  19.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  18.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  10.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  18.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 2.5min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  19.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  13.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  15.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  14.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  44.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  12.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  42.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  42.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  25.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  42.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   7.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  38.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  18.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  18.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  10.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  18.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   3.4s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  41.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  14.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  42.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  41.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  43.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  13.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  20.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  18.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  18.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  18.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  19.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  32.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   6.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   6.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   6.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  16.8s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  25.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 2.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 2.5min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.8min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  45.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  45.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  14.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  12.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  25.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   8.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  44.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   8.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   9.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   8.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  25.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  43.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   8.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  43.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 2.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  26.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  28.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  26.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  18.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  15.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  14.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  13.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  14.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  14.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  12.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  12.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.1min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  40.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   8.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   8.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   8.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  24.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  42.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  25.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  24.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  42.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   8.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   4.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  12.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   4.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  10.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   4.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   4.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  18.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  10.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  18.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   3.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  18.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  14.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  41.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  13.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  42.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  43.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  13.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   6.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  18.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  18.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  32.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   6.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  32.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  17.3s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 2.5min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  26.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  26.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.8min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  44.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  47.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  42.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  45.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  43.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  41.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  42.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   8.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  44.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  25.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   8.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   9.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   8.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  43.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   8.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  39.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  18.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  18.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  11.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  10.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  18.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  14.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  42.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  13.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  14.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  14.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  42.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  43.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  43.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  42.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  33.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  25.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  23.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  27.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  26.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  24.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  50.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  44.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  39.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  42.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  40.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  40.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   8.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  42.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  25.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   7.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   9.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   8.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  24.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  42.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   4.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  11.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  10.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  11.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  10.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  18.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  18.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  10.5s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  41.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  42.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  13.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  15.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  14.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  43.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  31.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  18.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  32.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   6.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   6.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   6.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  18.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  16.8s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 2.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 2.5min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  25.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  25.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  22.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  52.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  46.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  41.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  42.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  42.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  43.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  28.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   8.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  42.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  25.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  25.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  43.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  12.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   4.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  11.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  18.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   3.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  18.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  10.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  10.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  17.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  13.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  42.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  33.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   6.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  19.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  32.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   6.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  32.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  19.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  17.2s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=StandardScaler();, score=0.348 total time=  17.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=RobustScaler();, score=0.348 total time=   2.8s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=StandardScaler();, score=0.502 total time=   8.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=MinMaxScaler();, score=0.508 total time=   4.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=MinMaxScaler();, score=0.513 total time=  17.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  26.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.8min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  13.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  14.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  14.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  13.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  39.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 1.1min\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   8.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  40.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   8.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  25.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  24.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  42.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   8.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  41.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  24.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  18.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  18.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  18.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   3.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  10.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  17.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  13.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  43.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  33.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   6.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  31.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   6.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   6.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  19.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  18.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  31.5s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 2.1min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  26.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.5min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  17.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  13.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  13.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  15.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  14.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  13.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  41.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  42.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  44.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  25.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  42.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   8.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  43.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   8.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   4.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   4.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  12.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   4.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  11.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   4.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   4.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   4.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  11.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  18.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  18.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  41.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  14.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  14.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  20.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  32.5s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  27.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  25.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  29.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  26.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  14.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  13.2s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  40.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  13.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  40.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   8.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  24.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  24.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  41.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   8.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  42.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  24.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  25.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  24.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  18.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  18.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  11.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  10.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  10.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  18.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  41.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  14.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  13.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  42.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  43.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  43.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  43.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  31.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  18.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  19.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  32.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   6.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  30.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  26.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  29.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  25.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  25.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 2.5min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  26.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.9min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  14.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  42.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  13.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  16.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  14.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  45.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  13.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   9.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  28.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   8.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  42.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  25.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  43.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   8.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  38.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   4.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  11.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  10.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  11.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  18.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  18.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  41.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  14.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  14.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  13.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  33.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  24.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.8min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  13.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  42.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  44.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  44.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.1min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  13.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   8.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  26.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   7.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  42.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  25.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  42.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   7.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  38.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   3.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  11.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  10.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  10.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  18.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   3.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   4.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  10.5s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  14.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  41.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  42.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  13.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  14.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  15.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  14.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  42.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  33.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  19.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  31.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   6.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   7.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   6.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  18.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  31.3s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  24.5s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  28.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  25.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  25.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 2.5min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  24.5s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  26.5s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.9min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  14.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  13.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  14.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  17.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  12.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  42.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  25.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   8.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  25.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  11.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   8.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  25.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  25.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  43.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   8.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  43.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  19.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   3.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  18.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  11.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   3.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   4.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   3.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  10.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  18.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  14.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  42.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  42.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  42.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  25.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  26.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  44.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   8.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  42.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  25.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  26.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  39.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  18.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  10.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  18.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  18.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  10.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  14.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  14.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  13.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  43.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  42.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  33.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   6.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  32.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  34.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  19.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  32.2s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=RobustScaler();, score=0.348 total time=  15.2s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=RobustScaler();, score=0.348 total time=   1.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=RobustScaler();, score=0.370 total time=   2.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=RobustScaler();, score=0.463 total time=   3.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=RobustScaler();, score=0.513 total time=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  25.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  25.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  24.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  53.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  42.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  42.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  41.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  44.2s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  13.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  15.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  13.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.1min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  24.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   9.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   8.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   7.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   8.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   8.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  24.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  42.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   8.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  42.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  11.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  10.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  11.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  10.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  11.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  18.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  18.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  40.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  41.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  42.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  43.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  42.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  20.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  18.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  18.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  31.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   6.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  32.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  18.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  16.8s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  25.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  26.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 2.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.8min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  13.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  42.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  44.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  45.2s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  43.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   9.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   9.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   8.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  25.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  45.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  25.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  25.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  43.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  25.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  12.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  11.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  11.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  10.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  18.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   4.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  10.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  18.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  14.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  15.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  15.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  41.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  42.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  20.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  18.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  32.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  19.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  32.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   6.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  18.8s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=RobustScaler();, score=0.348 total time=  15.3s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=StandardScaler();, score=0.366 total time=   3.3s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=MinMaxScaler();, score=0.379 total time=   2.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=RobustScaler();, score=0.506 total time=   8.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  25.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 2.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  19.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  44.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  45.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  42.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  25.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   7.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  42.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  24.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  25.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  42.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   8.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   9.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   8.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  24.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  19.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  11.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  18.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  10.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  10.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  18.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  41.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  14.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  14.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  13.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  13.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  14.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   8.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   8.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   8.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  20.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  31.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  32.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  19.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  32.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   6.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  26.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  27.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  25.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  26.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 2.5min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 2.1min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.5min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  48.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  43.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  44.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  42.2s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  41.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  25.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  26.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  26.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  42.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   8.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  43.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  25.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  25.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  19.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   3.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  18.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  11.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  10.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  18.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  18.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  43.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  42.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  14.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  32.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   7.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  32.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   6.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   7.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   6.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  19.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  20.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminlavoie/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 2.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 2.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 2.1min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  26.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.8min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  42.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  13.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  40.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  41.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  40.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  24.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  24.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  25.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  24.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  42.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   8.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   8.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   8.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  25.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  38.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  18.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  10.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  18.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  18.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  10.5s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  42.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  14.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  43.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  42.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  33.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   6.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  31.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  32.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  19.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  18.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  19.9s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  27.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  26.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  25.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 2.1min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  26.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  23.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  26.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  54.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  45.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  47.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  14.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  14.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  13.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  11.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  13.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  44.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  42.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  25.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  25.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  43.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   4.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  12.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  11.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  11.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  10.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  11.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  18.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   4.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   3.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  17.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  13.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  42.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   7.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   7.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  18.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  32.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  19.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  19.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  19.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  19.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  19.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=RobustScaler();, score=0.348 total time=  15.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=RobustScaler();, score=0.348 total time=   1.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=StandardScaler();, score=0.471 total time=   3.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=StandardScaler();, score=0.520 total time=   6.9s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=MinMaxScaler();, score=0.489 total time=   4.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  25.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  50.2s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  40.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  45.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  13.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  24.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   7.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  41.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  24.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  42.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   8.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  42.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  24.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  18.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  18.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   3.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  18.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  10.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  10.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  10.4s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  14.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  41.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  13.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  15.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  14.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  41.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  13.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  42.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  33.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   6.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  31.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  19.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  19.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  18.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  31.6s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  26.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  29.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  26.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  26.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 2.5min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  25.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  22.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  52.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  45.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  41.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  42.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   9.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  44.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   8.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   8.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   9.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  25.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  25.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  43.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   4.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  12.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  11.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  11.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  10.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  18.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  18.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  10.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  41.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  43.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  14.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  14.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  14.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  43.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  42.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  33.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   6.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  32.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  32.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  19.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 2.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  25.5s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.9min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  42.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  44.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  41.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  12.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  14.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  13.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  13.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 1.1min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  24.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  24.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  25.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  42.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   7.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  42.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  25.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  38.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  18.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  18.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  18.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  10.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  10.5s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  14.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  41.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  41.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  41.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  42.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  14.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  20.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  18.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  18.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  31.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   6.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  32.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  18.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  20.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 2.1min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 2.1min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  27.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.5min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  17.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  41.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  13.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  14.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  44.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  25.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  25.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  43.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   8.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   9.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   8.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  25.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  19.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  11.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  18.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  10.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  18.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  18.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  14.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  42.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  13.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  44.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  42.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  14.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   6.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  34.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  19.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  19.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  32.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   6.2s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=StandardScaler();, score=0.348 total time=   8.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=StandardScaler();, score=0.348 total time=   2.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=StandardScaler();, score=0.348 total time=   6.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=RobustScaler();, score=0.366 total time=   2.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=RobustScaler();, score=0.476 total time=   3.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=RobustScaler();, score=0.502 total time=   8.1s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=StandardScaler();, score=0.504 total time= 2.8min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=MinMaxScaler();, score=0.497 total time= 2.5min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=RobustScaler();, score=0.498 total time= 3.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  32.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  28.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  24.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  51.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  43.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  43.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  42.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  41.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  24.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  25.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  42.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   8.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  42.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  18.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  18.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  11.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   3.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   4.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  18.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   3.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  17.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  42.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  43.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  43.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  21.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  18.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  32.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  19.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  19.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  32.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   6.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  18.3s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  24.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 2.0min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.5min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  46.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  42.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   9.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  27.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  42.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   8.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  43.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  26.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  39.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  18.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  18.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   3.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  18.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  10.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  10.5s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  41.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  14.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  14.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  42.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  13.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  14.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  14.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  42.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  44.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  32.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  19.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  32.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   6.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  32.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  17.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=  15.2s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=RobustScaler();, score=0.348 total time=   1.4s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=MinMaxScaler();, score=0.348 total time=   0.9s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=MinMaxScaler();, score=0.396 total time=   2.5s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=StandardScaler();, score=0.505 total time=  10.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=RobustScaler();, score=0.517 total time= 1.3min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=RobustScaler();, score=0.505 total time= 3.4min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=StandardScaler();, score=0.496 total time= 3.4min\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=MinMaxScaler();, score=0.403 total time=   3.0s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=RobustScaler();, score=0.476 total time=   3.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 2.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  25.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  24.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  24.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  23.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  50.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  46.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  39.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  42.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  42.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  42.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  25.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  24.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  42.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   4.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  11.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  10.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  11.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  10.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  18.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  10.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  10.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  17.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  14.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  15.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  14.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  43.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  13.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  31.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  32.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   5.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  32.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  17.3s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  25.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  19.2s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.5min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  12.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  14.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  13.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  13.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  25.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  25.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  27.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  25.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  42.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   8.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  43.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  25.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  19.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   3.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  18.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  18.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  10.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  10.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  10.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  41.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  42.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  14.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  42.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  33.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  19.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  32.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   6.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   7.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   6.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  19.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  32.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=RobustScaler();, score=0.348 total time=  15.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   0.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=MinMaxScaler();, score=0.348 total time=   1.3s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=StandardScaler();, score=0.483 total time=   3.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=MinMaxScaler();, score=0.465 total time=   3.3s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=StandardScaler();, score=0.516 total time= 1.4min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=RobustScaler();, score=0.498 total time= 3.4min\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=StandardScaler();, score=0.511 total time= 2.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  42.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  14.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  42.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  45.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  42.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  43.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  31.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  32.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   6.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  33.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  19.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  17.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   8.2s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=StandardScaler();, score=0.348 total time=   6.9s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=StandardScaler();, score=0.362 total time=   2.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=MinMaxScaler();, score=0.403 total time=   2.5s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=MinMaxScaler();, score=0.445 total time=   3.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=StandardScaler();, score=0.504 total time= 1.9min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=MinMaxScaler();, score=0.509 total time= 2.4min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=StandardScaler();, score=0.504 total time= 2.1min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=StandardScaler();, score=0.505 total time= 2.8min\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=RobustScaler();, score=0.500 total time=  50.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=RobustScaler();, score=0.489 total time= 3.4min\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=StandardScaler();, score=0.513 total time=  39.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=StandardScaler();, score=0.348 total time=   1.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   0.5s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=RobustScaler();, score=0.348 total time=   0.9s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=StandardScaler();, score=0.366 total time=   3.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=RobustScaler();, score=0.348 total time=   3.9s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=MinMaxScaler();, score=0.383 total time=   1.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=RobustScaler();, score=0.460 total time=   3.4s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=StandardScaler();, score=0.503 total time=   7.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=StandardScaler();, score=0.511 total time=  41.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=StandardScaler();, score=0.479 total time=  27.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=MinMaxScaler();, score=0.492 total time=  56.4s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=StandardScaler();, score=0.512 total time=  19.0s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=StandardScaler();, score=0.508 total time=  22.9s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=RobustScaler();, score=0.501 total time=  23.3s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=StandardScaler();, score=0.493 total time=   6.9s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=RobustScaler();, score=0.485 total time=  22.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=StandardScaler();, score=0.476 total time=  12.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=MinMaxScaler();, score=0.459 total time=  22.3s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=RobustScaler();, score=0.481 total time=  15.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=StandardScaler();, score=0.494 total time=  15.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=StandardScaler();, score=0.476 total time=  14.1s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=MinMaxScaler();, score=0.460 total time=   1.5s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=MinMaxScaler();, score=0.470 total time=   1.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=RobustScaler();, score=0.496 total time=  16.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=RobustScaler();, score=0.510 total time=   1.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=StandardScaler();, score=0.491 total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   8.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  40.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   8.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  42.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   8.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   8.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   9.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   7.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  42.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  25.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  38.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  17.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  18.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  18.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  10.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  17.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  14.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  43.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   7.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   7.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  18.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  31.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  19.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  31.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   6.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  18.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 2.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 2.5min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 2.1min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  14.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  45.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  46.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  14.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  43.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  44.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  25.7s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  42.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   8.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   9.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   9.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  26.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  39.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  18.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  18.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   3.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  18.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  10.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  10.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  14.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  42.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  42.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  13.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  43.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  32.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  19.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  19.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  33.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   6.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  31.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=StandardScaler();, score=0.348 total time=  15.3s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=StandardScaler();, score=0.348 total time=   2.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=MinMaxScaler();, score=0.383 total time=   2.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=MinMaxScaler();, score=0.451 total time=   3.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=StandardScaler();, score=0.525 total time= 1.6min\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=StandardScaler();, score=0.530 total time= 2.5min\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=RobustScaler();, score=0.522 total time= 2.2min\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=StandardScaler();, score=0.530 total time= 2.5min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=MinMaxScaler();, score=0.475 total time=   3.4s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=MinMaxScaler();, score=0.480 total time=   3.1s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=RobustScaler();, score=0.489 total time= 1.1min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=RobustScaler();, score=0.513 total time= 3.4min\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=StandardScaler();, score=0.514 total time=  58.5s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=MinMaxScaler();, score=0.446 total time=   1.8s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=RobustScaler();, score=0.495 total time=   5.0s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=MinMaxScaler();, score=0.478 total time=   1.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  19.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   3.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  18.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   4.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   4.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  10.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  10.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  18.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  41.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  42.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  43.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  14.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  20.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  19.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  19.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  19.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  32.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   6.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  32.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  17.9s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=  15.0s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   0.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=MinMaxScaler();, score=0.348 total time=   1.3s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=StandardScaler();, score=0.494 total time=   3.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=StandardScaler();, score=0.519 total time=   6.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=MinMaxScaler();, score=0.501 total time=   4.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=StandardScaler();, score=0.532 total time= 3.3min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=RobustScaler();, score=0.502 total time= 2.5min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=StandardScaler();, score=0.504 total time= 2.0min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=MinMaxScaler();, score=0.348 total time=   0.9s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=MinMaxScaler();, score=0.348 total time=   0.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=RobustScaler();, score=0.362 total time=   2.9s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=StandardScaler();, score=0.466 total time=   3.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=StandardScaler();, score=0.486 total time=   3.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=RobustScaler();, score=0.463 total time=   3.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=StandardScaler();, score=0.485 total time=   6.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=MinMaxScaler();, score=0.462 total time=   2.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=MinMaxScaler();, score=0.451 total time=   2.8s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=RobustScaler();, score=0.513 total time=   6.8s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=StandardScaler();, score=0.508 total time= 1.0min\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=StandardScaler();, score=0.513 total time= 3.5min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=MinMaxScaler();, score=0.480 total time=   4.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=MinMaxScaler();, score=0.496 total time=   5.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=RobustScaler();, score=0.513 total time=  42.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=StandardScaler();, score=0.348 total time=   2.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=StandardScaler();, score=0.348 total time=   2.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   2.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=RobustScaler();, score=0.348 total time=   2.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=RobustScaler();, score=0.348 total time=   3.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=StandardScaler();, score=0.348 total time=   1.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=RobustScaler();, score=0.348 total time=   0.9s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=StandardScaler();, score=0.367 total time=   3.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=StandardScaler();, score=0.473 total time=   3.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=MinMaxScaler();, score=0.403 total time=   1.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=RobustScaler();, score=0.475 total time=   3.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=MinMaxScaler();, score=0.457 total time=   1.8s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=MinMaxScaler();, score=0.448 total time=   1.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=RobustScaler();, score=0.510 total time=   6.2s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=RobustScaler();, score=0.503 total time=  32.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=MinMaxScaler();, score=0.491 total time=   6.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=StandardScaler();, score=0.508 total time=  24.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=MinMaxScaler();, score=0.483 total time=  49.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=StandardScaler();, score=0.479 total time=  26.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=RobustScaler();, score=0.501 total time=  15.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  19.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  19.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  18.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  19.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  32.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   6.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  31.4s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=  15.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   0.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=MinMaxScaler();, score=0.348 total time=   1.3s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=StandardScaler();, score=0.468 total time=   2.9s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=StandardScaler();, score=0.491 total time=   7.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=MinMaxScaler();, score=0.504 total time=   4.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=StandardScaler();, score=0.508 total time= 2.8min\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=MinMaxScaler();, score=0.500 total time= 2.5min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=RobustScaler();, score=0.502 total time= 2.4min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=RobustScaler();, score=0.348 total time=   2.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=RobustScaler();, score=0.348 total time=   2.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=StandardScaler();, score=0.348 total time=   0.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   0.5s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=RobustScaler();, score=0.348 total time=   0.9s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=StandardScaler();, score=0.362 total time=   2.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=StandardScaler();, score=0.362 total time=   2.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=RobustScaler();, score=0.348 total time=   3.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=StandardScaler();, score=0.492 total time=   3.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=MinMaxScaler();, score=0.383 total time=   2.8s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=RobustScaler();, score=0.480 total time=   3.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=StandardScaler();, score=0.504 total time=  11.0s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=MinMaxScaler();, score=0.445 total time=   2.7s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=RobustScaler();, score=0.508 total time=   7.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=StandardScaler();, score=0.514 total time= 1.0min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=StandardScaler();, score=0.487 total time= 3.5min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=StandardScaler();, score=0.512 total time= 1.1min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   1.2s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   0.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=StandardScaler();, score=0.362 total time=   3.8s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=RobustScaler();, score=0.366 total time=   3.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=MinMaxScaler();, score=0.396 total time=   1.9s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=RobustScaler();, score=0.481 total time=   3.5s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=StandardScaler();, score=0.499 total time=   8.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=MinMaxScaler();, score=0.480 total time=   1.9s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=RobustScaler();, score=0.503 total time=  31.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=MinMaxScaler();, score=0.483 total time=   5.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=RobustScaler();, score=0.501 total time= 2.6min\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=RobustScaler();, score=0.488 total time=  24.0s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=StandardScaler();, score=0.494 total time=  15.5s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=MinMaxScaler();, score=0.453 total time=  19.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=RobustScaler();, score=0.485 total time=   6.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=StandardScaler();, score=0.486 total time=   8.8s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=MinMaxScaler();, score=0.460 total time=   1.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=MinMaxScaler();, score=0.448 total time=   1.5s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=MinMaxScaler();, score=0.453 total time=   1.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=RobustScaler();, score=0.481 total time=  15.4s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=StandardScaler();, score=0.486 total time=   9.8s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=MinMaxScaler();, score=0.469 total time=   1.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=RobustScaler();, score=0.485 total time=   7.1s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=StandardScaler();, score=0.432 total time=   0.7s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=StandardScaler();, score=0.429 total time=   0.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=StandardScaler();, score=0.429 total time=   0.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   0.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   0.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   1.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=RobustScaler();, score=0.425 total time=   0.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=RobustScaler();, score=0.423 total time=   0.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=StandardScaler();, score=0.499 total time=   0.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=StandardScaler();, score=0.512 total time=   0.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=StandardScaler();, score=0.513 total time=   0.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=MinMaxScaler();, score=0.351 total time=   0.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=RobustScaler();, score=0.483 total time=   0.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=StandardScaler();, score=0.511 total time=   0.8s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=StandardScaler();, score=0.521 total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best logistic regression's accuracy on the train set: 0.5780236550934758\n",
      "The best logistic regression's accuracy on the test set: 0.49325337331334335\n",
      "CPU times: user 1min 50s, sys: 2.97 s, total: 1min 53s\n",
      "Wall time: 24min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Instantiate the log reg grid search\n",
    "logreg_gs = GridSearchCV(my_pipeline, param_grid=logreg_param_grid, cv=5, n_jobs=-1, verbose=3)\n",
    "\n",
    "# Fit the log reg grid search\n",
    "logreg_gs.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best logistic regression's accuracy on the train set: {logreg_gs.score(X_train, y_train)}\")\n",
    "print(f\"The best logistic regression's accuracy on the test set: {logreg_gs.score(X_test, y_test)}\")\n",
    "\n",
    "df_scores.loc[f\"LogReg_GS Model: \"]=round(logreg_gs.score(X_test, y_test),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408a36af",
   "metadata": {},
   "source": [
    "<div id=\"heading--4-1\"/>\n",
    "\n",
    "## 4.1 - First Scores, some optimization\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a1286797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline log reg : C=1.0</th>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One-Fold : C=1</th>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-Fold : C=0.1</th>\n",
       "      <td>0.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pipeline_test:</th>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier:</th>\n",
       "      <td>0.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost:</th>\n",
       "      <td>0.439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest:</th>\n",
       "      <td>0.555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XG Boost:</th>\n",
       "      <td>0.539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN Boost:</th>\n",
       "      <td>0.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier:</th>\n",
       "      <td>0.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier:</th>\n",
       "      <td>0.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best XGB Model:</th>\n",
       "      <td>0.539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best RF Model:</th>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg_GS Model:</th>\n",
       "      <td>0.493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          score\n",
       "Baseline log reg : C=1.0  0.525\n",
       "One-Fold : C=1            0.525\n",
       "5-Fold : C=0.1            0.508\n",
       "pipeline_test:            0.496\n",
       "RandomForestClassifier:   0.402\n",
       "AdaBoost:                 0.439\n",
       "Random Forest:            0.555\n",
       "XG Boost:                 0.539\n",
       "NN Boost:                 0.530\n",
       "DecisionTreeClassifier:   0.515\n",
       "BaggingClassifier:        0.513\n",
       "Best XGB Model:           0.539\n",
       "Best RF Model:            0.545\n",
       "LogReg_GS Model:          0.493"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing all the scores\n",
    "\n",
    "df_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55df0503",
   "metadata": {},
   "source": [
    "<div id=\"heading--4-2\"/>\n",
    "\n",
    "## 4.2 - Confusion Matrix\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "eeb97ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predict 1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True 1</th>\n",
       "      <td>235</td>\n",
       "      <td>144</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146</td>\n",
       "      <td>403</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160</td>\n",
       "      <td>87</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Predict 1    2    3\n",
       "True 1        235  144  259\n",
       "2             146  403  126\n",
       "3             160   87  441"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# quick test of confusion matrix\n",
    "\n",
    "# Get class predictions\n",
    "y_pred = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# label rows and columns\n",
    "cf_df = pd.DataFrame(\n",
    "    cf_matrix,\n",
    "    columns=[\"Predict 1\", \"2\", \"3\"],\n",
    "    index=[\"True 1\", \"2\", \"3\"]\n",
    ")\n",
    "\n",
    "display(cf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "75f24018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x161ad0690>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(best_xgb_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "af777eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current best accuracy with XG Boost is : 0.539\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=MinMaxScaler();, score=0.417 total time=   0.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=MinMaxScaler();, score=0.401 total time=   0.5s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=RobustScaler();, score=0.507 total time=   0.7s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=StandardScaler();, score=0.520 total time=   1.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=MinMaxScaler();, score=0.472 total time=   1.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=RobustScaler();, score=0.493 total time=   1.2s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=StandardScaler();, score=0.494 total time=   2.7s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=MinMaxScaler();, score=0.485 total time=   1.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=RobustScaler();, score=0.499 total time=   2.9s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=StandardScaler();, score=0.496 total time=   5.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=RobustScaler();, score=0.505 total time=   6.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=MinMaxScaler();, score=0.496 total time=   6.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=StandardScaler();, score=0.529 total time=   7.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=RobustScaler();, score=0.512 total time=   9.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=StandardScaler();, score=0.496 total time=  12.1s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=RobustScaler();, score=0.427 total time=   1.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=StandardScaler();, score=0.478 total time=   1.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=RobustScaler();, score=0.472 total time=   1.3s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=MinMaxScaler();, score=0.414 total time=   1.0s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=MinMaxScaler();, score=0.449 total time=   1.1s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=StandardScaler();, score=0.511 total time=   4.3s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=MinMaxScaler();, score=0.478 total time=   3.3s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=StandardScaler();, score=0.513 total time=   5.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=StandardScaler();, score=0.514 total time=   5.2s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=MinMaxScaler();, score=0.495 total time=   5.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=MinMaxScaler();, score=0.480 total time=   5.3s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=StandardScaler();, score=0.495 total time=   2.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=RobustScaler();, score=0.475 total time=   1.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=RobustScaler();, score=0.501 total time=   2.2s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=RobustScaler();, score=0.500 total time=   2.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=RobustScaler();, score=0.501 total time=   2.8s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=RobustScaler();, score=0.501 total time=   3.4s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=MinMaxScaler();, score=0.483 total time=   2.4s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=StandardScaler();, score=0.503 total time=   3.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   0.7s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=StandardScaler();, score=0.482 total time=   1.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=RobustScaler();, score=0.497 total time=   1.3s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=MinMaxScaler();, score=0.443 total time=   0.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=MinMaxScaler();, score=0.459 total time=   1.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=RobustScaler();, score=0.486 total time=   2.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=RobustScaler();, score=0.481 total time=   2.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=StandardScaler();, score=0.485 total time=   2.2s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=MinMaxScaler();, score=0.449 total time=   2.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=StandardScaler();, score=0.485 total time=   2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=RobustScaler();, score=0.518 total time= 1.4min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=StandardScaler();, score=0.505 total time= 2.1min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=RobustScaler();, score=0.498 total time= 3.5min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=MinMaxScaler();, score=0.509 total time=  14.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=MinMaxScaler();, score=0.511 total time=   9.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=RobustScaler();, score=0.512 total time= 3.2min\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=StandardScaler();, score=0.513 total time=  40.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=RobustScaler();, score=0.488 total time= 1.4min\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=RobustScaler();, score=0.499 total time=  36.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=RobustScaler();, score=0.499 total time=  34.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=StandardScaler();, score=0.348 total time=   2.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=StandardScaler();, score=0.348 total time=   2.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   2.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=RobustScaler();, score=0.348 total time=   5.8s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=RobustScaler();, score=0.348 total time=   0.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=StandardScaler();, score=0.362 total time=   3.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=RobustScaler();, score=0.366 total time=   3.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=StandardScaler();, score=0.479 total time=   3.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=StandardScaler();, score=0.503 total time=   7.7s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=StandardScaler();, score=0.504 total time=  43.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=StandardScaler();, score=0.503 total time=  20.1s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=MinMaxScaler();, score=0.460 total time= 1.0min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=StandardScaler();, score=0.502 total time=  24.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=StandardScaler();, score=0.479 total time=  26.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   2.3s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=RobustScaler();, score=0.348 total time=   2.4s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   0.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=RobustScaler();, score=0.348 total time=   0.8s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=StandardScaler();, score=0.366 total time=   2.4s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=RobustScaler();, score=0.366 total time=   2.1s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=MinMaxScaler();, score=0.396 total time=   1.2s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=RobustScaler();, score=0.474 total time=   3.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=StandardScaler();, score=0.498 total time=   5.2s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=StandardScaler();, score=0.503 total time=  24.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=StandardScaler();, score=0.485 total time=   9.4s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=StandardScaler();, score=0.502 total time=  13.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=RobustScaler();, score=0.495 total time=  15.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=RobustScaler();, score=0.487 total time=  24.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=RobustScaler();, score=0.487 total time=  14.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=StandardScaler();, score=0.502 total time=  14.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=StandardScaler();, score=0.447 total time=   0.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=StandardScaler();, score=0.438 total time=   0.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   0.7s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   0.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=RobustScaler();, score=0.429 total time=   1.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=RobustScaler();, score=0.446 total time=   0.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=RobustScaler();, score=0.432 total time=   0.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=StandardScaler();, score=0.482 total time=   0.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=StandardScaler();, score=0.506 total time=   0.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=MinMaxScaler();, score=0.350 total time=   0.5s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=MinMaxScaler();, score=0.351 total time=   0.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=RobustScaler();, score=0.500 total time=   0.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=RobustScaler();, score=0.510 total time=   0.7s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=StandardScaler();, score=0.508 total time=   0.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=MinMaxScaler();, score=0.420 total time=   0.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=RobustScaler();, score=0.492 total time=   0.7s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=StandardScaler();, score=0.493 total time=   1.3s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=MinMaxScaler();, score=0.459 total time=   0.9s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=RobustScaler();, score=0.507 total time=   1.2s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=StandardScaler();, score=0.508 total time=   2.8s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=MinMaxScaler();, score=0.493 total time=   1.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=RobustScaler();, score=0.508 total time=   2.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=StandardScaler();, score=0.505 total time=   4.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=MinMaxScaler();, score=0.493 total time=   3.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=StandardScaler();, score=0.504 total time=   6.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=RobustScaler();, score=0.503 total time=   7.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=MinMaxScaler();, score=0.497 total time=   9.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=MinMaxScaler();, score=0.497 total time=  12.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=RobustScaler();, score=0.498 total time=  10.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=MinMaxScaler();, score=0.470 total time=   1.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=MinMaxScaler();, score=0.480 total time=   2.1s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=StandardScaler();, score=0.487 total time=   5.3s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=MinMaxScaler();, score=0.480 total time=   5.7s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=MinMaxScaler();, score=0.481 total time=   5.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=MinMaxScaler();, score=0.496 total time=   5.3s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=RobustScaler();, score=0.511 total time=   4.3s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=MinMaxScaler();, score=0.351 total time=   2.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=MinMaxScaler();, score=0.417 total time=   0.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=StandardScaler();, score=0.497 total time=   2.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=MinMaxScaler();, score=0.481 total time=   1.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=MinMaxScaler();, score=0.460 total time=   2.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=RobustScaler();, score=0.501 total time=   3.3s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=MinMaxScaler();, score=0.460 total time=   2.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=StandardScaler();, score=0.503 total time=   2.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=MinMaxScaler();, score=0.483 total time=   2.5s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=StandardScaler();, score=0.420 total time=   1.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=StandardScaler();, score=0.495 total time=   1.1s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=MinMaxScaler();, score=0.415 total time=   0.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=RobustScaler();, score=0.491 total time=   1.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=StandardScaler();, score=0.495 total time=   2.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=MinMaxScaler();, score=0.472 total time=   1.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=StandardScaler();, score=0.495 total time=   2.3s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=MinMaxScaler();, score=0.470 total time=   1.8s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=StandardScaler();, score=0.495 total time=   1.9s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=StandardScaler();, score=0.495 total time=   2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=RobustScaler();, score=0.498 total time=  31.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=MinMaxScaler();, score=0.474 total time=   5.0s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=RobustScaler();, score=0.501 total time= 2.6min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=MinMaxScaler();, score=0.456 total time=   1.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=StandardScaler();, score=0.495 total time= 2.4min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=RobustScaler();, score=0.503 total time=   6.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=MinMaxScaler();, score=0.502 total time=   6.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=StandardScaler();, score=0.505 total time=   7.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=StandardScaler();, score=0.504 total time=   6.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=RobustScaler();, score=0.522 total time=  11.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=StandardScaler();, score=0.433 total time=   1.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=StandardScaler();, score=0.443 total time=   1.2s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   0.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   0.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=RobustScaler();, score=0.432 total time=   1.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=MinMaxScaler();, score=0.351 total time=   0.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=StandardScaler();, score=0.510 total time=   1.3s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=RobustScaler();, score=0.503 total time=   1.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=RobustScaler();, score=0.514 total time=   2.7s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=RobustScaler();, score=0.513 total time=   4.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=StandardScaler();, score=0.487 total time=   5.7s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=StandardScaler();, score=0.487 total time=   5.4s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=StandardScaler();, score=0.513 total time=   4.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=StandardScaler();, score=0.514 total time=   4.9s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   0.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=RobustScaler();, score=0.438 total time=   1.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=MinMaxScaler();, score=0.352 total time=   2.1s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=MinMaxScaler();, score=0.407 total time=   0.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=StandardScaler();, score=0.510 total time=   2.2s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=RobustScaler();, score=0.507 total time=   2.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=RobustScaler();, score=0.475 total time=   3.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=RobustScaler();, score=0.501 total time=   2.8s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=RobustScaler();, score=0.501 total time=   2.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=RobustScaler();, score=0.501 total time=   2.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=RobustScaler();, score=0.501 total time=   2.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=StandardScaler();, score=0.496 total time=   1.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=MinMaxScaler();, score=0.452 total time=   0.8s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=StandardScaler();, score=0.502 total time=   2.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=RobustScaler();, score=0.495 total time=   2.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=RobustScaler();, score=0.481 total time=   2.7s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=StandardScaler();, score=0.494 total time=   2.8s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=MinMaxScaler();, score=0.453 total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  14.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  14.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   8.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   8.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   8.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  20.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  32.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  32.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  19.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  32.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   6.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  19.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=StandardScaler();, score=0.348 total time=  11.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   5.5s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=RobustScaler();, score=0.366 total time=   2.4s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=RobustScaler();, score=0.488 total time=   3.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=StandardScaler();, score=0.507 total time= 1.7min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=StandardScaler();, score=0.505 total time= 2.6min\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=RobustScaler();, score=0.511 total time= 3.0min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=MinMaxScaler();, score=0.497 total time=   9.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=RobustScaler();, score=0.522 total time= 2.4min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=MinMaxScaler();, score=0.480 total time=  13.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=RobustScaler();, score=0.499 total time= 3.4min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=MinMaxScaler();, score=0.495 total time=   3.7s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=MinMaxScaler();, score=0.480 total time=   4.4s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=MinMaxScaler();, score=0.490 total time=   4.4s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=MinMaxScaler();, score=0.496 total time=   5.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=RobustScaler();, score=0.511 total time=  41.4s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=StandardScaler();, score=0.501 total time=  55.9s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=MinMaxScaler();, score=0.463 total time= 1.1min\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=StandardScaler();, score=0.503 total time=  18.4s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=RobustScaler();, score=0.499 total time=  16.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=StandardScaler();, score=0.503 total time=  19.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=StandardScaler();, score=0.348 total time=   2.5s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   2.2s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=RobustScaler();, score=0.348 total time=   2.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=StandardScaler();, score=0.348 total time=   0.8s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   0.4s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   0.4s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=RobustScaler();, score=0.348 total time=   0.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=StandardScaler();, score=0.362 total time=   2.2s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=StandardScaler();, score=0.457 total time=   2.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=MinMaxScaler();, score=0.379 total time=   1.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=StandardScaler();, score=0.495 total time=   6.9s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=StandardScaler();, score=0.495 total time=  43.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=MinMaxScaler();, score=0.469 total time=  21.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=StandardScaler();, score=0.495 total time=  14.3s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=MinMaxScaler();, score=0.470 total time=   1.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=RobustScaler();, score=0.496 total time=  17.3s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=StandardScaler();, score=0.494 total time=  17.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=RobustScaler();, score=0.487 total time=  12.8s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=StandardScaler();, score=0.506 total time=   3.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=RobustScaler();, score=0.519 total time=   1.3s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=StandardScaler();, score=0.517 total time=   2.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=MinMaxScaler();, score=0.502 total time=   1.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=RobustScaler();, score=0.517 total time=   3.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=StandardScaler();, score=0.512 total time=   4.9s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=RobustScaler();, score=0.498 total time=   7.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=MinMaxScaler();, score=0.512 total time=   5.8s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=StandardScaler();, score=0.511 total time=   7.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=StandardScaler();, score=0.496 total time=  10.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=StandardScaler();, score=0.505 total time=   8.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=StandardScaler();, score=0.438 total time=   1.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   0.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=RobustScaler();, score=0.441 total time=   1.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=StandardScaler();, score=0.509 total time=   1.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=StandardScaler();, score=0.512 total time=   1.4s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=RobustScaler();, score=0.512 total time=   1.2s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=RobustScaler();, score=0.502 total time=   2.8s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=StandardScaler();, score=0.511 total time=   5.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=MinMaxScaler();, score=0.496 total time=   5.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=StandardScaler();, score=0.513 total time=   4.8s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=StandardScaler();, score=0.513 total time=   4.3s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=StandardScaler();, score=0.513 total time=   4.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   0.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=RobustScaler();, score=0.425 total time=   1.2s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   2.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=RobustScaler();, score=0.510 total time=   1.1s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=RobustScaler();, score=0.506 total time=   2.3s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=RobustScaler();, score=0.475 total time=   3.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=StandardScaler();, score=0.502 total time=   3.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=MinMaxScaler();, score=0.483 total time=   2.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=StandardScaler();, score=0.512 total time=   3.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=MinMaxScaler();, score=0.492 total time=   2.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   0.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=StandardScaler();, score=0.485 total time=   1.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=StandardScaler();, score=0.493 total time=   1.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=RobustScaler();, score=0.496 total time=   1.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=RobustScaler();, score=0.481 total time=   2.3s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=RobustScaler();, score=0.486 total time=   2.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=MinMaxScaler();, score=0.453 total time=   1.7s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=StandardScaler();, score=0.485 total time=   2.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=MinMaxScaler();, score=0.449 total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=MinMaxScaler();, score=0.500 total time=  10.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=RobustScaler();, score=0.498 total time= 3.7min\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=MinMaxScaler();, score=0.496 total time= 2.0min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=MinMaxScaler();, score=0.482 total time=   4.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=RobustScaler();, score=0.488 total time= 1.1min\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=MinMaxScaler();, score=0.379 total time=   1.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=RobustScaler();, score=0.487 total time=   3.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=MinMaxScaler();, score=0.465 total time=   2.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=RobustScaler();, score=0.480 total time=   7.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=StandardScaler();, score=0.508 total time= 2.7min\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=MinMaxScaler();, score=0.492 total time=   2.2s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=RobustScaler();, score=0.501 total time=  15.5s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=MinMaxScaler();, score=0.348 total time=   0.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=RobustScaler();, score=0.362 total time=   2.4s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=StandardScaler();, score=0.490 total time=   2.9s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=StandardScaler();, score=0.475 total time=   4.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=StandardScaler();, score=0.475 total time=  23.5s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=RobustScaler();, score=0.485 total time= 2.5min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=MinMaxScaler();, score=0.509 total time=  11.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=RobustScaler();, score=0.503 total time=   9.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=StandardScaler();, score=0.480 total time=   4.0s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=RobustScaler();, score=0.521 total time=   5.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=RobustScaler();, score=0.490 total time=   5.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=RobustScaler();, score=0.513 total time=   5.0s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=StandardScaler();, score=0.512 total time=   4.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=StandardScaler();, score=0.487 total time=   4.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=StandardScaler();, score=0.443 total time=   1.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   0.9s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=StandardScaler();, score=0.495 total time=   1.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=StandardScaler();, score=0.485 total time=   1.8s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=StandardScaler();, score=0.505 total time=   1.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=MinMaxScaler();, score=0.465 total time=   1.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=StandardScaler();, score=0.479 total time=   3.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=RobustScaler();, score=0.509 total time=   3.2s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=RobustScaler();, score=0.475 total time=   3.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=RobustScaler();, score=0.499 total time=   2.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=RobustScaler();, score=0.475 total time=   3.4s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=MinMaxScaler();, score=0.417 total time=   0.9s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=MinMaxScaler();, score=0.444 total time=   0.8s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=StandardScaler();, score=0.494 total time=   2.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=MinMaxScaler();, score=0.453 total time=   1.5s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=StandardScaler();, score=0.494 total time=   2.2s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=MinMaxScaler();, score=0.448 total time=   1.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=RobustScaler();, score=0.488 total time=   3.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=MinMaxScaler();, score=0.470 total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=MinMaxScaler();, score=0.415 total time=   0.5s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=RobustScaler();, score=0.506 total time=   0.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=StandardScaler();, score=0.504 total time=   1.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=MinMaxScaler();, score=0.450 total time=   0.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=MinMaxScaler();, score=0.462 total time=   0.8s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=RobustScaler();, score=0.502 total time=   1.3s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=StandardScaler();, score=0.505 total time=   2.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=MinMaxScaler();, score=0.494 total time=   1.5s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=RobustScaler();, score=0.505 total time=   2.9s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=StandardScaler();, score=0.506 total time=   4.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=MinMaxScaler();, score=0.514 total time=   3.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=MinMaxScaler();, score=0.511 total time=   7.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=StandardScaler();, score=0.496 total time=   8.7s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=RobustScaler();, score=0.503 total time=   5.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=MinMaxScaler();, score=0.511 total time=   8.9s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=MinMaxScaler();, score=0.497 total time=  11.7s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=MinMaxScaler();, score=0.409 total time=   1.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=StandardScaler();, score=0.511 total time=   2.2s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=MinMaxScaler();, score=0.486 total time=   2.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=StandardScaler();, score=0.513 total time=   5.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=MinMaxScaler();, score=0.491 total time=   5.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=MinMaxScaler();, score=0.480 total time=   5.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=MinMaxScaler();, score=0.482 total time=   5.1s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=RobustScaler();, score=0.522 total time=   4.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=RobustScaler();, score=0.506 total time=   2.0s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=MinMaxScaler();, score=0.415 total time=   0.7s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=MinMaxScaler();, score=0.459 total time=   0.9s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=StandardScaler();, score=0.481 total time=   3.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=RobustScaler();, score=0.509 total time=   3.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=RobustScaler();, score=0.475 total time=   3.5s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=RobustScaler();, score=0.499 total time=   2.7s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=RobustScaler();, score=0.501 total time=   3.2s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=StandardScaler();, score=0.424 total time=   1.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=RobustScaler();, score=0.417 total time=   1.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=RobustScaler();, score=0.499 total time=   1.0s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=StandardScaler();, score=0.495 total time=   1.7s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=MinMaxScaler();, score=0.454 total time=   1.3s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=StandardScaler();, score=0.502 total time=   2.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=RobustScaler();, score=0.496 total time=   2.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=RobustScaler();, score=0.481 total time=   2.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=RobustScaler();, score=0.487 total time=   2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  43.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  14.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  15.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  14.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  42.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  33.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   6.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  32.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   7.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   6.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  19.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  19.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  32.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=  13.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   1.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=StandardScaler();, score=0.362 total time=   3.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=MinMaxScaler();, score=0.387 total time=   2.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=MinMaxScaler();, score=0.448 total time=   3.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=MinMaxScaler();, score=0.503 total time=   4.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=RobustScaler();, score=0.497 total time= 1.3min\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=MinMaxScaler();, score=0.512 total time=  18.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=StandardScaler();, score=0.511 total time= 2.6min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=RobustScaler();, score=0.503 total time= 2.3min\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=StandardScaler();, score=0.511 total time= 2.6min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=RobustScaler();, score=0.512 total time=  54.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=RobustScaler();, score=0.521 total time= 3.4min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=StandardScaler();, score=0.486 total time= 1.0min\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=RobustScaler();, score=0.491 total time=   5.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=MinMaxScaler();, score=0.479 total time=   2.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=StandardScaler();, score=0.503 total time= 2.7min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=StandardScaler();, score=0.348 total time=   2.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=StandardScaler();, score=0.348 total time=   2.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   2.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   2.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=RobustScaler();, score=0.348 total time=   2.5s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=StandardScaler();, score=0.348 total time=   0.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   0.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=RobustScaler();, score=0.348 total time=   0.8s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=StandardScaler();, score=0.362 total time=   2.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=StandardScaler();, score=0.472 total time=   2.8s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=MinMaxScaler();, score=0.387 total time=   1.2s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=RobustScaler();, score=0.487 total time=   3.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=MinMaxScaler();, score=0.442 total time=   1.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=RobustScaler();, score=0.490 total time=   4.1s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=RobustScaler();, score=0.482 total time=  21.8s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=RobustScaler();, score=0.488 total time= 2.5min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=StandardScaler();, score=0.504 total time=   9.8s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=RobustScaler();, score=0.511 total time=   8.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=MinMaxScaler();, score=0.455 total time=   1.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=StandardScaler();, score=0.513 total time=   4.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=MinMaxScaler();, score=0.491 total time=   3.8s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=RobustScaler();, score=0.522 total time=   5.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=RobustScaler();, score=0.522 total time=   5.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=RobustScaler();, score=0.522 total time=   4.8s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=MinMaxScaler();, score=0.496 total time=   5.2s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=StandardScaler();, score=0.512 total time=   4.0s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=MinMaxScaler();, score=0.479 total time=   1.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=StandardScaler();, score=0.512 total time=   3.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=MinMaxScaler();, score=0.492 total time=   2.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=StandardScaler();, score=0.479 total time=   3.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=RobustScaler();, score=0.509 total time=   3.1s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=RobustScaler();, score=0.509 total time=   3.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   0.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=StandardScaler();, score=0.482 total time=   1.0s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=StandardScaler();, score=0.496 total time=   1.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=MinMaxScaler();, score=0.466 total time=   1.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=StandardScaler();, score=0.485 total time=   2.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=MinMaxScaler();, score=0.470 total time=   1.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=StandardScaler();, score=0.476 total time=   2.4s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=MinMaxScaler();, score=0.453 total time=   2.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=StandardScaler();, score=0.494 total time=   2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=RobustScaler();, score=0.348 total time=  15.1s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=RobustScaler();, score=0.348 total time=   1.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=RobustScaler();, score=0.362 total time=   2.5s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=RobustScaler();, score=0.476 total time=   3.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=RobustScaler();, score=0.520 total time=   7.9s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=StandardScaler();, score=0.496 total time= 3.3min\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=MinMaxScaler();, score=0.511 total time= 2.5min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=StandardScaler();, score=0.496 total time= 3.5min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=StandardScaler();, score=0.511 total time= 3.2min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=RobustScaler();, score=0.513 total time=  46.1s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=StandardScaler();, score=0.512 total time=  50.0s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=MinMaxScaler();, score=0.348 total time=   1.1s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=RobustScaler();, score=0.370 total time=   3.4s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=StandardScaler();, score=0.483 total time=   3.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=StandardScaler();, score=0.485 total time=   7.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=StandardScaler();, score=0.505 total time=  52.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=StandardScaler();, score=0.512 total time=  20.1s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=RobustScaler();, score=0.509 total time=  26.4s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=RobustScaler();, score=0.499 total time=  17.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=StandardScaler();, score=0.508 total time=  22.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=RobustScaler();, score=0.501 total time=  22.8s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=MinMaxScaler();, score=0.463 total time=   2.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=MinMaxScaler();, score=0.460 total time=   2.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=MinMaxScaler();, score=0.475 total time=   2.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=RobustScaler();, score=0.499 total time=  17.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=RobustScaler();, score=0.370 total time=   2.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=StandardScaler();, score=0.475 total time=   2.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=StandardScaler();, score=0.486 total time=   5.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=StandardScaler();, score=0.485 total time=  25.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=StandardScaler();, score=0.495 total time=  15.1s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=MinMaxScaler();, score=0.448 total time=  28.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=StandardScaler();, score=0.476 total time=  12.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=MinMaxScaler();, score=0.469 total time=   1.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=RobustScaler();, score=0.485 total time=   6.9s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=StandardScaler();, score=0.495 total time=  16.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=MinMaxScaler();, score=0.449 total time=   1.5s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=MinMaxScaler();, score=0.453 total time=   1.7s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=RobustScaler();, score=0.481 total time=  14.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   0.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=MinMaxScaler();, score=0.352 total time=   0.5s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=RobustScaler();, score=0.504 total time=   0.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=StandardScaler();, score=0.515 total time=   0.7s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=MinMaxScaler();, score=0.412 total time=   0.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=RobustScaler();, score=0.507 total time=   0.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=RobustScaler();, score=0.519 total time=   0.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=StandardScaler();, score=0.516 total time=   1.4s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=MinMaxScaler();, score=0.474 total time=   0.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=RobustScaler();, score=0.512 total time=   1.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=StandardScaler();, score=0.524 total time=   2.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=MinMaxScaler();, score=0.506 total time=   1.4s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=RobustScaler();, score=0.519 total time=   2.7s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=StandardScaler();, score=0.531 total time=   5.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=MinMaxScaler();, score=0.505 total time=   3.4s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=StandardScaler();, score=0.511 total time=   6.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=RobustScaler();, score=0.522 total time=   8.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=RobustScaler();, score=0.503 total time=   7.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=RobustScaler();, score=0.503 total time=  10.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=MinMaxScaler();, score=0.511 total time=   8.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   0.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=RobustScaler();, score=0.506 total time=   1.4s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=RobustScaler();, score=0.501 total time=   1.3s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=RobustScaler();, score=0.488 total time=   2.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=RobustScaler();, score=0.510 total time=   4.4s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=RobustScaler();, score=0.513 total time=   4.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=RobustScaler();, score=0.511 total time=   4.9s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=RobustScaler();, score=0.513 total time=   4.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=StandardScaler();, score=0.512 total time=   4.3s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=StandardScaler();, score=0.429 total time=   1.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=StandardScaler();, score=0.433 total time=   1.0s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=RobustScaler();, score=0.428 total time=   1.2s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=MinMaxScaler();, score=0.350 total time=   2.2s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=StandardScaler();, score=0.510 total time=   0.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=MinMaxScaler();, score=0.451 total time=   0.9s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=StandardScaler();, score=0.502 total time=   3.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=MinMaxScaler();, score=0.491 total time=   2.0s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=MinMaxScaler();, score=0.463 total time=   2.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=StandardScaler();, score=0.508 total time=   2.9s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=StandardScaler();, score=0.479 total time=   3.3s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=MinMaxScaler();, score=0.475 total time=   2.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   0.7s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=StandardScaler();, score=0.500 total time=   1.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=StandardScaler();, score=0.497 total time=   0.9s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=MinMaxScaler();, score=0.433 total time=   0.8s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=RobustScaler();, score=0.489 total time=   1.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=StandardScaler();, score=0.495 total time=   2.3s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=StandardScaler();, score=0.502 total time=   2.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=MinMaxScaler();, score=0.469 total time=   1.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=MinMaxScaler();, score=0.460 total time=   1.9s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=StandardScaler();, score=0.476 total time=   2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=StandardScaler();, score=0.512 total time=   8.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=MinMaxScaler();, score=0.465 total time=   2.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=RobustScaler();, score=0.505 total time=   8.4s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=StandardScaler();, score=0.511 total time= 1.4min\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=MinMaxScaler();, score=0.494 total time=  11.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=StandardScaler();, score=0.514 total time=  54.2s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=MinMaxScaler();, score=0.480 total time= 2.0min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=MinMaxScaler();, score=0.495 total time=   4.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=MinMaxScaler();, score=0.490 total time=   4.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=RobustScaler();, score=0.511 total time=  39.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=RobustScaler();, score=0.513 total time=  44.3s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=StandardScaler();, score=0.479 total time= 2.7min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=RobustScaler();, score=0.475 total time=  32.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=StandardScaler();, score=0.494 total time= 2.4min\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=RobustScaler();, score=0.520 total time=   7.0s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=MinMaxScaler();, score=0.497 total time=   6.1s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=MinMaxScaler();, score=0.509 total time=   8.3s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=StandardScaler();, score=0.529 total time=   8.7s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=StandardScaler();, score=0.529 total time=  10.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   0.9s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=RobustScaler();, score=0.429 total time=   1.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=StandardScaler();, score=0.505 total time=   1.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=RobustScaler();, score=0.506 total time=   1.3s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=RobustScaler();, score=0.489 total time=   1.4s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=RobustScaler();, score=0.503 total time=   2.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=RobustScaler();, score=0.498 total time=   4.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=RobustScaler();, score=0.511 total time=   7.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=RobustScaler();, score=0.488 total time=   5.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=RobustScaler();, score=0.511 total time=   4.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=RobustScaler();, score=0.488 total time=   5.3s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=StandardScaler();, score=0.499 total time=   1.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=StandardScaler();, score=0.481 total time=   1.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=MinMaxScaler();, score=0.462 total time=   1.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=StandardScaler();, score=0.503 total time=   3.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=MinMaxScaler();, score=0.475 total time=   2.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=MinMaxScaler();, score=0.463 total time=   2.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=StandardScaler();, score=0.508 total time=   2.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=StandardScaler();, score=0.508 total time=   2.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=StandardScaler();, score=0.428 total time=   1.1s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=RobustScaler();, score=0.421 total time=   0.9s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=MinMaxScaler();, score=0.351 total time=   0.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=RobustScaler();, score=0.496 total time=   1.1s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=RobustScaler();, score=0.480 total time=   1.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=RobustScaler();, score=0.487 total time=   2.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=MinMaxScaler();, score=0.460 total time=   1.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=RobustScaler();, score=0.487 total time=   2.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=StandardScaler();, score=0.476 total time=   3.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=MinMaxScaler();, score=0.469 total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  20.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  19.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  19.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  19.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  19.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  33.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   6.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   7.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   6.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  17.3s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=StandardScaler();, score=0.348 total time=  15.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=StandardScaler();, score=0.367 total time=   3.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=RobustScaler();, score=0.475 total time=   3.1s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=RobustScaler();, score=0.492 total time=   7.9s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=RobustScaler();, score=0.505 total time= 1.4min\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=RobustScaler();, score=0.520 total time= 3.4min\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=StandardScaler();, score=0.530 total time= 2.4min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=MinMaxScaler();, score=0.497 total time=  17.9s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=StandardScaler();, score=0.348 total time=   2.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=StandardScaler();, score=0.348 total time=   2.3s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=StandardScaler();, score=0.348 total time=   2.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   2.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   2.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=RobustScaler();, score=0.348 total time=   2.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=RobustScaler();, score=0.348 total time=   2.4s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=StandardScaler();, score=0.348 total time=   0.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   0.4s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   0.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=RobustScaler();, score=0.348 total time=   0.8s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=RobustScaler();, score=0.348 total time=   0.9s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=StandardScaler();, score=0.367 total time=   2.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=MinMaxScaler();, score=0.348 total time=   0.7s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=MinMaxScaler();, score=0.348 total time=   0.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=MinMaxScaler();, score=0.348 total time=   0.8s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=RobustScaler();, score=0.366 total time=   2.7s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=StandardScaler();, score=0.465 total time=   3.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=MinMaxScaler();, score=0.396 total time=   2.5s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=MinMaxScaler();, score=0.387 total time=   2.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=RobustScaler();, score=0.476 total time=   3.9s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=StandardScaler();, score=0.512 total time=  10.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=RobustScaler();, score=0.491 total time=   7.1s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=StandardScaler();, score=0.489 total time= 1.0min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=StandardScaler();, score=0.511 total time= 1.6min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=MinMaxScaler();, score=0.481 total time= 1.9min\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=StandardScaler();, score=0.514 total time=  57.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=StandardScaler();, score=0.348 total time=   2.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   2.4s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   2.5s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=RobustScaler();, score=0.348 total time=   2.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=StandardScaler();, score=0.348 total time=   1.2s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=StandardScaler();, score=0.348 total time=   1.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=RobustScaler();, score=0.348 total time=   0.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=StandardScaler();, score=0.348 total time=   2.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=MinMaxScaler();, score=0.348 total time=   1.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=StandardScaler();, score=0.464 total time=   3.7s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=MinMaxScaler();, score=0.387 total time=   1.8s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=RobustScaler();, score=0.473 total time=   3.3s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=MinMaxScaler();, score=0.453 total time=   1.8s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=RobustScaler();, score=0.509 total time=   5.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=MinMaxScaler();, score=0.466 total time=   1.8s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=RobustScaler();, score=0.506 total time=  35.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=RobustScaler();, score=0.475 total time= 2.6min\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=MinMaxScaler();, score=0.469 total time=   1.4s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=StandardScaler();, score=0.486 total time= 2.4min\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=RobustScaler();, score=0.511 total time=   7.2s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=RobustScaler();, score=0.498 total time=   9.9s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=RobustScaler();, score=0.498 total time=   9.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=RobustScaler();, score=0.512 total time=  11.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=StandardScaler();, score=0.429 total time=   1.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=StandardScaler();, score=0.427 total time=   1.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   4.1s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=MinMaxScaler();, score=0.417 total time=   0.9s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=StandardScaler();, score=0.507 total time=   2.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=StandardScaler();, score=0.514 total time=   4.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=RobustScaler();, score=0.521 total time=   5.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=RobustScaler();, score=0.488 total time=   6.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=RobustScaler();, score=0.499 total time=   4.0s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=RobustScaler();, score=0.513 total time=   4.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=RobustScaler();, score=0.499 total time=   3.9s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=StandardScaler();, score=0.497 total time=   1.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=StandardScaler();, score=0.497 total time=   1.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=StandardScaler();, score=0.503 total time=   1.7s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=MinMaxScaler();, score=0.478 total time=   1.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=StandardScaler();, score=0.502 total time=   3.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=MinMaxScaler();, score=0.483 total time=   2.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=StandardScaler();, score=0.512 total time=   3.2s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=MinMaxScaler();, score=0.492 total time=   2.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=StandardScaler();, score=0.503 total time=   3.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=StandardScaler();, score=0.429 total time=   1.0s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=MinMaxScaler();, score=0.350 total time=   0.7s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=RobustScaler();, score=0.492 total time=   1.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=RobustScaler();, score=0.489 total time=   1.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=StandardScaler();, score=0.476 total time=   2.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=MinMaxScaler();, score=0.469 total time=   1.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=MinMaxScaler();, score=0.469 total time=   1.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=MinMaxScaler();, score=0.460 total time=   1.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=RobustScaler();, score=0.487 total time=   2.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=RobustScaler();, score=0.488 total time=   3.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=StandardScaler();, score=0.511 total time= 3.3min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=MinMaxScaler();, score=0.498 total time= 2.5min\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=RobustScaler();, score=0.512 total time= 3.0min\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=MinMaxScaler();, score=0.492 total time=   3.5s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=RobustScaler();, score=0.508 total time=  59.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=MinMaxScaler();, score=0.490 total time=  10.9s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=StandardScaler();, score=0.512 total time=  47.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=MinMaxScaler();, score=0.495 total time= 2.0min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=StandardScaler();, score=0.512 total time=  50.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=RobustScaler();, score=0.522 total time=  56.3s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=StandardScaler();, score=0.512 total time= 2.7min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=StandardScaler();, score=0.348 total time=   2.5s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=StandardScaler();, score=0.348 total time=   2.3s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   2.2s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=RobustScaler();, score=0.348 total time=   2.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=StandardScaler();, score=0.348 total time=   0.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=StandardScaler();, score=0.348 total time=   0.7s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   0.4s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=RobustScaler();, score=0.348 total time=   0.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=StandardScaler();, score=0.348 total time=   1.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=MinMaxScaler();, score=0.348 total time=   1.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=StandardScaler();, score=0.490 total time=   3.0s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=RobustScaler();, score=0.470 total time=   2.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=MinMaxScaler();, score=0.463 total time=   1.3s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=RobustScaler();, score=0.486 total time=   4.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=MinMaxScaler();, score=0.470 total time=   1.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=MinMaxScaler();, score=0.459 total time=   2.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=MinMaxScaler();, score=0.449 total time=   3.4s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=MinMaxScaler();, score=0.469 total time=   2.4s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=MinMaxScaler();, score=0.454 total time=   2.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=MinMaxScaler();, score=0.469 total time=   2.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=RobustScaler();, score=0.495 total time= 2.4min\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=RobustScaler();, score=0.522 total time=   8.8s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=RobustScaler();, score=0.503 total time=   9.5s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=RobustScaler();, score=0.522 total time=   9.4s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=StandardScaler();, score=0.513 total time=   2.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=MinMaxScaler();, score=0.496 total time=   2.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=MinMaxScaler();, score=0.495 total time=   3.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=RobustScaler();, score=0.499 total time=   4.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=RobustScaler();, score=0.499 total time=   4.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=RobustScaler();, score=0.511 total time=   5.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=RobustScaler();, score=0.499 total time=   3.9s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=RobustScaler();, score=0.513 total time=   4.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=MinMaxScaler();, score=0.351 total time=   2.2s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=MinMaxScaler();, score=0.398 total time=   0.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=MinMaxScaler();, score=0.445 total time=   0.9s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=StandardScaler();, score=0.506 total time=   2.7s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=MinMaxScaler();, score=0.461 total time=   2.2s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=StandardScaler();, score=0.478 total time=   3.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=RobustScaler();, score=0.509 total time=   3.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=RobustScaler();, score=0.475 total time=   3.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=RobustScaler();, score=0.499 total time=   2.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=RobustScaler();, score=0.494 total time=   0.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=RobustScaler();, score=0.477 total time=   0.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=RobustScaler();, score=0.486 total time=   1.5s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=RobustScaler();, score=0.486 total time=   2.5s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=StandardScaler();, score=0.485 total time=   2.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=StandardScaler();, score=0.494 total time=   2.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=MinMaxScaler();, score=0.470 total time=   2.2s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=StandardScaler();, score=0.502 total time=   2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  19.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=  20.2s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=StandardScaler();, score=0.348 total time=   8.3s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=StandardScaler();, score=0.348 total time=   6.5s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=RobustScaler();, score=0.348 total time=   1.3s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=MinMaxScaler();, score=0.348 total time=   0.8s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=StandardScaler();, score=0.490 total time=   2.9s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=MinMaxScaler();, score=0.462 total time=   3.1s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=StandardScaler();, score=0.494 total time= 1.5min\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=RobustScaler();, score=0.512 total time= 3.4min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=MinMaxScaler();, score=0.509 total time=  14.7s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=MinMaxScaler();, score=0.500 total time=   9.8s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=MinMaxScaler();, score=0.497 total time=   8.7s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=RobustScaler();, score=0.522 total time= 2.1min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=RobustScaler();, score=0.503 total time= 2.5min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=MinMaxScaler();, score=0.482 total time=  11.1s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=StandardScaler();, score=0.486 total time=  57.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=MinMaxScaler();, score=0.490 total time= 1.8min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=StandardScaler();, score=0.486 total time=  59.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=RobustScaler();, score=0.499 total time=  35.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=StandardScaler();, score=0.482 total time=  37.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=RobustScaler();, score=0.509 total time= 2.6min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=StandardScaler();, score=0.495 total time=  43.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=MinMaxScaler();, score=0.470 total time=  20.8s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=RobustScaler();, score=0.487 total time=  13.4s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=StandardScaler();, score=0.502 total time=  13.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=RobustScaler();, score=0.487 total time=  27.2s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=RobustScaler();, score=0.487 total time=  24.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=MinMaxScaler();, score=0.508 total time=   3.7s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=MinMaxScaler();, score=0.497 total time=   3.3s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=StandardScaler();, score=0.505 total time=   6.8s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=RobustScaler();, score=0.503 total time=   6.4s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=MinMaxScaler();, score=0.500 total time=   8.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=MinMaxScaler();, score=0.499 total time=   9.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=MinMaxScaler();, score=0.499 total time=   9.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=StandardScaler();, score=0.504 total time=   1.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=RobustScaler();, score=0.495 total time=   1.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=RobustScaler();, score=0.511 total time=   1.2s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=RobustScaler();, score=0.516 total time=   2.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=RobustScaler();, score=0.489 total time=   4.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=StandardScaler();, score=0.512 total time=   5.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=StandardScaler();, score=0.512 total time=   5.1s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=StandardScaler();, score=0.487 total time=   5.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=StandardScaler();, score=0.513 total time=   4.7s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   0.8s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=RobustScaler();, score=0.427 total time=   1.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=RobustScaler();, score=0.467 total time=   2.3s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=RobustScaler();, score=0.507 total time=   1.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=RobustScaler();, score=0.492 total time=   2.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=RobustScaler();, score=0.498 total time=   2.5s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=RobustScaler();, score=0.499 total time=   2.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=RobustScaler();, score=0.499 total time=   3.0s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=RobustScaler();, score=0.501 total time=   3.1s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=MinMaxScaler();, score=0.463 total time=   2.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=StandardScaler();, score=0.439 total time=   1.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=RobustScaler();, score=0.433 total time=   1.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=MinMaxScaler();, score=0.352 total time=   0.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=MinMaxScaler();, score=0.399 total time=   0.7s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=MinMaxScaler();, score=0.458 total time=   0.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=StandardScaler();, score=0.487 total time=   2.1s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=MinMaxScaler();, score=0.450 total time=   1.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=StandardScaler();, score=0.476 total time=   2.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=RobustScaler();, score=0.495 total time=   2.3s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=RobustScaler();, score=0.481 total time=   3.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=RobustScaler();, score=0.485 total time=   1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=MinMaxScaler();, score=0.496 total time=  21.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=MinMaxScaler();, score=0.500 total time=  19.9s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=MinMaxScaler();, score=0.499 total time=  21.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=StandardScaler();, score=0.496 total time= 3.5min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=MinMaxScaler();, score=0.497 total time=  16.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=MinMaxScaler();, score=0.511 total time=   8.4s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=RobustScaler();, score=0.503 total time= 2.1min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=StandardScaler();, score=0.348 total time=   2.5s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=StandardScaler();, score=0.348 total time=   2.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   2.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   2.2s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   2.5s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=RobustScaler();, score=0.348 total time=   2.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=StandardScaler();, score=0.348 total time=   0.9s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=StandardScaler();, score=0.348 total time=   0.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=StandardScaler();, score=0.348 total time=   0.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   0.4s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   0.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=RobustScaler();, score=0.348 total time=   0.8s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=RobustScaler();, score=0.348 total time=   0.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=StandardScaler();, score=0.348 total time=   1.9s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=StandardScaler();, score=0.366 total time=   2.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=RobustScaler();, score=0.370 total time=   2.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=RobustScaler();, score=0.366 total time=   2.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=StandardScaler();, score=0.483 total time=   4.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=MinMaxScaler();, score=0.379 total time=   2.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=RobustScaler();, score=0.479 total time=   4.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=StandardScaler();, score=0.511 total time=   8.2s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=MinMaxScaler();, score=0.448 total time=   2.8s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=RobustScaler();, score=0.501 total time=   8.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=StandardScaler();, score=0.510 total time= 1.0min\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=StandardScaler();, score=0.512 total time= 3.4min\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=StandardScaler();, score=0.513 total time=  39.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=MinMaxScaler();, score=0.482 total time=   3.7s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=RobustScaler();, score=0.488 total time= 1.2min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=MinMaxScaler();, score=0.462 total time=   7.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=MinMaxScaler();, score=0.461 total time=   6.7s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=RobustScaler();, score=0.499 total time= 2.6min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=MinMaxScaler();, score=0.455 total time=   1.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=StandardScaler();, score=0.476 total time= 2.4min\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=StandardScaler();, score=0.530 total time=   7.4s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=RobustScaler();, score=0.512 total time=   8.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=MinMaxScaler();, score=0.511 total time=   6.4s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=StandardScaler();, score=0.511 total time=   9.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=MinMaxScaler();, score=0.509 total time=  10.7s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=MinMaxScaler();, score=0.351 total time=   1.0s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=StandardScaler();, score=0.510 total time=   1.3s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=StandardScaler();, score=0.485 total time=   2.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=MinMaxScaler();, score=0.477 total time=   2.3s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=StandardScaler();, score=0.512 total time=   4.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=StandardScaler();, score=0.514 total time=   5.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=MinMaxScaler();, score=0.495 total time=   5.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=MinMaxScaler();, score=0.480 total time=   5.4s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=MinMaxScaler();, score=0.481 total time=   5.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=RobustScaler();, score=0.492 total time=   2.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=RobustScaler();, score=0.495 total time=   1.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=RobustScaler();, score=0.479 total time=   2.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=StandardScaler();, score=0.508 total time=   2.9s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=StandardScaler();, score=0.508 total time=   2.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=StandardScaler();, score=0.503 total time=   3.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=MinMaxScaler();, score=0.475 total time=   2.3s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=StandardScaler();, score=0.512 total time=   3.2s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   0.7s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=StandardScaler();, score=0.495 total time=   1.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=MinMaxScaler();, score=0.412 total time=   0.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=StandardScaler();, score=0.501 total time=   1.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=RobustScaler();, score=0.497 total time=   2.7s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=RobustScaler();, score=0.487 total time=   2.4s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=StandardScaler();, score=0.502 total time=   2.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=RobustScaler();, score=0.495 total time=   3.3s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=RobustScaler();, score=0.487 total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=MinMaxScaler();, score=0.488 total time=   2.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=MinMaxScaler();, score=0.500 total time=   3.1s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=RobustScaler();, score=0.518 total time=  57.0s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=MinMaxScaler();, score=0.495 total time=  12.5s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=RobustScaler();, score=0.510 total time= 3.4min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=StandardScaler();, score=0.512 total time= 1.1min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=StandardScaler();, score=0.502 total time= 1.0min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=MinMaxScaler();, score=0.475 total time=  43.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=RobustScaler();, score=0.501 total time=  15.2s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=MinMaxScaler();, score=0.463 total time=   2.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=MinMaxScaler();, score=0.483 total time=   2.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=MinMaxScaler();, score=0.492 total time=   2.2s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=RobustScaler();, score=0.475 total time=  31.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=MinMaxScaler();, score=0.483 total time=   2.2s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=RobustScaler();, score=0.509 total time=  26.2s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=RobustScaler();, score=0.494 total time=   4.8s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=RobustScaler();, score=0.499 total time=  21.4s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=RobustScaler();, score=0.487 total time= 2.4min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=MinMaxScaler();, score=0.497 total time=   9.3s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=MinMaxScaler();, score=0.497 total time=   8.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=StandardScaler();, score=0.505 total time=   1.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=RobustScaler();, score=0.501 total time=   1.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=MinMaxScaler();, score=0.400 total time=   1.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=MinMaxScaler();, score=0.453 total time=   1.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=StandardScaler();, score=0.510 total time=   4.3s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=MinMaxScaler();, score=0.496 total time=   3.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=MinMaxScaler();, score=0.495 total time=   5.3s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=MinMaxScaler();, score=0.496 total time=   5.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=RobustScaler();, score=0.488 total time=   5.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=StandardScaler();, score=0.430 total time=   1.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=StandardScaler();, score=0.423 total time=   1.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   0.9s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=StandardScaler();, score=0.473 total time=   0.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=RobustScaler();, score=0.500 total time=   2.4s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=MinMaxScaler();, score=0.461 total time=   1.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=StandardScaler();, score=0.512 total time=   3.0s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=MinMaxScaler();, score=0.478 total time=   2.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=MinMaxScaler();, score=0.460 total time=   2.7s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=StandardScaler();, score=0.502 total time=   3.0s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=MinMaxScaler();, score=0.464 total time=   2.3s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=StandardScaler();, score=0.479 total time=   3.5s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=RobustScaler();, score=0.424 total time=   0.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=MinMaxScaler();, score=0.351 total time=   0.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=StandardScaler();, score=0.488 total time=   0.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=StandardScaler();, score=0.474 total time=   1.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=MinMaxScaler();, score=0.464 total time=   1.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=MinMaxScaler();, score=0.457 total time=   1.3s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=RobustScaler();, score=0.485 total time=   2.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=RobustScaler();, score=0.485 total time=   2.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=RobustScaler();, score=0.485 total time=   1.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=RobustScaler();, score=0.485 total time=   2.1s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=RobustScaler();, score=0.481 total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=RobustScaler();, score=0.510 total time= 1.4min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=RobustScaler();, score=0.502 total time= 3.4min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=StandardScaler();, score=0.505 total time= 2.6min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=RobustScaler();, score=0.502 total time= 2.8min\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=StandardScaler();, score=0.512 total time= 1.1min\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=RobustScaler();, score=0.522 total time= 1.1min\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=RobustScaler();, score=0.511 total time=  44.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=RobustScaler();, score=0.522 total time=  54.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   2.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=RobustScaler();, score=0.348 total time=   2.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=StandardScaler();, score=0.348 total time=   1.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   0.5s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=MinMaxScaler();, score=0.348 total time=   0.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=RobustScaler();, score=0.348 total time=   1.0s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=MinMaxScaler();, score=0.348 total time=   0.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=MinMaxScaler();, score=0.348 total time=   0.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=MinMaxScaler();, score=0.348 total time=   0.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=RobustScaler();, score=0.362 total time=   4.2s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=StandardScaler();, score=0.491 total time=   3.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=StandardScaler();, score=0.511 total time=  10.7s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=MinMaxScaler();, score=0.460 total time=   2.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=RobustScaler();, score=0.475 total time=  42.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=StandardScaler();, score=0.502 total time=  26.2s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=RobustScaler();, score=0.475 total time=  32.0s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=100, scaler=RobustScaler();, score=0.501 total time=  22.9s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=MinMaxScaler();, score=0.460 total time=   2.0s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=MinMaxScaler();, score=0.475 total time=   1.9s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1000, scaler=RobustScaler();, score=0.509 total time=  25.7s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=StandardScaler();, score=0.502 total time=  25.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=MinMaxScaler();, score=0.348 total time=   0.5s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=MinMaxScaler();, score=0.348 total time=   0.5s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=MinMaxScaler();, score=0.348 total time=   0.5s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=RobustScaler();, score=0.348 total time=   2.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=MinMaxScaler();, score=0.403 total time=   1.3s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=RobustScaler();, score=0.474 total time=   3.1s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=MinMaxScaler();, score=0.452 total time=   1.2s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=RobustScaler();, score=0.482 total time=   4.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=MinMaxScaler();, score=0.451 total time=   1.4s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=StandardScaler();, score=0.502 total time= 2.4min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=StandardScaler();, score=0.496 total time=   8.2s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=StandardScaler();, score=0.504 total time=   6.7s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=MinMaxScaler();, score=0.497 total time=   6.8s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=StandardScaler();, score=0.505 total time=   9.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=StandardScaler();, score=0.511 total time=   9.7s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=RobustScaler();, score=0.423 total time=   1.0s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=MinMaxScaler();, score=0.350 total time=   0.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=MinMaxScaler();, score=0.352 total time=   0.9s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=StandardScaler();, score=0.513 total time=   1.4s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=StandardScaler();, score=0.512 total time=   2.0s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=MinMaxScaler();, score=0.485 total time=   2.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=StandardScaler();, score=0.511 total time=   4.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=StandardScaler();, score=0.513 total time=   5.3s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=StandardScaler();, score=0.513 total time=   4.6s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=StandardScaler();, score=0.514 total time=   4.9s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=MinMaxScaler();, score=0.495 total time=   5.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=RobustScaler();, score=0.418 total time=   1.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=RobustScaler();, score=0.496 total time=   2.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=RobustScaler();, score=0.497 total time=   1.0s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=RobustScaler();, score=0.506 total time=   2.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=RobustScaler();, score=0.502 total time=   2.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=StandardScaler();, score=0.503 total time=   3.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=MinMaxScaler();, score=0.475 total time=   2.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=StandardScaler();, score=0.502 total time=   2.8s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=MinMaxScaler();, score=0.460 total time=   2.7s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=MinMaxScaler();, score=0.348 total time=   0.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1e-05, scaler=RobustScaler();, score=0.421 total time=   1.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=RobustScaler();, score=0.474 total time=   1.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=StandardScaler();, score=0.485 total time=   1.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=MinMaxScaler();, score=0.456 total time=   1.2s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=StandardScaler();, score=0.494 total time=   2.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=MinMaxScaler();, score=0.454 total time=   1.6s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=StandardScaler();, score=0.495 total time=   2.3s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=StandardScaler();, score=0.502 total time=   3.2s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=RobustScaler();, score=0.495 total time=   2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10000, scaler=StandardScaler();, score=0.512 total time=  19.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1e-05, scaler=RobustScaler();, score=0.348 total time=   2.5s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=StandardScaler();, score=0.348 total time=   0.8s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.0001, scaler=RobustScaler();, score=0.348 total time=   0.7s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=StandardScaler();, score=0.367 total time=   2.4s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.001, scaler=RobustScaler();, score=0.366 total time=   2.2s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=MinMaxScaler();, score=0.383 total time=   1.2s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.01, scaler=RobustScaler();, score=0.459 total time=   3.0s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=MinMaxScaler();, score=0.443 total time=   1.2s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=MinMaxScaler();, score=0.445 total time=   1.3s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=0.1, scaler=RobustScaler();, score=0.490 total time=   3.8s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=1, scaler=RobustScaler();, score=0.485 total time=  18.7s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', random_state=1,\n",
      "                   solver='saga'), model__C=10, scaler=RobustScaler();, score=0.481 total time= 2.5min\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=RobustScaler();, score=0.498 total time=  12.1s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=RobustScaler();, score=0.504 total time=   8.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=MinMaxScaler();, score=0.419 total time=   1.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=MinMaxScaler();, score=0.471 total time=   1.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=StandardScaler();, score=0.489 total time=   4.7s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=MinMaxScaler();, score=0.483 total time=   3.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=MinMaxScaler();, score=0.479 total time=   5.3s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=MinMaxScaler();, score=0.490 total time=   5.1s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=MinMaxScaler();, score=0.490 total time=   4.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=MinMaxScaler();, score=0.490 total time=   4.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.0001, scaler=StandardScaler();, score=0.500 total time=   2.4s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=MinMaxScaler();, score=0.414 total time=   0.7s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=MinMaxScaler();, score=0.448 total time=   1.0s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.1, scaler=StandardScaler();, score=0.504 total time=   2.9s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=MinMaxScaler();, score=0.484 total time=   2.1s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=StandardScaler();, score=0.512 total time=   3.2s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=100, scaler=MinMaxScaler();, score=0.492 total time=   2.7s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=MinMaxScaler();, score=0.460 total time=   4.6s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=RobustScaler();, score=0.501 total time=   3.0s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=MinMaxScaler();, score=0.407 total time=   0.5s\n",
      "[CV 3/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.001, scaler=RobustScaler();, score=0.488 total time=   0.9s\n",
      "[CV 4/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=0.01, scaler=RobustScaler();, score=0.485 total time=   1.6s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1, scaler=StandardScaler();, score=0.476 total time=   2.4s\n",
      "[CV 2/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=MinMaxScaler();, score=0.449 total time=   1.6s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10, scaler=RobustScaler();, score=0.487 total time=   2.7s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=1000, scaler=MinMaxScaler();, score=0.469 total time=   2.3s\n",
      "[CV 1/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=MinMaxScaler();, score=0.460 total time=   1.8s\n",
      "[CV 5/5] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=LogisticRegression(max_iter=1000, n_jobs=-1, random_state=1), model__C=10000, scaler=RobustScaler();, score=0.488 total time=   1.1s\n"
     ]
    }
   ],
   "source": [
    "print(f'The current best accuracy with XG Boost is : {round(best_xgb_model.score(X_test, y_test),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba87ae2",
   "metadata": {},
   "source": [
    "## The models are just a first draft of what it can do, I haven't optimized a lot yet.\n",
    "\n",
    "## More to follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768ff55b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7204bd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "cdda04eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Models/xgb_model.sav']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_xgb_model, \"../Models/xgb_model.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a288eb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating pickle file\n"
     ]
    }
   ],
   "source": [
    "print(\"creating pickle file\")\n",
    "pickle.dump(tfidf_Name,open('../Models/name.pkl','wb'))\n",
    "pickle.dump(tfidf_Publisher,open('../Models/publisher.pkl','wb'))\n",
    "pickle.dump(tfidf_Developer,open('../Models/developer.pkl','wb'))\n",
    "pickle.dump(xgb_model,open('../Models/xgb_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d251c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
